---
title: 'Normalization Inflates Type I error: A Simulation Motivated by Replication Study: Melanoma exosomes educate bone marrow progenitor cells toward a pro-metastatic phenotype through MET'
author: Jeff Walker
date: 'October 23, 2019'
output:
  BiocStyle::html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    fig_caption: yes
    number_sections: true
    code_folding: hide
---

<script src="/rmarkdown-libs/kePrint/kePrint.js"></script>


<div id="summary" class="section level1">
<h1>Summary</h1>
<p>Fig 1C of the <a href="https://elifesciences.org/articles/39944">Replication Study: Melanoma exosomes educate bone marrow progenitor cells toward a pro-metastatic phenotype through MET</a> uses an odd (to me) three stage normalization procedure for the quantified western blots. The authors compared blot values of a treatment (Met or pMet) to a control (shScr) using GAPDH to normalize the values. The three stages of the normalization are</p>
<ol style="list-style-type: decimal">
<li>first, the value for the Antibody levels were normalized by the value of a reference (GAPDH) for each Set. This is the typical normalization throughout bench biology.</li>
<li>second, the GAPDH-normalized values were rescaled by the mean of the GAPDH-normalized values for the shScr Condition within each combination of Antibody+Type+Blot. And,</li>
<li>third, <em>all</em> values in the shScr group were assigned to 1 (since the mean within the Condition level is 1). The statistical test then is a one-sample t-test of shMet with <span class="math inline">\(\mu=1\)</span>.</li>
</ol>
<p>As shown in the simulation below and summarized in the section <a href="#summary-of-simulation-results-for-n4">Summary of simulation results for n=4</a>, Stage 1 can introduce inflated <em>conditional</em> type I error due to regression to the mean while stage 2 and 3 renormalizations introduce inflated marginal (or unconditional) type I error.</p>
</div>
<div id="conditional-v-marginal-type-i-error" class="section level1">
<h1>Conditional v marginal type I error</h1>
<p>Normalizing a value using a reference, such as GAPDH, is used to increase the precision of a treatment effect by removing the noise in band intensity due to non-biological sources of variation. The reference value (intensity) is the proxy for this variation and the treatment or control values are expected to go up and down (that is have a positive correlation) with this reference. Normalizing by a reference value assumes that the correlation between reference values and either control or treatment values is 1.0 – that is they are precisely similarly effected by the non-biological sources of variation. At any correlation less that 1.0, there will be some consequence of <a href="https://www.middleprofessor.com/files/quasipubs/change_scores.html">regression to the mean</a> due to the vicissitudes of sampling. This consequence is largest when the true correlation between reference values and control/treatment values is zero.</p>
<p>The consequences of regression to the mean on type I error can be shown by plotting the probability of type I error against the observed difference in the reference value between treatment and control, which I’ll refer to as <span class="math inline">\(\Delta Gapdh\)</span> since GAPDH is the reference in the focal study. An increase in the probability of type I error as the magnitude of <span class="math inline">\(\Delta Gapdh\)</span> increases is the result of regression to the mean – an experiment with a larger <span class="math inline">\(\Delta Gapdh\)</span> is more likely to result in a larger observed treatment effect, when no true treatment effect exists, and therefore more likely to result in small <em>p</em>-values and inflated type I error.</p>
<p>The type I error as a function of the magnitude of <span class="math inline">\(\Delta Gapdh\)</span> is the <strong>conditional type I error</strong> because it is conditional on <span class="math inline">\(\Delta Gapdh\)</span>. I refer to the type I error taken over all values of <span class="math inline">\(\Delta Gapdh\)</span> as the <strong>marginal type I error</strong>. The marginal type I error is the type I error that we usually talk about (because we usually don’t think of it as being conditioned on some covariate)</p>
</div>
<div id="fig-1c" class="section level1">
<h1>Fig 1C</h1>
<pre class="r"><code>folder &lt;- &quot;Data from Generation and characterization of shMet B16-F10 cells and exosomes&quot;
filename &lt;- &quot;Study_42_Figure_1_WB_quant_Data.csv&quot;
file_path &lt;- here(data_path, folder, filename)
exp1 &lt;- fread(file_path)
exp1[, Condition := factor(Condition, c(&quot;shScr&quot;, &quot;shMet&quot;))]
#View(exp1)</code></pre>
<p>The Met and pMet values in Fig 1C are normalized using a three-step procedure (each its own kind of normalization).</p>
<ol style="list-style-type: decimal">
<li>norm1 is the conventional normalization using the reference (GAPDH) value.</li>
<li>norm2 is norm1 rescaled by the mean of shScr.</li>
<li>norm3 is setting all rescaled values of shScr to equal 1.</li>
</ol>
<pre class="r"><code># get GAPDH ref for each row to rescale (&quot;normalize&quot;) by GAPDH
gapdh_ref.dt &lt;- exp1[Antibody==&quot;Gapdh&quot;, .(gapdh_ref=mean(Value)), by=Set]
exp1.v1 &lt;- merge(exp1, gapdh_ref.dt, by=&quot;Set&quot;)
exp1.v1[, norm1:=Value/gapdh_ref]

# get mean shScr for each Antibody:Type:Blot to rescale by mean shScr 
shScr_ref.dt &lt;- exp1.v1[Condition==&quot;shScr&quot;, .(shScr_ref=mean(norm1)), by=.(Antibody, Type, Blot)]
exp1.v1 &lt;- merge(exp1.v1, shScr_ref.dt, by=c(&quot;Antibody&quot;, &quot;Type&quot;, &quot;Blot&quot;))
exp1.v1[, norm2:=norm1/shScr_ref]
exp1.v1[, norm3:=ifelse(Condition==&quot;shScr&quot;, 1, norm2)]
#View(exp1.v1)

gg1 &lt;- ggbarplot(data=exp1.v1[Antibody==&quot;Met&quot; &amp; Type==&quot;Cells&quot;], 
                 x=&quot;Condition&quot;, 
                 y=&quot;norm1&quot;,
          add=c(&quot;mean_se&quot;)) +
  ylab(&quot;Met&quot;) +
  NULL
gg2 &lt;- ggbarplot(data=exp1.v1[Antibody==&quot;pMet&quot; &amp; Type==&quot;Cells&quot;,],
                 x=&quot;Condition&quot;, 
                 y=&quot;norm1&quot;,
                 add=c(&quot;mean_se&quot;)) +
  ylab(&quot;pMet&quot;) +
  NULL

gg3 &lt;- ggbarplot(data=exp1.v1[Antibody==&quot;Met&quot; &amp; Type==&quot;Cells&quot;], 
                 x=&quot;Condition&quot;, 
                 y=&quot;norm3&quot;,
          add=c(&quot;mean_se&quot;)) +
  ylab(&quot;Met&quot;) +
  NULL
gg4 &lt;- ggbarplot(data=exp1.v1[Antibody==&quot;pMet&quot; &amp; Type==&quot;Cells&quot;,],
                 x=&quot;Condition&quot;, 
                 y=&quot;norm3&quot;,
                 add=c(&quot;mean_se&quot;)) +
  ylab(&quot;pMet&quot;) +
  NULL

plot_grid(gg1, gg2, gg3, gg4, nrow=2)</code></pre>
<p><img src="/quasipub/normalization-inflates-type-i-error_files/figure-html/reproducibility-1.png" width="672" /></p>
<p>The two bottom plots reproduce Fig 1C from the paper, which uses norm3. The two top plots are scaled by GAPDH but not shScr (norm1).</p>
<div id="plots-of-the-data" class="section level2">
<h2>Plots of the data</h2>
<pre class="r"><code>gg1 &lt;- ggstripchart(data=exp1.v1[Antibody==&quot;Met&quot; &amp; Type==&quot;Cells&quot;], 
                 x=&quot;Condition&quot;, 
                 y=&quot;Value&quot;,
          add=c(&quot;mean_se&quot;)) +
  ylab(&quot;Met&quot;) +
  theme_minimal() +
  NULL
gg2 &lt;- ggstripchart(data=exp1.v1[Antibody==&quot;pMet&quot; &amp; Type==&quot;Cells&quot;,],
                 x=&quot;Condition&quot;, 
                 y=&quot;Value&quot;,
                 add=c(&quot;mean_se&quot;)) +
  ylab(&quot;pMet&quot;) +
  theme_minimal() +
  NULL
gg3 &lt;- ggplot(data=exp1.v1[Antibody==&quot;Met&quot; &amp; Type==&quot;Cells&quot;], 
              aes(x=gapdh_ref/10^3, y=Value, color=Condition)) +
  geom_point() +
  ylab(&quot;Met&quot;) +
  xlab(expression(paste(Gapdh, &quot; (X&quot;, 10^{-3}, &quot;)&quot;))) +
  theme_minimal() +
  NULL
gg4 &lt;- ggplot(data=exp1.v1[Antibody==&quot;pMet&quot; &amp; Type==&quot;Cells&quot;],
              aes(x=gapdh_ref/10^3, y=Value, color=Condition)) +
  geom_point() +
  ylab(&quot;pMet&quot;) +
  xlab(expression(paste(Gapdh, &quot; (X&quot;, 10^{-3}, &quot;)&quot;))) +
  theme_minimal() +
  NULL
plot_grid(gg1, gg2, gg3, gg4, nrow=2)</code></pre>
<p><img src="/quasipub/normalization-inflates-type-i-error_files/figure-html/stripchart-1.png" width="672" /></p>
<p>We might infer from the top plots that the shMet condition decreases Met and pMet but the p-values from a t-test for these are 0.098 and 0.208 (see below) (note here and throughout, I use simple linear models and t-tests to compute p-values even though I would probably fit generalized linear models were I to analyze these data. For comparison, the Wilcoxan p-values are 0.1 and 0.34). The bottom plots suggest trivial correlations between GAPDH and either shScr or shMet, although the sample size for this is extremely small (see below for computations of various attempts to estimate this correlation).</p>
</div>
<div id="what-are-the-consequences-of-normalization-compare-to-linear-model-with-gapdh-as-covariate" class="section level2">
<h2>What are the consequences of normalization? Compare to linear model with Gapdh as covariate</h2>
<p>Here I compare p-values of t-tests of the three different normalizations, with a t-test of the raw (non-normalized) values and with a linear model (“lm”) with <span class="math inline">\(Gapdh\)</span> as a covariate, which is the preferred method of adjusting for nuissance co-variation.</p>
<div id="met" class="section level3">
<h3>Met</h3>
<pre class="r"><code>prob &lt;- numeric(5) # p-values for all five ways of analyzing data
# linear model with ref as covariate
m1 &lt;- lm(Value ~ gapdh_ref + Condition, data=exp1.v1[Antibody==&quot;Met&quot; &amp; Type==&quot;Cells&quot;])
# linear model with no accounting for ref
m2 &lt;- lm(Value ~ Condition, data=exp1.v1[Antibody==&quot;Met&quot; &amp; Type==&quot;Cells&quot;])
# linear model using Gapdh normalized values
m3 &lt;- lm(norm1 ~ Condition, data=exp1.v1[Antibody==&quot;Met&quot; &amp; Type==&quot;Cells&quot;])
# linear model using Gapdh normalized rescaled to shScr values
m4 &lt;- lm(norm2 ~ Condition, data=exp1.v1[Antibody==&quot;Met&quot; &amp; Type==&quot;Cells&quot;])

prob[1] &lt;- coef(summary(m1))[&quot;ConditionshMet&quot;, &quot;Pr(&gt;|t|)&quot;]
prob[2] &lt;- coef(summary(m2))[&quot;ConditionshMet&quot;, &quot;Pr(&gt;|t|)&quot;]
prob[3] &lt;- coef(summary(m3))[&quot;ConditionshMet&quot;, &quot;Pr(&gt;|t|)&quot;]
prob[4] &lt;- coef(summary(m4))[&quot;ConditionshMet&quot;, &quot;Pr(&gt;|t|)&quot;]
prob[5] &lt;- t.test(x=exp1.v1[Antibody==&quot;Met&quot; &amp;
                              Type==&quot;Cells&quot; &amp;
                              Condition == &quot;shMet&quot;, norm3],
                  mu=1)$p.value
prob6 &lt;- wilcox.test(x=exp1.v1[Antibody==&quot;Met&quot; &amp;
                                 Type==&quot;Cells&quot; &amp;
                                 Condition == &quot;shMet&quot;, Value],
                     y=exp1.v1[Antibody==&quot;Met&quot; &amp;
                                 Type==&quot;Cells&quot; &amp;
                                 Condition == &quot;shScr&quot;, Value])
knitr::kable(data.table(Method=c(&quot;lm&quot;, &quot;none&quot;, &quot;norm1&quot;, &quot;norm2&quot;, &quot;norm3&quot;),
             &quot;p-value&quot; = prob), digits = 3,
             caption = &quot;P-values for Met&quot;)</code></pre>
<table>
<caption><span id="tab:covariate-v-normalization-met">Table 1: </span>P-values for Met</caption>
<thead>
<tr class="header">
<th align="left">Method</th>
<th align="right">p-value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">lm</td>
<td align="right">0.191</td>
</tr>
<tr class="even">
<td align="left">none</td>
<td align="right">0.098</td>
</tr>
<tr class="odd">
<td align="left">norm1</td>
<td align="right">0.128</td>
</tr>
<tr class="even">
<td align="left">norm2</td>
<td align="right">0.079</td>
</tr>
<tr class="odd">
<td align="left">norm3</td>
<td align="right">0.014</td>
</tr>
</tbody>
</table>
</div>
<div id="pmet" class="section level3">
<h3>pMet</h3>
<pre class="r"><code>prob &lt;- numeric(5) # p-values for all five ways of analyzing data
# linear model with ref as covariate
m1 &lt;- lm(Value ~ gapdh_ref + Condition, data=exp1.v1[Antibody==&quot;pMet&quot; &amp; Type==&quot;Cells&quot;])
# linear model with no accounting for ref
m2 &lt;- lm(Value ~ Condition, data=exp1.v1[Antibody==&quot;pMet&quot; &amp; Type==&quot;Cells&quot;])
# linear model using Gapdh normalized values
m3 &lt;- lm(norm1 ~ Condition, data=exp1.v1[Antibody==&quot;pMet&quot; &amp; Type==&quot;Cells&quot;])
# linear model using Gapdh normalized rescaled to shScr values
m4 &lt;- lm(norm2 ~ Condition, data=exp1.v1[Antibody==&quot;pMet&quot; &amp; Type==&quot;Cells&quot;])

prob[1] &lt;- coef(summary(m1))[&quot;ConditionshMet&quot;, &quot;Pr(&gt;|t|)&quot;]
prob[2] &lt;- coef(summary(m2))[&quot;ConditionshMet&quot;, &quot;Pr(&gt;|t|)&quot;]
prob[3] &lt;- coef(summary(m3))[&quot;ConditionshMet&quot;, &quot;Pr(&gt;|t|)&quot;]
prob[4] &lt;- coef(summary(m4))[&quot;ConditionshMet&quot;, &quot;Pr(&gt;|t|)&quot;]
prob[5] &lt;- t.test(x=exp1.v1[Antibody==&quot;pMet&quot; &amp;
                              Type==&quot;Cells&quot; &amp;
                              Condition == &quot;shMet&quot;, norm3],
                  mu=1)$p.value
prob6 &lt;- wilcox.test(x=exp1.v1[Antibody==&quot;pMet&quot; &amp;
                                 Type==&quot;Cells&quot; &amp;
                                 Condition == &quot;shMet&quot;, Value],
                     y=exp1.v1[Antibody==&quot;pMet&quot; &amp;
                                 Type==&quot;Cells&quot; &amp;
                                 Condition == &quot;shScr&quot;, Value])

knitr::kable(data.table(Method=c(&quot;lm&quot;, &quot;none&quot;, &quot;norm1&quot;, &quot;norm2&quot;, &quot;norm3&quot;),
             &quot;p-value&quot; = prob), digits = 3,
             caption = &quot;P-values for pMet&quot;)</code></pre>
<table>
<caption><span id="tab:covariate-v-normalization-pmet-1">Table 2: </span>P-values for pMet</caption>
<thead>
<tr class="header">
<th align="left">Method</th>
<th align="right">p-value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">lm</td>
<td align="right">0.254</td>
</tr>
<tr class="even">
<td align="left">none</td>
<td align="right">0.208</td>
</tr>
<tr class="odd">
<td align="left">norm1</td>
<td align="right">0.227</td>
</tr>
<tr class="even">
<td align="left">norm2</td>
<td align="right">0.000</td>
</tr>
<tr class="odd">
<td align="left">norm3</td>
<td align="right">0.003</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div id="simulations" class="section level1">
<h1>Simulations</h1>
<p>Here I simulate the experiment in Fig 1 C of the paper. Effectively, this simulates an experiment with one control level, one treatment level, and a sample size of 4 (per level). Control and treatment levels are adjusted using a reference level (simulating GAPDH). The adjustments are 1) lm (linear model with <span class="math inline">\(Gapdh\)</span> has covariate), 2) norm1 (the ratio of the control or treatment level divided by <span class="math inline">\(Gapdh\)</span> level), 3) norm2 (norm1 rescaled to the control mean) and 4) norm3, equivalent to norm2 but the values for control are set to equal one.</p>
<div id="what-is-correlation-between-gapdh-and-control-or-treatment" class="section level2">
<h2>What is correlation between gapdh and control or treatment?</h2>
<p>As described above, normalization assumes a correlation of 1.0 between the reference and focal values. Here I compute multiple estimates of the true correlation between the reference values and the conditional response (conditioned on treatment level) in the whole data set and different subgroups. The true correlation is estimated with large error, because of the small sample size, so the estimates here are very uncertain. Nevertheless, the different estimates are pretty consistent that this correlation is very small. Regardless, Keep these values in mind.</p>
<pre class="r"><code>r &lt;- numeric(5)
dataset &lt;- rep(&quot;&quot;, 5)
fit &lt;- lm(Value ~ Condition + Type + Antibody,
          data=exp1.v1[Antibody!=&quot;Gapdh&quot;])
r[1] &lt;- cor(residuals(fit), exp1.v1[Antibody!=&quot;Gapdh&quot;, gapdh_ref])
dataset[1] &lt;- &quot;whole dataset&quot;
  
fit &lt;- lm(Value ~ Condition + Antibody,
          data=exp1.v1[Antibody!=&quot;Gapdh&quot; &amp; Type==&quot;Cells&quot;])
r[2] &lt;- cor(residuals(fit), exp1.v1[Antibody!=&quot;Gapdh&quot; &amp; Type==&quot;Cells&quot;, gapdh_ref])
dataset[2] &lt;- &quot;subset of Type=Cells&quot;

fit &lt;- lm(Value ~ Condition + Type, data=exp1.v1[Antibody==&quot;Met&quot;])
r[3] &lt;- cor(residuals(fit), exp1.v1[Antibody==&quot;Met&quot;, gapdh_ref])
dataset[3] &lt;- &quot;subset of Antibody=Met&quot;

fit &lt;- lm(Value ~ Condition, data=exp1.v1[Antibody==&quot;Met&quot; &amp; Type==&quot;Cells&quot;])
r[4] &lt;- cor(residuals(fit), exp1.v1[Antibody==&quot;Met&quot; &amp; Type==&quot;Cells&quot;, gapdh_ref])
dataset[4] &lt;- &quot;subset of Antibody=Met and Type=Cells&quot;

fit &lt;- lm(Value ~ Condition, data=exp1.v1[Antibody==&quot;pMet&quot;])
r[5] &lt;- cor(residuals(fit), exp1.v1[Antibody==&quot;pMet&quot;, gapdh_ref])
dataset[5] &lt;- &quot;subset of Antibody=pMet (all Type=Cells)&quot;

knitr::kable(data.table(Dataset=dataset, Cor=r), digits=3)</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">Dataset</th>
<th align="right">Cor</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">whole dataset</td>
<td align="right">0.027</td>
</tr>
<tr class="even">
<td align="left">subset of Type=Cells</td>
<td align="right">0.068</td>
</tr>
<tr class="odd">
<td align="left">subset of Antibody=Met</td>
<td align="right">-0.020</td>
</tr>
<tr class="even">
<td align="left">subset of Antibody=Met and Type=Cells</td>
<td align="right">-0.153</td>
</tr>
<tr class="odd">
<td align="left">subset of Antibody=pMet (all Type=Cells)</td>
<td align="right">0.027</td>
</tr>
</tbody>
</table>
</div>
<div id="how-are-the-experiments-structured" class="section level2">
<h2>How are the experiments structured?</h2>
<pre class="r"><code>exp1[Antibody==&quot;Met&quot; &amp; Type==&quot;Cells&quot;, .(N=.N), by=.(Antibody, Type, Blot, Condition)]</code></pre>
<pre><code>##    Antibody  Type                  Blot Condition N
## 1:      Met Cells https://osf.io/e3dny/     shScr 1
## 2:      Met Cells https://osf.io/e3dny/     shMet 1
## 3:      Met Cells https://osf.io/nra32/     shMet 2
## 4:      Met Cells https://osf.io/nra32/     shScr 2</code></pre>
<pre class="r"><code>exp1[Antibody==&quot;pMet&quot; &amp; Type==&quot;Cells&quot;, .(N=.N), by=.(Antibody, Type, Blot, Condition)]</code></pre>
<pre><code>##    Antibody  Type                  Blot Condition N
## 1:     pMet Cells https://osf.io/bnxht/     shScr 1
## 2:     pMet Cells https://osf.io/bnxht/     shMet 1
## 3:     pMet Cells https://osf.io/nra32/     shMet 2
## 4:     pMet Cells https://osf.io/nra32/     shScr 2
## 5:     pMet Cells https://osf.io/dg4kx/     shScr 1
## 6:     pMet Cells https://osf.io/dg4kx/     shMet 1</code></pre>
<p>Met data: one replicate in one blot and two replicates in one blot for the Met data (so n=3);</p>
<p>pMet data: one replicate in two blots and two replicates in one blots (so n=4).</p>
</div>
<div id="simulation-functions" class="section level2">
<h2>Simulation functions</h2>
<p>The functions for generating a data set with a control, a treatment, and a reference for normalization. norm1, norm2, and norm3 are defined as above. The parameter rho controls the expected correlation between the reference and either the control or treatment. The explored values are (0, 0.3, 0.6). Note the empirical estimates of rho are close to zero.</p>
<pre class="r"><code>get_fake_data &lt;- function(
  n=4, # number of replicates per treatment level
  rho=0.5, # correlation between the reference value and that of a control level
  s_kappa=1, # effect of treatment on shape (this is multiplicative so 1 = no effect)
  s_theta=1, # effect of treatment on scale (this is multiplicative so 1 = no effect
  kappa_0=80, # shape parameter for reference
  theta_0=100, # scale parameter for reference
  kappa_1=30, # shape parameter for control
  theta_1=100 # scale parameter for control
){
  kappa_1_i &lt;- rep(c(kappa_1, kappa_1*s_kappa), each=n)
  theta_1_i &lt;- rep(c(theta_1, theta_1*s_theta), each=n)
  y1 &lt;- rgamma(n*2, shape=kappa_0 - rho*sqrt(kappa_0*kappa_1), scale=1)
  y2 &lt;- rgamma(n*2, shape=kappa_1_i - rho*sqrt(kappa_0*kappa_1_i), scale=1)
  y3 &lt;- rgamma(n*2, shape=rho*sqrt(kappa_0*kappa_1), scale=1)
  fd &lt;- data.table(
    treatment=rep(c(&quot;cn&quot;, &quot;tr&quot;), each=n),
    gapdh=theta_0*(y1+y3),
    value=theta_1_i*(y2+y3)
  )
  return(fd)
}

simulate_experiment &lt;- function(
  n=4, # number of replicates per treatment level
  blot_id=rep(&quot;blot1&quot;, n), # how to divy up the n samples among blots
  rho=0.5, # correlation between the reference value and that of a control level
  s_kappa=1, # effect of treatment on shape (this is multiplicative so 1 = no effect)
  s_theta=1, # effect of treatment on scale (this is multiplicative so 1 = no effect
  kappa_0=80, # shape parameter for reference
  theta_0=100, # scale parameter for reference
  kappa_1=30, # shape parameter for control
  theta_1=100 # scale parameter for control
){
  fd &lt;- get_fake_data(n, rho, s_kappa, s_theta, 
                      kappa_0, theta_0, kappa_1, theta_1)
  fd[, blot:=rep(blot_id, 2)]
  fd[, norm1:=value/gapdh]
  cn_ref_list &lt;- fd[treatment==&quot;cn&quot;, .(cn_ref=mean(norm1)), by=blot]
  fd &lt;- merge(fd, cn_ref_list, by=&quot;blot&quot;)
  fd[, norm2:=norm1/cn_ref]
  fd[, norm3:=ifelse(treatment==&quot;cn&quot;, 1, norm2)]
  return(fd)
}

iterate_experiment &lt;- function(
  n=4, # number of replicates per treatment level
  blot_id=rep(&quot;blot1&quot;, n), # how to divy up the n samples among blots
  niter=2000, # number of iterations
  rho=0.5, # correlation between the reference value and that of a control level
  s_kappa=1, # effect of treatment on shape (this is multiplicative so 1 = no effect)
  s_theta=1, # effect of treatment on scale (this is multiplicative so 1 = no effect
  kappa_0=80, # shape parameter for reference
  theta_0=100, # scale parameter for reference
  kappa_1=30, # shape parameter for control
  theta_1=100 # scale parameter for control
  ){
  # Given a western blot with three &quot;treatments&quot;: reference (Gapdh) is the set of values for normaliztion
  # control is the set of values for a control. The treatment value is determined by beta_1 -- the effect
  prob_cols &lt;- c(&quot;lm&quot;, &quot;norm1&quot;, &quot;norm2&quot;, &quot;norm3&quot;)
  prob &lt;- data.table(matrix(-9999, nrow=niter, ncol=length(prob_cols)))
  setnames(prob, old=colnames(prob), new=prob_cols)
  effect_cols &lt;- c(&quot;delta_gapdh&quot;, &quot;effect_lm&quot;, &quot;effect_norm1&quot;, &quot;effect_norm2&quot;, &quot;effect_norm3&quot;)
  effects_dt &lt;- data.table(matrix(-9999, nrow=niter, ncol=length(effect_cols)))
  setnames(effects_dt, old=colnames(effects_dt), new=effect_cols)
  r &lt;- numeric(niter) # dor between control and gapdh values
  se.norm1 &lt;- numeric(niter) # se.norm1
  set.seed(1) # yes I want to reset this to the same with each combo
  for(iter in 1:niter){
    fd &lt;- simulate_experiment(
      n=n, # number of replicates per treatment level
      blot_id=blot_id, # how to divy up the n samples among blots
      rho=rho, # correlation between the reference value and that of a control level
      s_kappa=s_kappa, # effect of treatment on shape (this is multiplicative so 1 = no effect)
      s_theta=s_theta, # effect of treatment on scale (this is multiplicative so 1 = no effect
      kappa_0=kappa_0, # shape parameter for reference
      theta_0=theta_0, # scale parameter for reference
      kappa_1=kappa_1, # shape parameter for control
      theta_1=theta_1 # scale parameter for control
    )
    m1 &lt;- lm(value ~ gapdh + treatment, data=fd)
    m1.coef &lt;- coef(summary(m1))
    prob[iter, lm := m1.coef[&quot;treatmenttr&quot;, &quot;Pr(&gt;|t|)&quot;]]
    m2 &lt;- lm(norm1 ~ treatment, data=fd)
    m2.coef &lt;- coef(summary(m2))
    prob[iter, norm1 := m2.coef[&quot;treatmenttr&quot;, &quot;Pr(&gt;|t|)&quot;]]
    # prob[iter, norm1 := t.test(fd[treatment==&quot;cn&quot;, norm1], fd[treatment==&quot;tr&quot;, norm1], var.equal=TRUE)$p.value]
    prob[iter, norm2 := t.test(fd[treatment==&quot;cn&quot;, norm2], fd[treatment==&quot;tr&quot;, norm2], var.equal=TRUE)$p.value]
    prob[iter, norm3 := t.test(x=fd[treatment==&quot;tr&quot;, norm3], mu=1)$p.value]
    
    effects_dt[iter, delta_gapdh := mean(fd[treatment==&quot;tr&quot;, gapdh]) - mean(fd[treatment==&quot;cn&quot;, gapdh])]
    effects_dt[iter, effect_lm := m1.coef[&quot;treatmenttr&quot;, &quot;Estimate&quot;]]
    effects_dt[iter, effect_norm1 := m2.coef[&quot;treatmenttr&quot;, &quot;Estimate&quot;]]
    effects_dt[iter, effect_norm2 := mean(fd[treatment==&quot;tr&quot;, norm2]) - mean(fd[treatment==&quot;cn&quot;, norm2])]
    effects_dt[iter, effect_norm3 := mean(fd[treatment==&quot;tr&quot;, norm3]) - 1]
    
    r[iter] &lt;- cor(fd[treatment==&quot;cn&quot;, gapdh], fd[treatment==&quot;cn&quot;, value])
    se.norm1[iter] &lt;- m2.coef[&quot;treatmenttr&quot;, &quot;Std. Error&quot;]
  }
  return(
    data.table(prob, effects_dt, cor=r, se_norm1=se.norm1)
  )
}</code></pre>
<pre class="r"><code>n=10^4 # number of replicates per treatment level
rho=0.5 # correlation between the reference value and that of a control level
s_kappa=1.0 # effect of treatment on shape (this is multiplicative so 1 = no effect)
s_theta=1.0 # effect of treatment on scale (this is multiplicative so 1 = no effect
kappa_0=80 # shape parameter for reference
theta_0=100 # scale parameter for reference
kappa_1=30 # shape parameter for control
theta_1=100 # scale parameter for control
(s_kappa*kappa_1*s_theta*theta_1 - kappa_1*theta_1)/(sqrt(kappa_1*theta_1^2))

  fd &lt;- get_fake_data(n, rho, s_kappa, s_theta, 
                      kappa_0, theta_0, kappa_1, theta_1)
# quick and dirty cohen&#39;s
kappa_1*theta_1
s_kappa*kappa_1*s_theta*theta_1
(means_table &lt;- fd[, .(cell_mean=mean(value), cell_sd=sd(value)), by=treatment])
(means_table[treatment==&quot;tr&quot;, cell_mean] - means_table[treatment==&quot;cn&quot;, cell_mean])/means_table[treatment==&quot;cn&quot;, cell_sd]</code></pre>
</div>
<div id="functions-to-plot-simulation-results" class="section level2">
<h2>functions to plot simulation results</h2>
<pre class="r"><code>plot_effects &lt;- function(res){
  prob_cols &lt;- c(&quot;lm&quot;, &quot;norm1&quot;, &quot;norm2&quot;, &quot;norm3&quot;)
  gg1 &lt;- qplot(x=res$delta_gapdh/10^3, y=res$effect_lm) +
    geom_smooth(method=&quot;lm&quot;) +
    ggtitle(&quot;Linear model&quot;) +
    xlab(expression(paste(Gapdh[t] - Gapdh[c],  &quot;(X 1000)&quot;))) +
    ylab(&quot;Effect&quot;) +
    theme_minimal() +
    NULL
  gg2 &lt;- qplot(x=res$delta_gapdh/10^3, y=res$effect_norm1) +
    geom_smooth(method=&quot;lm&quot;) +
    ggtitle(&quot;Norm1&quot;) +
    xlab(expression(paste(Gapdh[t] - Gapdh[c],  &quot;(X 1000)&quot;))) +
    ylab(&quot;Effect&quot;) +
    theme_minimal() +
    NULL
  gg3 &lt;- qplot(x=res$delta_gapdh/10^3, y=res$effect_norm2) +
    geom_smooth(method=&quot;lm&quot;) +
    ggtitle(&quot;Norm2&quot;) +
    xlab(expression(paste(Gapdh[t] - Gapdh[c],  &quot;(X 1000)&quot;))) +
    ylab(&quot;Effect&quot;) +
    theme_minimal() +
    NULL
  gg4 &lt;- qplot(x=res$delta_gapdh/10^3, y=res$effect_norm3) +
    geom_smooth(method=&quot;lm&quot;) +
    ggtitle(&quot;Norm3&quot;) +
    xlab(expression(paste(Gapdh[t] - Gapdh[c],  &quot;(X 1000)&quot;))) +
    ylab(&quot;Effect&quot;) +
    theme_minimal() +
    NULL
  gg &lt;- plot_grid(gg1, gg2, gg3, gg4, nrow=2)
  return(gg)
}

plot_se &lt;- function(res){
  prob_cols &lt;- c(&quot;lm&quot;, &quot;norm1&quot;, &quot;norm2&quot;, &quot;norm3&quot;)
  blot_levels &lt;- unique(res$blots)
  i &lt;- 1
  gg1 &lt;- qplot(x=res[blots==blot_levels[i], delta_gapdh/10^3], y=res[blots==blot_levels[i], se_norm1]) +
    geom_smooth(method=&quot;lm&quot;) +
    ggtitle(paste(&quot;blots =&quot;, blot_levels[i])) +
    xlab(expression(paste(Gapdh[t] - Gapdh[c],  &quot;(X 1000)&quot;))) +
    ylab(&quot;Effect&quot;) +
    theme_minimal() +
    NULL
  i &lt;- 2
  gg2 &lt;- qplot(x=res[blots==blot_levels[i], delta_gapdh/10^3], y=res[blots==blot_levels[i], se_norm1]) +
    geom_smooth(method=&quot;lm&quot;) +
    ggtitle(paste(&quot;blots =&quot;, blot_levels[i])) +
    xlab(expression(paste(Gapdh[t] - Gapdh[c],  &quot;(X 1000)&quot;))) +
    ylab(&quot;Effect&quot;) +
    theme_minimal() +
    NULL
  i &lt;- 3
  gg3 &lt;- qplot(x=res[blots==blot_levels[i], delta_gapdh/10^3], y=res[blots==blot_levels[i], se_norm1]) +
    geom_smooth(method=&quot;lm&quot;) +
    ggtitle(paste(&quot;blots =&quot;, blot_levels[i])) +
    xlab(expression(paste(Gapdh[t] - Gapdh[c],  &quot;(X 1000)&quot;))) +
    ylab(&quot;Effect&quot;) +
    theme_minimal() +
    NULL
  i &lt;- 4
  gg4 &lt;- qplot(x=res[blots==blot_levels[i], delta_gapdh/10^3], y=res[blots==blot_levels[i], se_norm1]) +
    geom_smooth(method=&quot;lm&quot;) +
    ggtitle(paste(&quot;blots =&quot;, blot_levels[i])) +
    xlab(expression(paste(Gapdh[t] - Gapdh[c],  &quot;(X 1000)&quot;))) +
    ylab(&quot;Effect&quot;) +
    theme_minimal() +
    NULL
  gg &lt;- plot_grid(gg1, gg2, gg3, gg4, nrow=2)
  return(gg)
}

plot_prob_t1 &lt;- function(res){
  res[, t1.lm:=ifelse(lm &lt;= 0.05, 1, 0)]
  res[, t1.norm1:=ifelse(norm1 &lt;= 0.05, 1, 0)]
  res[, t1.norm2:=ifelse(norm2 &lt;= 0.05, 1, 0)]
  res[, t1.norm3:=ifelse(norm3 &lt;= 0.05, 1, 0)]
  gg1 &lt;- ggplot(data=res, aes(x=abs(delta_gapdh), y=t1.lm)) +
    geom_smooth(method=&#39;glm&#39;, method.args=list(family=&#39;binomial&#39;)) +
    ylab(&quot;Prob(Type I): linear model&quot;) +
    xlab(expression(paste(&quot;|&quot;,Gapdh[t] - Gapdh[c],&quot;|&quot;))) +
    theme_minimal()
  gg2 &lt;- ggplot(data=res, aes(x=abs(delta_gapdh), y=t1.norm1)) +
    geom_smooth(method=&#39;glm&#39;, method.args=list(family=&#39;binomial&#39;)) +
    ylab(&quot;Prob(Type I): norm1&quot;) +
    xlab(expression(paste(&quot;|&quot;,Gapdh[t] - Gapdh[c],&quot;|&quot;))) +
    theme_minimal()
  gg3 &lt;- ggplot(data=res, aes(x=abs(delta_gapdh), y=t1.norm2)) +
    geom_smooth(method=&#39;glm&#39;, method.args=list(family=&#39;binomial&#39;)) +
    ylab(&quot;Prob(Type I): norm2&quot;) +
    xlab(expression(paste(&quot;|&quot;,Gapdh[t] - Gapdh[c],&quot;|&quot;))) +
    theme_minimal()
  gg4 &lt;- ggplot(data=res, aes(x=abs(delta_gapdh), y=t1.norm3)) +
    geom_smooth(method=&#39;glm&#39;, method.args=list(family=&#39;binomial&#39;)) +
    ylab(&quot;Prob(Type I): norm3&quot;) +
    xlab(expression(paste(&quot;|&quot;,Gapdh[t] - Gapdh[c],&quot;|&quot;))) +
    theme_minimal()
  gg &lt;- plot_grid(gg1, gg2, gg3, gg4, nrow=2)
  return(gg)
}

plot_prob_t1_2 &lt;- function(res, ycol, two_d=FALSE){
  res[, t1:=ifelse(get(ycol) &lt;= 0.05, 1, 0)]
  gg &lt;- ggplot(data=res, aes(x=abs(delta_gapdh), y=t1)) +
    geom_smooth(method=&#39;glm&#39;, method.args=list(family=&#39;binomial&#39;)) +
    ylab(paste(&quot;Prob(Type I):&quot;, ycol)) +
    xlab(expression(paste(&quot;|&quot;,Gapdh[t] - Gapdh[c],&quot;|&quot;))) +
    geom_hline(aes(yintercept = 0.05), color=&quot;red&quot;) +
    theme_minimal() +
    NULL
  if(two_d==TRUE){
    gg &lt;- gg + facet_grid(blots ~ rho, labeller=label_both)
  }else{
    gg &lt;- gg + facet_grid(. ~ rho, labeller=label_both)
  }
  return(gg)
}</code></pre>
<pre class="r"><code>get_type_1_table &lt;- function(res){
  prob_cols &lt;- c(&quot;lm&quot;,&quot;norm1&quot;, &quot;norm2&quot;,&quot;norm3&quot;)
  niter &lt;- nrow(res)/length(unique(res[, blots]))/length(unique(res[, rho]))
  res_long &lt;- melt(res, id.vars = c(&quot;blots&quot;, &quot;rho&quot;), measure.vars = prob_cols, variable.name = &quot;method&quot;, value.name = &quot;p.value&quot;)
  type_1 &lt;- res_long[, .(Type_I=sum(p.value &lt; 0.05)/niter), by=.(blots, rho, method)]
  type_1_wide &lt;- dcast(type_1, blots ~ method, value.var = &quot;Type_I&quot;)
  return(type_1_wide)
}</code></pre>
</div>
<div id="function-to-run-the-simulation" class="section level2">
<h2>Function to run the simulation</h2>
<p>The simulation computes type I error at all combinations of <span class="math inline">\(blots\)</span> and <span class="math inline">\(rho\)</span>. The parameter <span class="math inline">\(blots\)</span> is the number of unique blots. The number of replicates per blot is n/blots, so with blots=1 there is one blot with four replicates. With n=4 and blots=3, there are 1, 1, and 2 replicates in the three blots, which is the case for pMet in Fig 1C. The parameter <span class="math inline">\(rho\)</span> is the expected correlation between the reference level and either the control or treatment level. Again, the empirical estimate of rho are close to zero. Effects and p-values are computed for 10,000 iterations of each combination of <span class="math inline">\(blots\)</span> and <span class="math inline">\(rho\)</span>. Sample size of <span class="math inline">\(n=4\)</span> (that of the pMet data in the study. The Met data was <span class="math inline">\(n=3\)</span>) and <span class="math inline">\(n=10\)</span> were run.</p>
<pre class="r"><code># parameters
# n=4, # number of replicates per treatment level
# blots=blots_i, # number of blots. Reps/blot = n/blots
# niter=1000, # number of iterations
# rho=0, # correlation between the reference value and that of a control level
# s_kappa=1, # effect of multiplicative treatment on shape
# s_theta=1, # effect of multiplicative treatment on scale
# kappa_0=80, # shape parameter for reference
# theta_0=100, # scale parameter for reference
# kappa_1=30, # shape parameter for control
# theta_1=100 # scale parameter for control
simulate_it &lt;- FALSE
which_sim &lt;- &quot;sim1&quot;
if(which_sim==&quot;sim1&quot;){
  file_path &lt;- here(output_path, &quot;normalization_II_sim1.rds&quot;)
  n_iter &lt;- 10000
  rho_vec &lt;- c(0, 0.3, 0.6) # cor between ref and either cn or tr
  n &lt;- 4
  blots_vec &lt;- c(1, 2, 3, 4) 
  reps_per_blot_mat &lt;- t(matrix(c(c(rep(4, 1), rep(NA, 3)),
                                  c(rep(2, 2), rep(NA, 2)),
                                  c(c(1, 1, 2), rep(NA, 1)),
                                  rep(1, 4)), ncol=4))
}
if(which_sim==&quot;sim2&quot;){
  file_path &lt;- here(output_path, &quot;normalization_II_sim2.rds&quot;)
  n_iter &lt;- 10000
  rho_vec &lt;- c(0, 0.3, 0.6) # cor between ref and either cn or tr
  n &lt;- 10
  blots_vec &lt;- c(1, 2, 5, 10) # number of blots
  
  reps_per_blot_mat &lt;- t(matrix(c(c(rep(10, 1), rep(NA, 9)),
                                  c(rep(5, 2), rep(NA, 8)),
                                  c(rep(2, 5), rep(NA, 5)),
                                  rep(1, 10)), ncol=4))
}
if(simulate_it==TRUE){
  sim_combo &lt;- expand.grid(blots=blots_vec, rho=rho_vec)
  
  blot_id_mat &lt;- data.frame(matrix(nrow=nrow(reps_per_blot_mat), ncol=n))
  for(i in 1:nrow(reps_per_blot_mat)){
    reps_per_blot &lt;- na.omit(reps_per_blot_mat[i,])
    blot_names &lt;- paste0(&quot;blot&quot;, seq_along(reps_per_blot))
    blot_id_mat[i,] &lt;- rep(blot_names, times=reps_per_blot)
  }
  blot_id_mat$blots &lt;- blots_vec
   sim_combo &lt;- data.table(merge(sim_combo, blot_id_mat, by=&quot;blots&quot;))
  blot_id_cols &lt;- paste0(&quot;X&quot;, 1:n)
  
  res &lt;- data.table(NULL)
  for(combo in 1:nrow(sim_combo)){
    blots_i &lt;- sim_combo[combo, blots]
    blot_id_i &lt;- unlist(sim_combo[combo, .SD, .SDcols=blot_id_cols])
    rho_i &lt;- sim_combo[combo, rho]
    res &lt;- rbind(res, 
                 data.table(blots=blots_i,
                            rho=rho_i,
                            iterate_experiment(
                              n=n,
                              blot_id=blot_id_i,
                              niter=n_iter,
                              rho=rho_i,
                              s_kappa=1,
                              s_theta=1,
                              kappa_0=80,
                              theta_0=100,
                              kappa_1=30,
                              theta_1=100
                            )))
    
  }
  saveRDS(res, file = file_path)
}else{
  res &lt;- readRDS(file = file_path)
}</code></pre>
</div>
</div>
<div id="simulation-results" class="section level1">
<h1>Simulation Results</h1>
<div id="results-for-n4-that-of-the-replication-study" class="section level2">
<h2>Results for n=4 (that of the replication study)</h2>
<div id="marginal-type-i-error" class="section level3">
<h3>marginal type I error</h3>
<p>Again, the marginal type I error is just the normal type I error.</p>
<pre class="r"><code>file_path &lt;- here(output_path, &quot;normalization_II_sim1.rds&quot;)
res &lt;- readRDS(file = file_path)

type1_a &lt;- get_type_1_table(res[rho==0])
type1_b &lt;- get_type_1_table(res[rho==0.3])
type1 &lt;- cbind(type1_a, type1_b[, .SD, .SDcols=c(&quot;lm&quot;, &quot;norm1&quot;, &quot;norm2&quot;, &quot;norm3&quot;)])
type1_kable &lt;- knitr::kable(type1, full_width=TRUE, digits=3)
type1_kable &lt;- kableExtra::add_header_above(type1_kable, c(&quot; &quot; = 1, &quot;rho = 0&quot; = 4, &quot;rho = 0.3&quot; = 4))</code></pre>
<pre><code>## Warning in kableExtra::add_header_above(type1_kable, c(` ` = 1, `rho = 0`
## = 4, : Please specify format in kable. kableExtra can customize either HTML
## or LaTeX outputs. See https://haozhu233.github.io/kableExtra/ for details.</code></pre>
<pre class="r"><code>type1_kable</code></pre>
<table>
<thead>
<tr class="header">
<th align="right">blots</th>
<th align="right">lm</th>
<th align="right">norm1</th>
<th align="right">norm2</th>
<th align="right">norm3</th>
<th align="right">lm</th>
<th align="right">norm1</th>
<th align="right">norm2</th>
<th align="right">norm3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">0.052</td>
<td align="right">0.049</td>
<td align="right">0.049</td>
<td align="right">0.117</td>
<td align="right">0.046</td>
<td align="right">0.049</td>
<td align="right">0.049</td>
<td align="right">0.108</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">0.052</td>
<td align="right">0.049</td>
<td align="right">0.060</td>
<td align="right">0.085</td>
<td align="right">0.046</td>
<td align="right">0.049</td>
<td align="right">0.059</td>
<td align="right">0.081</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">0.052</td>
<td align="right">0.049</td>
<td align="right">0.074</td>
<td align="right">0.064</td>
<td align="right">0.046</td>
<td align="right">0.049</td>
<td align="right">0.071</td>
<td align="right">0.062</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">0.052</td>
<td align="right">0.049</td>
<td align="right">0.090</td>
<td align="right">0.049</td>
<td align="right">0.046</td>
<td align="right">0.049</td>
<td align="right">0.089</td>
<td align="right">0.050</td>
</tr>
</tbody>
</table>
<p>The correlation parameter <span class="math inline">\(rho\)</span> doesn’t have much of an effect. Both lm and norm1 have nominal type I error regardless of rho or number of blots. Type I error of norm2 is increasingly inflated as the number of blots increases and the number of replicates/blot decreases. The reverse is the case for type I error of norm3 – type I error is inflated when all replicates are on a single blot. Note that the type I error for lm and norm1 are not a function of how replicates are structured.</p>
</div>
<div id="conditional-type-i-error-on-the-difference-in-gapdh-between-control-and-treatment" class="section level3">
<h3>Conditional type I error (on the difference in GAPDH between control and treatment)</h3>
<pre class="r"><code>plot_prob_t1_2(res, ycol=&quot;lm&quot;, two_d=TRUE)</code></pre>
<div class="figure"><span id="fig:unnamed-chunk-3"></span>
<img src="/quasipub/normalization-inflates-type-i-error_files/figure-html/unnamed-chunk-3-1.png" alt="p-values from linear model with Gapdh as covariate. The graphs are the same for all values of blots, but are shown for easy comparison with norm2 and norm3" width="672" />
<p class="caption">
Figure 1: p-values from linear model with Gapdh as covariate. The graphs are the same for all values of blots, but are shown for easy comparison with norm2 and norm3
</p>
</div>
<pre class="r"><code>plot_prob_t1_2(res, ycol=&quot;norm1&quot;, two_d=TRUE)</code></pre>
<div class="figure"><span id="fig:unnamed-chunk-4"></span>
<img src="/quasipub/normalization-inflates-type-i-error_files/figure-html/unnamed-chunk-4-1.png" alt="p-values from t-test of norm1. The graphs are the same for all values of blots, but are shown for easy comparison with norm2 and norm3" width="672" />
<p class="caption">
Figure 2: p-values from t-test of norm1. The graphs are the same for all values of blots, but are shown for easy comparison with norm2 and norm3
</p>
</div>
<pre class="r"><code>plot_prob_t1_2(res, ycol=&quot;norm2&quot;, two_d=TRUE)</code></pre>
<div class="figure"><span id="fig:unnamed-chunk-5"></span>
<img src="/quasipub/normalization-inflates-type-i-error_files/figure-html/unnamed-chunk-5-1.png" alt="p-values from t-test of norm2" width="672" />
<p class="caption">
Figure 3: p-values from t-test of norm2
</p>
</div>
<pre class="r"><code>plot_prob_t1_2(res, ycol=&quot;norm3&quot;, two_d=TRUE)</code></pre>
<div class="figure"><span id="fig:unnamed-chunk-6"></span>
<img src="/quasipub/normalization-inflates-type-i-error_files/figure-html/unnamed-chunk-6-1.png" alt="p-values from t-test of norm3" width="672" />
<p class="caption">
Figure 4: p-values from t-test of norm3
</p>
</div>
</div>
<div id="summary-of-simulation-results-for-n4" class="section level3">
<h3>Summary of simulation results for n=4</h3>
<p>The plots below show the estimated probability of a Type I error from the simulation and show two different sources of Type I error:</p>
<ol style="list-style-type: decimal">
<li>An increase in Type I error due to the re-normalization (norm 2 and norm3), which is shown by the upward shift of the curve (or, of the intercept) as the number of blots goes to <span class="math inline">\(n\)</span> for norm2 and to 1 for norm3. This is the marginal Type I error.</li>
<li>An increase in increased Type I error associated with increased magnitude of <span class="math inline">\(\Delta Gapdh\)</span>, which is shown by the positive slope of the curve. This is the conditional Type I error.</li>
</ol>
<p>Combined, the simulation shows</p>
<ol style="list-style-type: decimal">
<li><strong>linear model with Gapdh as covariate</strong> Both marginal and conditional type I error is well controlled using the linear model with the reference (GAPDH) as a covariate</li>
<li><strong>norm1</strong> Marginal type I error is well controlled using conventional normalization (norm1) but conditional type I error can be highly inflated as the magnitude of <span class="math inline">\(\Delta Gapdh\)</span> increases and especially when the correlation between the reference and control/treatment values is small.</li>
<li><strong>norm 2</strong> Marginal type I error for norm2 (renormalization using the control) is well controlled when there are many replicates per blot but increases above nominal when the number of replicates per blot decreases to one. Conditional type I error can be highly inflated as the magnitude of <span class="math inline">\(\Delta Gapdh\)</span> increases and especially when the correlation between the reference and control/treatment values is small.</li>
<li><strong>norm 3</strong> Marginal type I error for norm3 (setting control values to 1.0) is well controlled when there is one replicate per blot but increases above nominal when the number of replicates per blot increases. Conditional type I error can be highly inflated as the magnitude of <span class="math inline">\(\Delta Gapdh\)</span> increases and especially when the correlation between the reference and control/treatment values is small.</li>
</ol>
</div>
</div>
<div id="results-for-n10" class="section level2">
<h2>Results for n=10</h2>
<div id="marginal-type-i-error-1" class="section level3">
<h3>marginal type I error</h3>
<pre class="r"><code>file_path &lt;- here(output_path, &quot;normalization_II_sim2.rds&quot;)
res &lt;- readRDS(file = file_path)

type1_a &lt;- get_type_1_table(res[rho==0])
type1_b &lt;- get_type_1_table(res[rho==0.3])
type1 &lt;- cbind(type1_a, type1_b[, .SD, .SDcols=c(&quot;lm&quot;, &quot;norm1&quot;, &quot;norm2&quot;, &quot;norm3&quot;)])
type1_kable &lt;- knitr::kable(type1, full_width=TRUE, digits=3)
type1_kable &lt;- kableExtra::add_header_above(type1_kable, c(&quot; &quot; = 1, &quot;rho = 0&quot; = 4, &quot;rho = 0.3&quot; = 4))
type1_kable</code></pre>
<table>
<thead>
<tr>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="4">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
rho = 0
</div>
</th>
<th style="border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="4">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
rho = 0.3
</div>
</th>
</tr>
<tr>
<th style="text-align:right;">
blots
</th>
<th style="text-align:right;">
lm
</th>
<th style="text-align:right;">
norm1
</th>
<th style="text-align:right;">
norm2
</th>
<th style="text-align:right;">
norm3
</th>
<th style="text-align:right;">
lm
</th>
<th style="text-align:right;">
norm1
</th>
<th style="text-align:right;">
norm2
</th>
<th style="text-align:right;">
norm3
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0.05
</td>
<td style="text-align:right;">
0.05
</td>
<td style="text-align:right;">
0.050
</td>
<td style="text-align:right;">
0.151
</td>
<td style="text-align:right;">
0.045
</td>
<td style="text-align:right;">
0.046
</td>
<td style="text-align:right;">
0.046
</td>
<td style="text-align:right;">
0.141
</td>
</tr>
<tr>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
0.05
</td>
<td style="text-align:right;">
0.05
</td>
<td style="text-align:right;">
0.053
</td>
<td style="text-align:right;">
0.133
</td>
<td style="text-align:right;">
0.045
</td>
<td style="text-align:right;">
0.046
</td>
<td style="text-align:right;">
0.048
</td>
<td style="text-align:right;">
0.125
</td>
</tr>
<tr>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
0.05
</td>
<td style="text-align:right;">
0.05
</td>
<td style="text-align:right;">
0.056
</td>
<td style="text-align:right;">
0.093
</td>
<td style="text-align:right;">
0.045
</td>
<td style="text-align:right;">
0.046
</td>
<td style="text-align:right;">
0.054
</td>
<td style="text-align:right;">
0.086
</td>
</tr>
<tr>
<td style="text-align:right;">
10
</td>
<td style="text-align:right;">
0.05
</td>
<td style="text-align:right;">
0.05
</td>
<td style="text-align:right;">
0.068
</td>
<td style="text-align:right;">
0.051
</td>
<td style="text-align:right;">
0.045
</td>
<td style="text-align:right;">
0.046
</td>
<td style="text-align:right;">
0.066
</td>
<td style="text-align:right;">
0.049
</td>
</tr>
</tbody>
</table>
</div>
<div id="conditional-type-i-error" class="section level3">
<h3>Conditional Type I error</h3>
<pre class="r"><code>plot_prob_t1_2(res, ycol=&quot;lm&quot;, two_d=TRUE)</code></pre>
<div class="figure"><span id="fig:unnamed-chunk-8"></span>
<img src="/quasipub/normalization-inflates-type-i-error_files/figure-html/unnamed-chunk-8-1.png" alt="p-values from linear model with Gapdh as covariate. The graphs are the same for all values of blots, but are shown for easy comparison with norm2 and norm3" width="672" />
<p class="caption">
Figure 5: p-values from linear model with Gapdh as covariate. The graphs are the same for all values of blots, but are shown for easy comparison with norm2 and norm3
</p>
</div>
<pre class="r"><code>plot_prob_t1_2(res, ycol=&quot;norm1&quot;, two_d=TRUE)</code></pre>
<div class="figure"><span id="fig:unnamed-chunk-9"></span>
<img src="/quasipub/normalization-inflates-type-i-error_files/figure-html/unnamed-chunk-9-1.png" alt="p-values from t-test of norm1. The graphs are the same for all values of blots, but are shown for easy comparison with norm2 and norm3" width="672" />
<p class="caption">
Figure 6: p-values from t-test of norm1. The graphs are the same for all values of blots, but are shown for easy comparison with norm2 and norm3
</p>
</div>
<pre class="r"><code>plot_prob_t1_2(res, ycol=&quot;norm2&quot;, two_d=TRUE)</code></pre>
<div class="figure"><span id="fig:unnamed-chunk-10"></span>
<img src="/quasipub/normalization-inflates-type-i-error_files/figure-html/unnamed-chunk-10-1.png" alt="p-values from t-test of norm2" width="672" />
<p class="caption">
Figure 7: p-values from t-test of norm2
</p>
</div>
<pre class="r"><code>plot_prob_t1_2(res, ycol=&quot;norm3&quot;, two_d=TRUE)</code></pre>
<div class="figure"><span id="fig:unnamed-chunk-11"></span>
<img src="/quasipub/normalization-inflates-type-i-error_files/figure-html/unnamed-chunk-11-1.png" alt="p-values from t-test of norm3" width="672" />
<p class="caption">
Figure 8: p-values from t-test of norm3
</p>
</div>
<p>The general pattern is the same for <span class="math inline">\(n=10\)</span> as for <span class="math inline">\(n=4\)</span> and summarized above in <a href="#summary-of-simulation-results-for-n4">Summary of simulation results for n=4</a></p>
</div>
</div>
</div>
<div id="other-literature" class="section level1">
<h1>Other literature</h1>
<p>I wouldn’t think this is news but I’m not familiar with the literature. Google Scholaring found mostly normalization in microarray/RNAseq type stuff and much of this is concerned with different issues. There is abundant literature on normalizing for body weight in organismal physiology and adjusting for baseline in pre-post designs, but there doesn’t seem to be much acknowledgment within experimental biology of regression to the mean due to normalizing measures like band intensity. I did find this,</p>
<p>Janušonis, S., 2009. Comparing two small samples with an unstable, treatment-independent baseline. Journal of neuroscience methods, 179(2), pp.173-178.</p>
<p>which doesn’t discuss regression to the mean and inflated conditional type I error even though it cites some of this literature.</p>
</div>
