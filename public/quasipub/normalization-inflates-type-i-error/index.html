<!DOCTYPE html>
<html lang="en-us">
  <head>
    
    <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="generator" content="Hugo 0.54.0 with theme Tranquilpeak 0.4.3-SNAPSHOT">
<meta name="author" content="R doodles. Some ecology. Some physiology. Much fake data.">
<meta name="keywords" content="">
<meta name="description" content="Summary Fig 1C of the Replication Study: Melanoma exosomes educate bone marrow progenitor cells toward a pro-metastatic phenotype through MET uses an odd (to me) three stage normalization procedure for the quantified western blots. The authors compared blot values of a treatment (Met or pMet) to a control (shScr) using GAPDH to normalize the values. The three stages of the normalization are
first, the value for the Antibody levels were normalized by the value of a reference (GAPDH) for each Set.">


<meta property="og:description" content="Summary Fig 1C of the Replication Study: Melanoma exosomes educate bone marrow progenitor cells toward a pro-metastatic phenotype through MET uses an odd (to me) three stage normalization procedure for the quantified western blots. The authors compared blot values of a treatment (Met or pMet) to a control (shScr) using GAPDH to normalize the values. The three stages of the normalization are
first, the value for the Antibody levels were normalized by the value of a reference (GAPDH) for each Set.">
<meta property="og:type" content="article">
<meta property="og:title" content="Normalization Inflates Type I error: A Simulation Motivated by Replication Study: Melanoma exosomes educate bone marrow progenitor cells toward a pro-metastatic phenotype through MET">
<meta name="twitter:title" content="Normalization Inflates Type I error: A Simulation Motivated by Replication Study: Melanoma exosomes educate bone marrow progenitor cells toward a pro-metastatic phenotype through MET">
<meta property="og:url" content="/quasipub/normalization-inflates-type-i-error/">
<meta property="twitter:url" content="/quasipub/normalization-inflates-type-i-error/">
<meta property="og:site_name" content="R Doodles">
<meta property="og:description" content="Summary Fig 1C of the Replication Study: Melanoma exosomes educate bone marrow progenitor cells toward a pro-metastatic phenotype through MET uses an odd (to me) three stage normalization procedure for the quantified western blots. The authors compared blot values of a treatment (Met or pMet) to a control (shScr) using GAPDH to normalize the values. The three stages of the normalization are
first, the value for the Antibody levels were normalized by the value of a reference (GAPDH) for each Set.">
<meta name="twitter:description" content="Summary Fig 1C of the Replication Study: Melanoma exosomes educate bone marrow progenitor cells toward a pro-metastatic phenotype through MET uses an odd (to me) three stage normalization procedure for the quantified western blots. The authors compared blot values of a treatment (Met or pMet) to a control (shScr) using GAPDH to normalize the values. The three stages of the normalization are
first, the value for the Antibody levels were normalized by the value of a reference (GAPDH) for each Set.">
<meta property="og:locale" content="en-us">

  
  
  
  
  


<meta name="twitter:card" content="summary">

  <meta name="twitter:site" content="@jwalkrunski">


  <meta name="twitter:creator" content="@jwalkrunski">










  <meta property="og:image" content="https://www.gravatar.com/avatar/7bbef046c3aca6a4dce979b577e3e165?s=640">
  <meta property="twitter:image" content="https://www.gravatar.com/avatar/7bbef046c3aca6a4dce979b577e3e165?s=640">


    <title>Normalization Inflates Type I error: A Simulation Motivated by Replication Study: Melanoma exosomes educate bone marrow progenitor cells toward a pro-metastatic phenotype through MET</title>

    <link rel="icon" href="/favicon.png">
    

    

    <link rel="canonical" href="/quasipub/normalization-inflates-type-i-error/">

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.min.css" integrity="sha256-vuXZ9LGmmwtjqFX1F+EKin1ThZMub58gKULUyf0qECk=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.css" integrity="sha256-SEa4XYAHihTcEP1f5gARTB2K26Uk8PsndQYHQC1f4jU=" crossorigin="anonymous" />
    
    
    <link rel="stylesheet" href="/css/style-nnm2spxvve8onlujjlegkkytaehyadd4ksxc1hyzzq9a2wvtrgbljqyulomn.min.css" />
    
    

    
      
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-118821125-2', 'auto');
	
	ga('send', 'pageview');
}
</script>

    
    
  </head>

  <body>
    <div id="blog">
      <header id="header" data-behavior="1">
  <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
  <div class="header-title">
    <a class="header-title-link" href="/">R Doodles</a>
  </div>
  
    
      <a class="header-right-picture "
         href="/#about">
    
    
    
      
        <img class="header-picture" src="https://www.gravatar.com/avatar/7bbef046c3aca6a4dce979b577e3e165?s=90" alt="Author&#39;s picture" />
      
    
    </a>
  
</header>

      <nav id="sidebar" data-behavior="1">
  <div class="sidebar-container">
    
      <div class="sidebar-profile">
        <a href="/#about">
          <img class="sidebar-profile-picture" src="https://www.gravatar.com/avatar/7bbef046c3aca6a4dce979b577e3e165?s=110" alt="Author&#39;s picture" />
        </a>
        <h4 class="sidebar-profile-name">R doodles. Some ecology. Some physiology. Much fake data.</h4>
        
          <h5 class="sidebar-profile-bio">Thoughts on R, statistical best practices, and teaching applied statistics to Biology majors.</h5>
        
      </div>
    
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/">
    
      <i class="sidebar-button-icon fa fa-lg fa-home"></i>
      
      <span class="sidebar-button-desc">Home</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/categories">
    
      <i class="sidebar-button-icon fa fa-lg fa-bookmark"></i>
      
      <span class="sidebar-button-desc">Categories</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/tags">
    
      <i class="sidebar-button-icon fa fa-lg fa-tags"></i>
      
      <span class="sidebar-button-desc">Tags</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/archives">
    
      <i class="sidebar-button-icon fa fa-lg fa-archive"></i>
      
      <span class="sidebar-button-desc">Archives</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/#about">
    
      <i class="sidebar-button-icon fa fa-lg fa-question"></i>
      
      <span class="sidebar-button-desc">About</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="//github.com/middleprofessor">
    
      <i class="sidebar-button-icon fa fa-lg fa-github"></i>
      
      <span class="sidebar-button-desc">GitHub</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://stats.stackexchange.com/users/119435/jwalker">
    
      <i class="sidebar-button-icon fa fa-lg fa-stack-exchange"></i>
      
      <span class="sidebar-button-desc">CrossValidated</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://scholar.google.com/citations?user=W58TmakAAAAJ&amp;hl">
    
      <i class="sidebar-button-icon fa fa-lg fa-google"></i>
      
      <span class="sidebar-button-desc">Google Scholar</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://www.researchgate.net/profile/Jeffrey_Walker4/contributions">
    
      <i class="sidebar-button-icon fa fa-lg fa-archive"></i>
      
      <span class="sidebar-button-desc">Research Gate</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://www.middleprofessor.com">
    
      <i class="sidebar-button-icon fa fa-lg fa-university"></i>
      
      <span class="sidebar-button-desc">Research/Teaching</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/index.xml">
    
      <i class="sidebar-button-icon fa fa-lg fa-rss"></i>
      
      <span class="sidebar-button-desc">RSS</span>
    </a>
  </li>


    </ul>
  </div>
</nav>

      

      <div id="main" data-behavior="1"
        class="
               hasCoverMetaIn
               ">
        <article class="post" itemscope itemType="http://schema.org/BlogPosting">
          
          
            <div class="post-header main-content-wrap text-left">
  
    <h1 class="post-title" itemprop="headline">
      Normalization Inflates Type I error: A Simulation Motivated by Replication Study: Melanoma exosomes educate bone marrow progenitor cells toward a pro-metastatic phenotype through MET
    </h1>
  
  
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="0001-01-01T00:00:00Z">
        
  January 1, 1

      </time>
    
    
  </div>

</div>
          
          <div class="post-content markdown" itemprop="articleBody">
            <div class="main-content-wrap">
              
<script src="/rmarkdown-libs/kePrint/kePrint.js"></script>


<div id="summary" class="section level1">
<h1>Summary</h1>
<p>Fig 1C of the <a href="https://elifesciences.org/articles/39944">Replication Study: Melanoma exosomes educate bone marrow progenitor cells toward a pro-metastatic phenotype through MET</a> uses an odd (to me) three stage normalization procedure for the quantified western blots. The authors compared blot values of a treatment (Met or pMet) to a control (shScr) using GAPDH to normalize the values. The three stages of the normalization are</p>
<ol style="list-style-type: decimal">
<li>first, the value for the Antibody levels were normalized by the value of a reference (GAPDH) for each Set. This is the typical normalization throughout bench biology.</li>
<li>second, the GAPDH-normalized values were rescaled by the mean of the GAPDH-normalized values for the shScr Condition within each combination of Antibody+Type+Blot. And,</li>
<li>third, <em>all</em> values in the shScr group were assigned to 1 (since the mean within the Condition level is 1). The statistical test then is a one-sample t-test of shMet with <span class="math inline">\(\mu=1\)</span>.</li>
</ol>
<p>As shown in the simulation below and summarized in the section <a href="#summary-of-simulation-results-for-n4">Summary of simulation results for n=4</a>, Stage 1 can introduce inflated <em>conditional</em> type I error due to regression to the mean while stage 2 and 3 renormalizations introduce inflated marginal (or unconditional) type I error.</p>
</div>
<div id="conditional-v-marginal-type-i-error" class="section level1">
<h1>Conditional v marginal type I error</h1>
<p>Normalizing a value using a reference, such as GAPDH, is used to increase the precision of a treatment effect by removing the noise in band intensity due to non-biological sources of variation. The reference value (intensity) is the proxy for this variation and the treatment or control values are expected to go up and down (that is have a positive correlation) with this reference. Normalizing by a reference value assumes that the correlation between reference values and either control or treatment values is 1.0 – that is they are precisely similarly effected by the non-biological sources of variation. At any correlation less that 1.0, there will be some consequence of <a href="https://www.middleprofessor.com/files/quasipubs/change_scores.html">regression to the mean</a> due to the vicissitudes of sampling. This consequence is largest when the true correlation between reference values and control/treatment values is zero.</p>
<p>The consequences of regression to the mean on type I error can be shown by plotting the probability of type I error against the observed difference in the reference value between treatment and control, which I’ll refer to as <span class="math inline">\(\Delta Gapdh\)</span> since GAPDH is the reference in the focal study. An increase in the probability of type I error as the magnitude of <span class="math inline">\(\Delta Gapdh\)</span> increases is the result of regression to the mean – an experiment with a larger <span class="math inline">\(\Delta Gapdh\)</span> is more likely to result in a larger observed treatment effect, when no true treatment effect exists, and therefore more likely to result in small <em>p</em>-values and inflated type I error.</p>
<p>The type I error as a function of the magnitude of <span class="math inline">\(\Delta Gapdh\)</span> is the <strong>conditional type I error</strong> because it is conditional on <span class="math inline">\(\Delta Gapdh\)</span>. I refer to the type I error taken over all values of <span class="math inline">\(\Delta Gapdh\)</span> as the <strong>marginal type I error</strong>. The marginal type I error is the type I error that we usually talk about (because we usually don’t think of it as being conditioned on some covariate)</p>
</div>
<div id="fig-1c" class="section level1">
<h1>Fig 1C</h1>
<pre class="r"><code>folder &lt;- &quot;Data from Generation and characterization of shMet B16-F10 cells and exosomes&quot;
filename &lt;- &quot;Study_42_Figure_1_WB_quant_Data.csv&quot;
file_path &lt;- here(data_path, folder, filename)
exp1 &lt;- fread(file_path)
exp1[, Condition := factor(Condition, c(&quot;shScr&quot;, &quot;shMet&quot;))]
#View(exp1)</code></pre>
<p>The Met and pMet values in Fig 1C are normalized using a three-step procedure (each its own kind of normalization).</p>
<ol style="list-style-type: decimal">
<li>norm1 is the conventional normalization using the reference (GAPDH) value.</li>
<li>norm2 is norm1 rescaled by the mean of shScr.</li>
<li>norm3 is setting all rescaled values of shScr to equal 1.</li>
</ol>
<pre class="r"><code># get GAPDH ref for each row to rescale (&quot;normalize&quot;) by GAPDH
gapdh_ref.dt &lt;- exp1[Antibody==&quot;Gapdh&quot;, .(gapdh_ref=mean(Value)), by=Set]
exp1.v1 &lt;- merge(exp1, gapdh_ref.dt, by=&quot;Set&quot;)
exp1.v1[, norm1:=Value/gapdh_ref]

# get mean shScr for each Antibody:Type:Blot to rescale by mean shScr 
shScr_ref.dt &lt;- exp1.v1[Condition==&quot;shScr&quot;, .(shScr_ref=mean(norm1)), by=.(Antibody, Type, Blot)]
exp1.v1 &lt;- merge(exp1.v1, shScr_ref.dt, by=c(&quot;Antibody&quot;, &quot;Type&quot;, &quot;Blot&quot;))
exp1.v1[, norm2:=norm1/shScr_ref]
exp1.v1[, norm3:=ifelse(Condition==&quot;shScr&quot;, 1, norm2)]
#View(exp1.v1)

gg1 &lt;- ggbarplot(data=exp1.v1[Antibody==&quot;Met&quot; &amp; Type==&quot;Cells&quot;], 
                 x=&quot;Condition&quot;, 
                 y=&quot;norm1&quot;,
          add=c(&quot;mean_se&quot;)) +
  ylab(&quot;Met&quot;) +
  NULL
gg2 &lt;- ggbarplot(data=exp1.v1[Antibody==&quot;pMet&quot; &amp; Type==&quot;Cells&quot;,],
                 x=&quot;Condition&quot;, 
                 y=&quot;norm1&quot;,
                 add=c(&quot;mean_se&quot;)) +
  ylab(&quot;pMet&quot;) +
  NULL

gg3 &lt;- ggbarplot(data=exp1.v1[Antibody==&quot;Met&quot; &amp; Type==&quot;Cells&quot;], 
                 x=&quot;Condition&quot;, 
                 y=&quot;norm3&quot;,
          add=c(&quot;mean_se&quot;)) +
  ylab(&quot;Met&quot;) +
  NULL
gg4 &lt;- ggbarplot(data=exp1.v1[Antibody==&quot;pMet&quot; &amp; Type==&quot;Cells&quot;,],
                 x=&quot;Condition&quot;, 
                 y=&quot;norm3&quot;,
                 add=c(&quot;mean_se&quot;)) +
  ylab(&quot;pMet&quot;) +
  NULL

plot_grid(gg1, gg2, gg3, gg4, nrow=2)</code></pre>
<p><img src="/quasipub/normalization-inflates-type-i-error_files/figure-html/reproducibility-1.png" width="672" /></p>
<p>The two bottom plots reproduce Fig 1C from the paper, which uses norm3. The two top plots are scaled by GAPDH but not shScr (norm1).</p>
<div id="plots-of-the-data" class="section level2">
<h2>Plots of the data</h2>
<pre class="r"><code>gg1 &lt;- ggstripchart(data=exp1.v1[Antibody==&quot;Met&quot; &amp; Type==&quot;Cells&quot;], 
                 x=&quot;Condition&quot;, 
                 y=&quot;Value&quot;,
          add=c(&quot;mean_se&quot;)) +
  ylab(&quot;Met&quot;) +
  theme_minimal() +
  NULL
gg2 &lt;- ggstripchart(data=exp1.v1[Antibody==&quot;pMet&quot; &amp; Type==&quot;Cells&quot;,],
                 x=&quot;Condition&quot;, 
                 y=&quot;Value&quot;,
                 add=c(&quot;mean_se&quot;)) +
  ylab(&quot;pMet&quot;) +
  theme_minimal() +
  NULL
gg3 &lt;- ggplot(data=exp1.v1[Antibody==&quot;Met&quot; &amp; Type==&quot;Cells&quot;], 
              aes(x=gapdh_ref/10^3, y=Value, color=Condition)) +
  geom_point() +
  ylab(&quot;Met&quot;) +
  xlab(expression(paste(Gapdh, &quot; (X&quot;, 10^{-3}, &quot;)&quot;))) +
  theme_minimal() +
  NULL
gg4 &lt;- ggplot(data=exp1.v1[Antibody==&quot;pMet&quot; &amp; Type==&quot;Cells&quot;],
              aes(x=gapdh_ref/10^3, y=Value, color=Condition)) +
  geom_point() +
  ylab(&quot;pMet&quot;) +
  xlab(expression(paste(Gapdh, &quot; (X&quot;, 10^{-3}, &quot;)&quot;))) +
  theme_minimal() +
  NULL
plot_grid(gg1, gg2, gg3, gg4, nrow=2)</code></pre>
<p><img src="/quasipub/normalization-inflates-type-i-error_files/figure-html/stripchart-1.png" width="672" /></p>
<p>We might infer from the top plots that the shMet condition decreases Met and pMet but the p-values from a t-test for these are 0.098 and 0.208 (see below) (note here and throughout, I use simple linear models and t-tests to compute p-values even though I would probably fit generalized linear models were I to analyze these data. For comparison, the Wilcoxan p-values are 0.1 and 0.34). The bottom plots suggest trivial correlations between GAPDH and either shScr or shMet, although the sample size for this is extremely small (see below for computations of various attempts to estimate this correlation).</p>
</div>
<div id="what-are-the-consequences-of-normalization-compare-to-linear-model-with-gapdh-as-covariate" class="section level2">
<h2>What are the consequences of normalization? Compare to linear model with Gapdh as covariate</h2>
<p>Here I compare p-values of t-tests of the three different normalizations, with a t-test of the raw (non-normalized) values and with a linear model (“lm”) with <span class="math inline">\(Gapdh\)</span> as a covariate, which is the preferred method of adjusting for nuissance co-variation.</p>
<div id="met" class="section level3">
<h3>Met</h3>
<pre class="r"><code>prob &lt;- numeric(5) # p-values for all five ways of analyzing data
# linear model with ref as covariate
m1 &lt;- lm(Value ~ gapdh_ref + Condition, data=exp1.v1[Antibody==&quot;Met&quot; &amp; Type==&quot;Cells&quot;])
# linear model with no accounting for ref
m2 &lt;- lm(Value ~ Condition, data=exp1.v1[Antibody==&quot;Met&quot; &amp; Type==&quot;Cells&quot;])
# linear model using Gapdh normalized values
m3 &lt;- lm(norm1 ~ Condition, data=exp1.v1[Antibody==&quot;Met&quot; &amp; Type==&quot;Cells&quot;])
# linear model using Gapdh normalized rescaled to shScr values
m4 &lt;- lm(norm2 ~ Condition, data=exp1.v1[Antibody==&quot;Met&quot; &amp; Type==&quot;Cells&quot;])

prob[1] &lt;- coef(summary(m1))[&quot;ConditionshMet&quot;, &quot;Pr(&gt;|t|)&quot;]
prob[2] &lt;- coef(summary(m2))[&quot;ConditionshMet&quot;, &quot;Pr(&gt;|t|)&quot;]
prob[3] &lt;- coef(summary(m3))[&quot;ConditionshMet&quot;, &quot;Pr(&gt;|t|)&quot;]
prob[4] &lt;- coef(summary(m4))[&quot;ConditionshMet&quot;, &quot;Pr(&gt;|t|)&quot;]
prob[5] &lt;- t.test(x=exp1.v1[Antibody==&quot;Met&quot; &amp;
                              Type==&quot;Cells&quot; &amp;
                              Condition == &quot;shMet&quot;, norm3],
                  mu=1)$p.value
prob6 &lt;- wilcox.test(x=exp1.v1[Antibody==&quot;Met&quot; &amp;
                                 Type==&quot;Cells&quot; &amp;
                                 Condition == &quot;shMet&quot;, Value],
                     y=exp1.v1[Antibody==&quot;Met&quot; &amp;
                                 Type==&quot;Cells&quot; &amp;
                                 Condition == &quot;shScr&quot;, Value])
knitr::kable(data.table(Method=c(&quot;lm&quot;, &quot;none&quot;, &quot;norm1&quot;, &quot;norm2&quot;, &quot;norm3&quot;),
             &quot;p-value&quot; = prob), digits = 3,
             caption = &quot;P-values for Met&quot;)</code></pre>
<table>
<caption><span id="tab:covariate-v-normalization-met">Table 1: </span>P-values for Met</caption>
<thead>
<tr class="header">
<th align="left">Method</th>
<th align="right">p-value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">lm</td>
<td align="right">0.191</td>
</tr>
<tr class="even">
<td align="left">none</td>
<td align="right">0.098</td>
</tr>
<tr class="odd">
<td align="left">norm1</td>
<td align="right">0.128</td>
</tr>
<tr class="even">
<td align="left">norm2</td>
<td align="right">0.079</td>
</tr>
<tr class="odd">
<td align="left">norm3</td>
<td align="right">0.014</td>
</tr>
</tbody>
</table>
</div>
<div id="pmet" class="section level3">
<h3>pMet</h3>
<pre class="r"><code>prob &lt;- numeric(5) # p-values for all five ways of analyzing data
# linear model with ref as covariate
m1 &lt;- lm(Value ~ gapdh_ref + Condition, data=exp1.v1[Antibody==&quot;pMet&quot; &amp; Type==&quot;Cells&quot;])
# linear model with no accounting for ref
m2 &lt;- lm(Value ~ Condition, data=exp1.v1[Antibody==&quot;pMet&quot; &amp; Type==&quot;Cells&quot;])
# linear model using Gapdh normalized values
m3 &lt;- lm(norm1 ~ Condition, data=exp1.v1[Antibody==&quot;pMet&quot; &amp; Type==&quot;Cells&quot;])
# linear model using Gapdh normalized rescaled to shScr values
m4 &lt;- lm(norm2 ~ Condition, data=exp1.v1[Antibody==&quot;pMet&quot; &amp; Type==&quot;Cells&quot;])

prob[1] &lt;- coef(summary(m1))[&quot;ConditionshMet&quot;, &quot;Pr(&gt;|t|)&quot;]
prob[2] &lt;- coef(summary(m2))[&quot;ConditionshMet&quot;, &quot;Pr(&gt;|t|)&quot;]
prob[3] &lt;- coef(summary(m3))[&quot;ConditionshMet&quot;, &quot;Pr(&gt;|t|)&quot;]
prob[4] &lt;- coef(summary(m4))[&quot;ConditionshMet&quot;, &quot;Pr(&gt;|t|)&quot;]
prob[5] &lt;- t.test(x=exp1.v1[Antibody==&quot;pMet&quot; &amp;
                              Type==&quot;Cells&quot; &amp;
                              Condition == &quot;shMet&quot;, norm3],
                  mu=1)$p.value
prob6 &lt;- wilcox.test(x=exp1.v1[Antibody==&quot;pMet&quot; &amp;
                                 Type==&quot;Cells&quot; &amp;
                                 Condition == &quot;shMet&quot;, Value],
                     y=exp1.v1[Antibody==&quot;pMet&quot; &amp;
                                 Type==&quot;Cells&quot; &amp;
                                 Condition == &quot;shScr&quot;, Value])

knitr::kable(data.table(Method=c(&quot;lm&quot;, &quot;none&quot;, &quot;norm1&quot;, &quot;norm2&quot;, &quot;norm3&quot;),
             &quot;p-value&quot; = prob), digits = 3,
             caption = &quot;P-values for pMet&quot;)</code></pre>
<table>
<caption><span id="tab:covariate-v-normalization-pmet-1">Table 2: </span>P-values for pMet</caption>
<thead>
<tr class="header">
<th align="left">Method</th>
<th align="right">p-value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">lm</td>
<td align="right">0.254</td>
</tr>
<tr class="even">
<td align="left">none</td>
<td align="right">0.208</td>
</tr>
<tr class="odd">
<td align="left">norm1</td>
<td align="right">0.227</td>
</tr>
<tr class="even">
<td align="left">norm2</td>
<td align="right">0.000</td>
</tr>
<tr class="odd">
<td align="left">norm3</td>
<td align="right">0.003</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div id="simulations" class="section level1">
<h1>Simulations</h1>
<p>Here I simulate the experiment in Fig 1 C of the paper. Effectively, this simulates an experiment with one control level, one treatment level, and a sample size of 4 (per level). Control and treatment levels are adjusted using a reference level (simulating GAPDH). The adjustments are 1) lm (linear model with <span class="math inline">\(Gapdh\)</span> has covariate), 2) norm1 (the ratio of the control or treatment level divided by <span class="math inline">\(Gapdh\)</span> level), 3) norm2 (norm1 rescaled to the control mean) and 4) norm3, equivalent to norm2 but the values for control are set to equal one.</p>
<div id="what-is-correlation-between-gapdh-and-control-or-treatment" class="section level2">
<h2>What is correlation between gapdh and control or treatment?</h2>
<p>As described above, normalization assumes a correlation of 1.0 between the reference and focal values. Here I compute multiple estimates of the true correlation between the reference values and the conditional response (conditioned on treatment level) in the whole data set and different subgroups. The true correlation is estimated with large error, because of the small sample size, so the estimates here are very uncertain. Nevertheless, the different estimates are pretty consistent that this correlation is very small. Regardless, Keep these values in mind.</p>
<pre class="r"><code>r &lt;- numeric(5)
dataset &lt;- rep(&quot;&quot;, 5)
fit &lt;- lm(Value ~ Condition + Type + Antibody,
          data=exp1.v1[Antibody!=&quot;Gapdh&quot;])
r[1] &lt;- cor(residuals(fit), exp1.v1[Antibody!=&quot;Gapdh&quot;, gapdh_ref])
dataset[1] &lt;- &quot;whole dataset&quot;
  
fit &lt;- lm(Value ~ Condition + Antibody,
          data=exp1.v1[Antibody!=&quot;Gapdh&quot; &amp; Type==&quot;Cells&quot;])
r[2] &lt;- cor(residuals(fit), exp1.v1[Antibody!=&quot;Gapdh&quot; &amp; Type==&quot;Cells&quot;, gapdh_ref])
dataset[2] &lt;- &quot;subset of Type=Cells&quot;

fit &lt;- lm(Value ~ Condition + Type, data=exp1.v1[Antibody==&quot;Met&quot;])
r[3] &lt;- cor(residuals(fit), exp1.v1[Antibody==&quot;Met&quot;, gapdh_ref])
dataset[3] &lt;- &quot;subset of Antibody=Met&quot;

fit &lt;- lm(Value ~ Condition, data=exp1.v1[Antibody==&quot;Met&quot; &amp; Type==&quot;Cells&quot;])
r[4] &lt;- cor(residuals(fit), exp1.v1[Antibody==&quot;Met&quot; &amp; Type==&quot;Cells&quot;, gapdh_ref])
dataset[4] &lt;- &quot;subset of Antibody=Met and Type=Cells&quot;

fit &lt;- lm(Value ~ Condition, data=exp1.v1[Antibody==&quot;pMet&quot;])
r[5] &lt;- cor(residuals(fit), exp1.v1[Antibody==&quot;pMet&quot;, gapdh_ref])
dataset[5] &lt;- &quot;subset of Antibody=pMet (all Type=Cells)&quot;

knitr::kable(data.table(Dataset=dataset, Cor=r), digits=3)</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">Dataset</th>
<th align="right">Cor</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">whole dataset</td>
<td align="right">0.027</td>
</tr>
<tr class="even">
<td align="left">subset of Type=Cells</td>
<td align="right">0.068</td>
</tr>
<tr class="odd">
<td align="left">subset of Antibody=Met</td>
<td align="right">-0.020</td>
</tr>
<tr class="even">
<td align="left">subset of Antibody=Met and Type=Cells</td>
<td align="right">-0.153</td>
</tr>
<tr class="odd">
<td align="left">subset of Antibody=pMet (all Type=Cells)</td>
<td align="right">0.027</td>
</tr>
</tbody>
</table>
</div>
<div id="how-are-the-experiments-structured" class="section level2">
<h2>How are the experiments structured?</h2>
<pre class="r"><code>exp1[Antibody==&quot;Met&quot; &amp; Type==&quot;Cells&quot;, .(N=.N), by=.(Antibody, Type, Blot, Condition)]</code></pre>
<pre><code>##    Antibody  Type                  Blot Condition N
## 1:      Met Cells https://osf.io/e3dny/     shScr 1
## 2:      Met Cells https://osf.io/e3dny/     shMet 1
## 3:      Met Cells https://osf.io/nra32/     shMet 2
## 4:      Met Cells https://osf.io/nra32/     shScr 2</code></pre>
<pre class="r"><code>exp1[Antibody==&quot;pMet&quot; &amp; Type==&quot;Cells&quot;, .(N=.N), by=.(Antibody, Type, Blot, Condition)]</code></pre>
<pre><code>##    Antibody  Type                  Blot Condition N
## 1:     pMet Cells https://osf.io/bnxht/     shScr 1
## 2:     pMet Cells https://osf.io/bnxht/     shMet 1
## 3:     pMet Cells https://osf.io/nra32/     shMet 2
## 4:     pMet Cells https://osf.io/nra32/     shScr 2
## 5:     pMet Cells https://osf.io/dg4kx/     shScr 1
## 6:     pMet Cells https://osf.io/dg4kx/     shMet 1</code></pre>
<p>Met data: one replicate in one blot and two replicates in one blot for the Met data (so n=3);</p>
<p>pMet data: one replicate in two blots and two replicates in one blots (so n=4).</p>
</div>
<div id="simulation-functions" class="section level2">
<h2>Simulation functions</h2>
<p>The functions for generating a data set with a control, a treatment, and a reference for normalization. norm1, norm2, and norm3 are defined as above. The parameter rho controls the expected correlation between the reference and either the control or treatment. The explored values are (0, 0.3, 0.6). Note the empirical estimates of rho are close to zero.</p>
<pre class="r"><code>get_fake_data &lt;- function(
  n=4, # number of replicates per treatment level
  rho=0.5, # correlation between the reference value and that of a control level
  s_kappa=1, # effect of treatment on shape (this is multiplicative so 1 = no effect)
  s_theta=1, # effect of treatment on scale (this is multiplicative so 1 = no effect
  kappa_0=80, # shape parameter for reference
  theta_0=100, # scale parameter for reference
  kappa_1=30, # shape parameter for control
  theta_1=100 # scale parameter for control
){
  kappa_1_i &lt;- rep(c(kappa_1, kappa_1*s_kappa), each=n)
  theta_1_i &lt;- rep(c(theta_1, theta_1*s_theta), each=n)
  y1 &lt;- rgamma(n*2, shape=kappa_0 - rho*sqrt(kappa_0*kappa_1), scale=1)
  y2 &lt;- rgamma(n*2, shape=kappa_1_i - rho*sqrt(kappa_0*kappa_1_i), scale=1)
  y3 &lt;- rgamma(n*2, shape=rho*sqrt(kappa_0*kappa_1), scale=1)
  fd &lt;- data.table(
    treatment=rep(c(&quot;cn&quot;, &quot;tr&quot;), each=n),
    gapdh=theta_0*(y1+y3),
    value=theta_1_i*(y2+y3)
  )
  return(fd)
}

simulate_experiment &lt;- function(
  n=4, # number of replicates per treatment level
  blot_id=rep(&quot;blot1&quot;, n), # how to divy up the n samples among blots
  rho=0.5, # correlation between the reference value and that of a control level
  s_kappa=1, # effect of treatment on shape (this is multiplicative so 1 = no effect)
  s_theta=1, # effect of treatment on scale (this is multiplicative so 1 = no effect
  kappa_0=80, # shape parameter for reference
  theta_0=100, # scale parameter for reference
  kappa_1=30, # shape parameter for control
  theta_1=100 # scale parameter for control
){
  fd &lt;- get_fake_data(n, rho, s_kappa, s_theta, 
                      kappa_0, theta_0, kappa_1, theta_1)
  fd[, blot:=rep(blot_id, 2)]
  fd[, norm1:=value/gapdh]
  cn_ref_list &lt;- fd[treatment==&quot;cn&quot;, .(cn_ref=mean(norm1)), by=blot]
  fd &lt;- merge(fd, cn_ref_list, by=&quot;blot&quot;)
  fd[, norm2:=norm1/cn_ref]
  fd[, norm3:=ifelse(treatment==&quot;cn&quot;, 1, norm2)]
  return(fd)
}

iterate_experiment &lt;- function(
  n=4, # number of replicates per treatment level
  blot_id=rep(&quot;blot1&quot;, n), # how to divy up the n samples among blots
  niter=2000, # number of iterations
  rho=0.5, # correlation between the reference value and that of a control level
  s_kappa=1, # effect of treatment on shape (this is multiplicative so 1 = no effect)
  s_theta=1, # effect of treatment on scale (this is multiplicative so 1 = no effect
  kappa_0=80, # shape parameter for reference
  theta_0=100, # scale parameter for reference
  kappa_1=30, # shape parameter for control
  theta_1=100 # scale parameter for control
  ){
  # Given a western blot with three &quot;treatments&quot;: reference (Gapdh) is the set of values for normaliztion
  # control is the set of values for a control. The treatment value is determined by beta_1 -- the effect
  prob_cols &lt;- c(&quot;lm&quot;, &quot;norm1&quot;, &quot;norm2&quot;, &quot;norm3&quot;)
  prob &lt;- data.table(matrix(-9999, nrow=niter, ncol=length(prob_cols)))
  setnames(prob, old=colnames(prob), new=prob_cols)
  effect_cols &lt;- c(&quot;delta_gapdh&quot;, &quot;effect_lm&quot;, &quot;effect_norm1&quot;, &quot;effect_norm2&quot;, &quot;effect_norm3&quot;)
  effects_dt &lt;- data.table(matrix(-9999, nrow=niter, ncol=length(effect_cols)))
  setnames(effects_dt, old=colnames(effects_dt), new=effect_cols)
  r &lt;- numeric(niter) # dor between control and gapdh values
  se.norm1 &lt;- numeric(niter) # se.norm1
  set.seed(1) # yes I want to reset this to the same with each combo
  for(iter in 1:niter){
    fd &lt;- simulate_experiment(
      n=n, # number of replicates per treatment level
      blot_id=blot_id, # how to divy up the n samples among blots
      rho=rho, # correlation between the reference value and that of a control level
      s_kappa=s_kappa, # effect of treatment on shape (this is multiplicative so 1 = no effect)
      s_theta=s_theta, # effect of treatment on scale (this is multiplicative so 1 = no effect
      kappa_0=kappa_0, # shape parameter for reference
      theta_0=theta_0, # scale parameter for reference
      kappa_1=kappa_1, # shape parameter for control
      theta_1=theta_1 # scale parameter for control
    )
    m1 &lt;- lm(value ~ gapdh + treatment, data=fd)
    m1.coef &lt;- coef(summary(m1))
    prob[iter, lm := m1.coef[&quot;treatmenttr&quot;, &quot;Pr(&gt;|t|)&quot;]]
    m2 &lt;- lm(norm1 ~ treatment, data=fd)
    m2.coef &lt;- coef(summary(m2))
    prob[iter, norm1 := m2.coef[&quot;treatmenttr&quot;, &quot;Pr(&gt;|t|)&quot;]]
    # prob[iter, norm1 := t.test(fd[treatment==&quot;cn&quot;, norm1], fd[treatment==&quot;tr&quot;, norm1], var.equal=TRUE)$p.value]
    prob[iter, norm2 := t.test(fd[treatment==&quot;cn&quot;, norm2], fd[treatment==&quot;tr&quot;, norm2], var.equal=TRUE)$p.value]
    prob[iter, norm3 := t.test(x=fd[treatment==&quot;tr&quot;, norm3], mu=1)$p.value]
    
    effects_dt[iter, delta_gapdh := mean(fd[treatment==&quot;tr&quot;, gapdh]) - mean(fd[treatment==&quot;cn&quot;, gapdh])]
    effects_dt[iter, effect_lm := m1.coef[&quot;treatmenttr&quot;, &quot;Estimate&quot;]]
    effects_dt[iter, effect_norm1 := m2.coef[&quot;treatmenttr&quot;, &quot;Estimate&quot;]]
    effects_dt[iter, effect_norm2 := mean(fd[treatment==&quot;tr&quot;, norm2]) - mean(fd[treatment==&quot;cn&quot;, norm2])]
    effects_dt[iter, effect_norm3 := mean(fd[treatment==&quot;tr&quot;, norm3]) - 1]
    
    r[iter] &lt;- cor(fd[treatment==&quot;cn&quot;, gapdh], fd[treatment==&quot;cn&quot;, value])
    se.norm1[iter] &lt;- m2.coef[&quot;treatmenttr&quot;, &quot;Std. Error&quot;]
  }
  return(
    data.table(prob, effects_dt, cor=r, se_norm1=se.norm1)
  )
}</code></pre>
<pre class="r"><code>n=10^4 # number of replicates per treatment level
rho=0.5 # correlation between the reference value and that of a control level
s_kappa=1.0 # effect of treatment on shape (this is multiplicative so 1 = no effect)
s_theta=1.0 # effect of treatment on scale (this is multiplicative so 1 = no effect
kappa_0=80 # shape parameter for reference
theta_0=100 # scale parameter for reference
kappa_1=30 # shape parameter for control
theta_1=100 # scale parameter for control
(s_kappa*kappa_1*s_theta*theta_1 - kappa_1*theta_1)/(sqrt(kappa_1*theta_1^2))

  fd &lt;- get_fake_data(n, rho, s_kappa, s_theta, 
                      kappa_0, theta_0, kappa_1, theta_1)
# quick and dirty cohen&#39;s
kappa_1*theta_1
s_kappa*kappa_1*s_theta*theta_1
(means_table &lt;- fd[, .(cell_mean=mean(value), cell_sd=sd(value)), by=treatment])
(means_table[treatment==&quot;tr&quot;, cell_mean] - means_table[treatment==&quot;cn&quot;, cell_mean])/means_table[treatment==&quot;cn&quot;, cell_sd]</code></pre>
</div>
<div id="functions-to-plot-simulation-results" class="section level2">
<h2>functions to plot simulation results</h2>
<pre class="r"><code>plot_effects &lt;- function(res){
  prob_cols &lt;- c(&quot;lm&quot;, &quot;norm1&quot;, &quot;norm2&quot;, &quot;norm3&quot;)
  gg1 &lt;- qplot(x=res$delta_gapdh/10^3, y=res$effect_lm) +
    geom_smooth(method=&quot;lm&quot;) +
    ggtitle(&quot;Linear model&quot;) +
    xlab(expression(paste(Gapdh[t] - Gapdh[c],  &quot;(X 1000)&quot;))) +
    ylab(&quot;Effect&quot;) +
    theme_minimal() +
    NULL
  gg2 &lt;- qplot(x=res$delta_gapdh/10^3, y=res$effect_norm1) +
    geom_smooth(method=&quot;lm&quot;) +
    ggtitle(&quot;Norm1&quot;) +
    xlab(expression(paste(Gapdh[t] - Gapdh[c],  &quot;(X 1000)&quot;))) +
    ylab(&quot;Effect&quot;) +
    theme_minimal() +
    NULL
  gg3 &lt;- qplot(x=res$delta_gapdh/10^3, y=res$effect_norm2) +
    geom_smooth(method=&quot;lm&quot;) +
    ggtitle(&quot;Norm2&quot;) +
    xlab(expression(paste(Gapdh[t] - Gapdh[c],  &quot;(X 1000)&quot;))) +
    ylab(&quot;Effect&quot;) +
    theme_minimal() +
    NULL
  gg4 &lt;- qplot(x=res$delta_gapdh/10^3, y=res$effect_norm3) +
    geom_smooth(method=&quot;lm&quot;) +
    ggtitle(&quot;Norm3&quot;) +
    xlab(expression(paste(Gapdh[t] - Gapdh[c],  &quot;(X 1000)&quot;))) +
    ylab(&quot;Effect&quot;) +
    theme_minimal() +
    NULL
  gg &lt;- plot_grid(gg1, gg2, gg3, gg4, nrow=2)
  return(gg)
}

plot_se &lt;- function(res){
  prob_cols &lt;- c(&quot;lm&quot;, &quot;norm1&quot;, &quot;norm2&quot;, &quot;norm3&quot;)
  blot_levels &lt;- unique(res$blots)
  i &lt;- 1
  gg1 &lt;- qplot(x=res[blots==blot_levels[i], delta_gapdh/10^3], y=res[blots==blot_levels[i], se_norm1]) +
    geom_smooth(method=&quot;lm&quot;) +
    ggtitle(paste(&quot;blots =&quot;, blot_levels[i])) +
    xlab(expression(paste(Gapdh[t] - Gapdh[c],  &quot;(X 1000)&quot;))) +
    ylab(&quot;Effect&quot;) +
    theme_minimal() +
    NULL
  i &lt;- 2
  gg2 &lt;- qplot(x=res[blots==blot_levels[i], delta_gapdh/10^3], y=res[blots==blot_levels[i], se_norm1]) +
    geom_smooth(method=&quot;lm&quot;) +
    ggtitle(paste(&quot;blots =&quot;, blot_levels[i])) +
    xlab(expression(paste(Gapdh[t] - Gapdh[c],  &quot;(X 1000)&quot;))) +
    ylab(&quot;Effect&quot;) +
    theme_minimal() +
    NULL
  i &lt;- 3
  gg3 &lt;- qplot(x=res[blots==blot_levels[i], delta_gapdh/10^3], y=res[blots==blot_levels[i], se_norm1]) +
    geom_smooth(method=&quot;lm&quot;) +
    ggtitle(paste(&quot;blots =&quot;, blot_levels[i])) +
    xlab(expression(paste(Gapdh[t] - Gapdh[c],  &quot;(X 1000)&quot;))) +
    ylab(&quot;Effect&quot;) +
    theme_minimal() +
    NULL
  i &lt;- 4
  gg4 &lt;- qplot(x=res[blots==blot_levels[i], delta_gapdh/10^3], y=res[blots==blot_levels[i], se_norm1]) +
    geom_smooth(method=&quot;lm&quot;) +
    ggtitle(paste(&quot;blots =&quot;, blot_levels[i])) +
    xlab(expression(paste(Gapdh[t] - Gapdh[c],  &quot;(X 1000)&quot;))) +
    ylab(&quot;Effect&quot;) +
    theme_minimal() +
    NULL
  gg &lt;- plot_grid(gg1, gg2, gg3, gg4, nrow=2)
  return(gg)
}

plot_prob_t1 &lt;- function(res){
  res[, t1.lm:=ifelse(lm &lt;= 0.05, 1, 0)]
  res[, t1.norm1:=ifelse(norm1 &lt;= 0.05, 1, 0)]
  res[, t1.norm2:=ifelse(norm2 &lt;= 0.05, 1, 0)]
  res[, t1.norm3:=ifelse(norm3 &lt;= 0.05, 1, 0)]
  gg1 &lt;- ggplot(data=res, aes(x=abs(delta_gapdh), y=t1.lm)) +
    geom_smooth(method=&#39;glm&#39;, method.args=list(family=&#39;binomial&#39;)) +
    ylab(&quot;Prob(Type I): linear model&quot;) +
    xlab(expression(paste(&quot;|&quot;,Gapdh[t] - Gapdh[c],&quot;|&quot;))) +
    theme_minimal()
  gg2 &lt;- ggplot(data=res, aes(x=abs(delta_gapdh), y=t1.norm1)) +
    geom_smooth(method=&#39;glm&#39;, method.args=list(family=&#39;binomial&#39;)) +
    ylab(&quot;Prob(Type I): norm1&quot;) +
    xlab(expression(paste(&quot;|&quot;,Gapdh[t] - Gapdh[c],&quot;|&quot;))) +
    theme_minimal()
  gg3 &lt;- ggplot(data=res, aes(x=abs(delta_gapdh), y=t1.norm2)) +
    geom_smooth(method=&#39;glm&#39;, method.args=list(family=&#39;binomial&#39;)) +
    ylab(&quot;Prob(Type I): norm2&quot;) +
    xlab(expression(paste(&quot;|&quot;,Gapdh[t] - Gapdh[c],&quot;|&quot;))) +
    theme_minimal()
  gg4 &lt;- ggplot(data=res, aes(x=abs(delta_gapdh), y=t1.norm3)) +
    geom_smooth(method=&#39;glm&#39;, method.args=list(family=&#39;binomial&#39;)) +
    ylab(&quot;Prob(Type I): norm3&quot;) +
    xlab(expression(paste(&quot;|&quot;,Gapdh[t] - Gapdh[c],&quot;|&quot;))) +
    theme_minimal()
  gg &lt;- plot_grid(gg1, gg2, gg3, gg4, nrow=2)
  return(gg)
}

plot_prob_t1_2 &lt;- function(res, ycol, two_d=FALSE){
  res[, t1:=ifelse(get(ycol) &lt;= 0.05, 1, 0)]
  gg &lt;- ggplot(data=res, aes(x=abs(delta_gapdh), y=t1)) +
    geom_smooth(method=&#39;glm&#39;, method.args=list(family=&#39;binomial&#39;)) +
    ylab(paste(&quot;Prob(Type I):&quot;, ycol)) +
    xlab(expression(paste(&quot;|&quot;,Gapdh[t] - Gapdh[c],&quot;|&quot;))) +
    geom_hline(aes(yintercept = 0.05), color=&quot;red&quot;) +
    theme_minimal() +
    NULL
  if(two_d==TRUE){
    gg &lt;- gg + facet_grid(blots ~ rho, labeller=label_both)
  }else{
    gg &lt;- gg + facet_grid(. ~ rho, labeller=label_both)
  }
  return(gg)
}</code></pre>
<pre class="r"><code>get_type_1_table &lt;- function(res){
  prob_cols &lt;- c(&quot;lm&quot;,&quot;norm1&quot;, &quot;norm2&quot;,&quot;norm3&quot;)
  niter &lt;- nrow(res)/length(unique(res[, blots]))/length(unique(res[, rho]))
  res_long &lt;- melt(res, id.vars = c(&quot;blots&quot;, &quot;rho&quot;), measure.vars = prob_cols, variable.name = &quot;method&quot;, value.name = &quot;p.value&quot;)
  type_1 &lt;- res_long[, .(Type_I=sum(p.value &lt; 0.05)/niter), by=.(blots, rho, method)]
  type_1_wide &lt;- dcast(type_1, blots ~ method, value.var = &quot;Type_I&quot;)
  return(type_1_wide)
}</code></pre>
</div>
<div id="function-to-run-the-simulation" class="section level2">
<h2>Function to run the simulation</h2>
<p>The simulation computes type I error at all combinations of <span class="math inline">\(blots\)</span> and <span class="math inline">\(rho\)</span>. The parameter <span class="math inline">\(blots\)</span> is the number of unique blots. The number of replicates per blot is n/blots, so with blots=1 there is one blot with four replicates. With n=4 and blots=3, there are 1, 1, and 2 replicates in the three blots, which is the case for pMet in Fig 1C. The parameter <span class="math inline">\(rho\)</span> is the expected correlation between the reference level and either the control or treatment level. Again, the empirical estimate of rho are close to zero. Effects and p-values are computed for 10,000 iterations of each combination of <span class="math inline">\(blots\)</span> and <span class="math inline">\(rho\)</span>. Sample size of <span class="math inline">\(n=4\)</span> (that of the pMet data in the study. The Met data was <span class="math inline">\(n=3\)</span>) and <span class="math inline">\(n=10\)</span> were run.</p>
<pre class="r"><code># parameters
# n=4, # number of replicates per treatment level
# blots=blots_i, # number of blots. Reps/blot = n/blots
# niter=1000, # number of iterations
# rho=0, # correlation between the reference value and that of a control level
# s_kappa=1, # effect of multiplicative treatment on shape
# s_theta=1, # effect of multiplicative treatment on scale
# kappa_0=80, # shape parameter for reference
# theta_0=100, # scale parameter for reference
# kappa_1=30, # shape parameter for control
# theta_1=100 # scale parameter for control
simulate_it &lt;- FALSE
which_sim &lt;- &quot;sim1&quot;
if(which_sim==&quot;sim1&quot;){
  file_path &lt;- here(output_path, &quot;normalization_II_sim1.rds&quot;)
  n_iter &lt;- 10000
  rho_vec &lt;- c(0, 0.3, 0.6) # cor between ref and either cn or tr
  n &lt;- 4
  blots_vec &lt;- c(1, 2, 3, 4) 
  reps_per_blot_mat &lt;- t(matrix(c(c(rep(4, 1), rep(NA, 3)),
                                  c(rep(2, 2), rep(NA, 2)),
                                  c(c(1, 1, 2), rep(NA, 1)),
                                  rep(1, 4)), ncol=4))
}
if(which_sim==&quot;sim2&quot;){
  file_path &lt;- here(output_path, &quot;normalization_II_sim2.rds&quot;)
  n_iter &lt;- 10000
  rho_vec &lt;- c(0, 0.3, 0.6) # cor between ref and either cn or tr
  n &lt;- 10
  blots_vec &lt;- c(1, 2, 5, 10) # number of blots
  
  reps_per_blot_mat &lt;- t(matrix(c(c(rep(10, 1), rep(NA, 9)),
                                  c(rep(5, 2), rep(NA, 8)),
                                  c(rep(2, 5), rep(NA, 5)),
                                  rep(1, 10)), ncol=4))
}
if(simulate_it==TRUE){
  sim_combo &lt;- expand.grid(blots=blots_vec, rho=rho_vec)
  
  blot_id_mat &lt;- data.frame(matrix(nrow=nrow(reps_per_blot_mat), ncol=n))
  for(i in 1:nrow(reps_per_blot_mat)){
    reps_per_blot &lt;- na.omit(reps_per_blot_mat[i,])
    blot_names &lt;- paste0(&quot;blot&quot;, seq_along(reps_per_blot))
    blot_id_mat[i,] &lt;- rep(blot_names, times=reps_per_blot)
  }
  blot_id_mat$blots &lt;- blots_vec
   sim_combo &lt;- data.table(merge(sim_combo, blot_id_mat, by=&quot;blots&quot;))
  blot_id_cols &lt;- paste0(&quot;X&quot;, 1:n)
  
  res &lt;- data.table(NULL)
  for(combo in 1:nrow(sim_combo)){
    blots_i &lt;- sim_combo[combo, blots]
    blot_id_i &lt;- unlist(sim_combo[combo, .SD, .SDcols=blot_id_cols])
    rho_i &lt;- sim_combo[combo, rho]
    res &lt;- rbind(res, 
                 data.table(blots=blots_i,
                            rho=rho_i,
                            iterate_experiment(
                              n=n,
                              blot_id=blot_id_i,
                              niter=n_iter,
                              rho=rho_i,
                              s_kappa=1,
                              s_theta=1,
                              kappa_0=80,
                              theta_0=100,
                              kappa_1=30,
                              theta_1=100
                            )))
    
  }
  saveRDS(res, file = file_path)
}else{
  res &lt;- readRDS(file = file_path)
}</code></pre>
</div>
</div>
<div id="simulation-results" class="section level1">
<h1>Simulation Results</h1>
<div id="results-for-n4-that-of-the-replication-study" class="section level2">
<h2>Results for n=4 (that of the replication study)</h2>
<div id="marginal-type-i-error" class="section level3">
<h3>marginal type I error</h3>
<p>Again, the marginal type I error is just the normal type I error.</p>
<pre class="r"><code>file_path &lt;- here(output_path, &quot;normalization_II_sim1.rds&quot;)
res &lt;- readRDS(file = file_path)

type1_a &lt;- get_type_1_table(res[rho==0])
type1_b &lt;- get_type_1_table(res[rho==0.3])
type1 &lt;- cbind(type1_a, type1_b[, .SD, .SDcols=c(&quot;lm&quot;, &quot;norm1&quot;, &quot;norm2&quot;, &quot;norm3&quot;)])
type1_kable &lt;- knitr::kable(type1, full_width=TRUE, digits=3)
type1_kable &lt;- kableExtra::add_header_above(type1_kable, c(&quot; &quot; = 1, &quot;rho = 0&quot; = 4, &quot;rho = 0.3&quot; = 4))</code></pre>
<pre><code>## Warning in kableExtra::add_header_above(type1_kable, c(` ` = 1, `rho = 0`
## = 4, : Please specify format in kable. kableExtra can customize either HTML
## or LaTeX outputs. See https://haozhu233.github.io/kableExtra/ for details.</code></pre>
<pre class="r"><code>type1_kable</code></pre>
<table>
<thead>
<tr class="header">
<th align="right">blots</th>
<th align="right">lm</th>
<th align="right">norm1</th>
<th align="right">norm2</th>
<th align="right">norm3</th>
<th align="right">lm</th>
<th align="right">norm1</th>
<th align="right">norm2</th>
<th align="right">norm3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">0.052</td>
<td align="right">0.049</td>
<td align="right">0.049</td>
<td align="right">0.117</td>
<td align="right">0.046</td>
<td align="right">0.049</td>
<td align="right">0.049</td>
<td align="right">0.108</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">0.052</td>
<td align="right">0.049</td>
<td align="right">0.060</td>
<td align="right">0.085</td>
<td align="right">0.046</td>
<td align="right">0.049</td>
<td align="right">0.059</td>
<td align="right">0.081</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">0.052</td>
<td align="right">0.049</td>
<td align="right">0.074</td>
<td align="right">0.064</td>
<td align="right">0.046</td>
<td align="right">0.049</td>
<td align="right">0.071</td>
<td align="right">0.062</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">0.052</td>
<td align="right">0.049</td>
<td align="right">0.090</td>
<td align="right">0.049</td>
<td align="right">0.046</td>
<td align="right">0.049</td>
<td align="right">0.089</td>
<td align="right">0.050</td>
</tr>
</tbody>
</table>
<p>The correlation parameter <span class="math inline">\(rho\)</span> doesn’t have much of an effect. Both lm and norm1 have nominal type I error regardless of rho or number of blots. Type I error of norm2 is increasingly inflated as the number of blots increases and the number of replicates/blot decreases. The reverse is the case for type I error of norm3 – type I error is inflated when all replicates are on a single blot. Note that the type I error for lm and norm1 are not a function of how replicates are structured.</p>
</div>
<div id="conditional-type-i-error-on-the-difference-in-gapdh-between-control-and-treatment" class="section level3">
<h3>Conditional type I error (on the difference in GAPDH between control and treatment)</h3>
<pre class="r"><code>plot_prob_t1_2(res, ycol=&quot;lm&quot;, two_d=TRUE)</code></pre>
<div class="figure"><span id="fig:unnamed-chunk-3"></span>
<img src="/quasipub/normalization-inflates-type-i-error_files/figure-html/unnamed-chunk-3-1.png" alt="p-values from linear model with Gapdh as covariate. The graphs are the same for all values of blots, but are shown for easy comparison with norm2 and norm3" width="672" />
<p class="caption">
Figure 1: p-values from linear model with Gapdh as covariate. The graphs are the same for all values of blots, but are shown for easy comparison with norm2 and norm3
</p>
</div>
<pre class="r"><code>plot_prob_t1_2(res, ycol=&quot;norm1&quot;, two_d=TRUE)</code></pre>
<div class="figure"><span id="fig:unnamed-chunk-4"></span>
<img src="/quasipub/normalization-inflates-type-i-error_files/figure-html/unnamed-chunk-4-1.png" alt="p-values from t-test of norm1. The graphs are the same for all values of blots, but are shown for easy comparison with norm2 and norm3" width="672" />
<p class="caption">
Figure 2: p-values from t-test of norm1. The graphs are the same for all values of blots, but are shown for easy comparison with norm2 and norm3
</p>
</div>
<pre class="r"><code>plot_prob_t1_2(res, ycol=&quot;norm2&quot;, two_d=TRUE)</code></pre>
<div class="figure"><span id="fig:unnamed-chunk-5"></span>
<img src="/quasipub/normalization-inflates-type-i-error_files/figure-html/unnamed-chunk-5-1.png" alt="p-values from t-test of norm2" width="672" />
<p class="caption">
Figure 3: p-values from t-test of norm2
</p>
</div>
<pre class="r"><code>plot_prob_t1_2(res, ycol=&quot;norm3&quot;, two_d=TRUE)</code></pre>
<div class="figure"><span id="fig:unnamed-chunk-6"></span>
<img src="/quasipub/normalization-inflates-type-i-error_files/figure-html/unnamed-chunk-6-1.png" alt="p-values from t-test of norm3" width="672" />
<p class="caption">
Figure 4: p-values from t-test of norm3
</p>
</div>
</div>
<div id="summary-of-simulation-results-for-n4" class="section level3">
<h3>Summary of simulation results for n=4</h3>
<p>The plots below show the estimated probability of a Type I error from the simulation and show two different sources of Type I error:</p>
<ol style="list-style-type: decimal">
<li>An increase in Type I error due to the re-normalization (norm 2 and norm3), which is shown by the upward shift of the curve (or, of the intercept) as the number of blots goes to <span class="math inline">\(n\)</span> for norm2 and to 1 for norm3. This is the marginal Type I error.</li>
<li>An increase in increased Type I error associated with increased magnitude of <span class="math inline">\(\Delta Gapdh\)</span>, which is shown by the positive slope of the curve. This is the conditional Type I error.</li>
</ol>
<p>Combined, the simulation shows</p>
<ol style="list-style-type: decimal">
<li><strong>linear model with Gapdh as covariate</strong> Both marginal and conditional type I error is well controlled using the linear model with the reference (GAPDH) as a covariate</li>
<li><strong>norm1</strong> Marginal type I error is well controlled using conventional normalization (norm1) but conditional type I error can be highly inflated as the magnitude of <span class="math inline">\(\Delta Gapdh\)</span> increases and especially when the correlation between the reference and control/treatment values is small.</li>
<li><strong>norm 2</strong> Marginal type I error for norm2 (renormalization using the control) is well controlled when there are many replicates per blot but increases above nominal when the number of replicates per blot decreases to one. Conditional type I error can be highly inflated as the magnitude of <span class="math inline">\(\Delta Gapdh\)</span> increases and especially when the correlation between the reference and control/treatment values is small.</li>
<li><strong>norm 3</strong> Marginal type I error for norm3 (setting control values to 1.0) is well controlled when there is one replicate per blot but increases above nominal when the number of replicates per blot increases. Conditional type I error can be highly inflated as the magnitude of <span class="math inline">\(\Delta Gapdh\)</span> increases and especially when the correlation between the reference and control/treatment values is small.</li>
</ol>
</div>
</div>
<div id="results-for-n10" class="section level2">
<h2>Results for n=10</h2>
<div id="marginal-type-i-error-1" class="section level3">
<h3>marginal type I error</h3>
<pre class="r"><code>file_path &lt;- here(output_path, &quot;normalization_II_sim2.rds&quot;)
res &lt;- readRDS(file = file_path)

type1_a &lt;- get_type_1_table(res[rho==0])
type1_b &lt;- get_type_1_table(res[rho==0.3])
type1 &lt;- cbind(type1_a, type1_b[, .SD, .SDcols=c(&quot;lm&quot;, &quot;norm1&quot;, &quot;norm2&quot;, &quot;norm3&quot;)])
type1_kable &lt;- knitr::kable(type1, full_width=TRUE, digits=3)
type1_kable &lt;- kableExtra::add_header_above(type1_kable, c(&quot; &quot; = 1, &quot;rho = 0&quot; = 4, &quot;rho = 0.3&quot; = 4))
type1_kable</code></pre>
<table>
<thead>
<tr>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="4">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
rho = 0
</div>
</th>
<th style="border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="4">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
rho = 0.3
</div>
</th>
</tr>
<tr>
<th style="text-align:right;">
blots
</th>
<th style="text-align:right;">
lm
</th>
<th style="text-align:right;">
norm1
</th>
<th style="text-align:right;">
norm2
</th>
<th style="text-align:right;">
norm3
</th>
<th style="text-align:right;">
lm
</th>
<th style="text-align:right;">
norm1
</th>
<th style="text-align:right;">
norm2
</th>
<th style="text-align:right;">
norm3
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0.05
</td>
<td style="text-align:right;">
0.05
</td>
<td style="text-align:right;">
0.050
</td>
<td style="text-align:right;">
0.151
</td>
<td style="text-align:right;">
0.045
</td>
<td style="text-align:right;">
0.046
</td>
<td style="text-align:right;">
0.046
</td>
<td style="text-align:right;">
0.141
</td>
</tr>
<tr>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
0.05
</td>
<td style="text-align:right;">
0.05
</td>
<td style="text-align:right;">
0.053
</td>
<td style="text-align:right;">
0.133
</td>
<td style="text-align:right;">
0.045
</td>
<td style="text-align:right;">
0.046
</td>
<td style="text-align:right;">
0.048
</td>
<td style="text-align:right;">
0.125
</td>
</tr>
<tr>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
0.05
</td>
<td style="text-align:right;">
0.05
</td>
<td style="text-align:right;">
0.056
</td>
<td style="text-align:right;">
0.093
</td>
<td style="text-align:right;">
0.045
</td>
<td style="text-align:right;">
0.046
</td>
<td style="text-align:right;">
0.054
</td>
<td style="text-align:right;">
0.086
</td>
</tr>
<tr>
<td style="text-align:right;">
10
</td>
<td style="text-align:right;">
0.05
</td>
<td style="text-align:right;">
0.05
</td>
<td style="text-align:right;">
0.068
</td>
<td style="text-align:right;">
0.051
</td>
<td style="text-align:right;">
0.045
</td>
<td style="text-align:right;">
0.046
</td>
<td style="text-align:right;">
0.066
</td>
<td style="text-align:right;">
0.049
</td>
</tr>
</tbody>
</table>
</div>
<div id="conditional-type-i-error" class="section level3">
<h3>Conditional Type I error</h3>
<pre class="r"><code>plot_prob_t1_2(res, ycol=&quot;lm&quot;, two_d=TRUE)</code></pre>
<div class="figure"><span id="fig:unnamed-chunk-8"></span>
<img src="/quasipub/normalization-inflates-type-i-error_files/figure-html/unnamed-chunk-8-1.png" alt="p-values from linear model with Gapdh as covariate. The graphs are the same for all values of blots, but are shown for easy comparison with norm2 and norm3" width="672" />
<p class="caption">
Figure 5: p-values from linear model with Gapdh as covariate. The graphs are the same for all values of blots, but are shown for easy comparison with norm2 and norm3
</p>
</div>
<pre class="r"><code>plot_prob_t1_2(res, ycol=&quot;norm1&quot;, two_d=TRUE)</code></pre>
<div class="figure"><span id="fig:unnamed-chunk-9"></span>
<img src="/quasipub/normalization-inflates-type-i-error_files/figure-html/unnamed-chunk-9-1.png" alt="p-values from t-test of norm1. The graphs are the same for all values of blots, but are shown for easy comparison with norm2 and norm3" width="672" />
<p class="caption">
Figure 6: p-values from t-test of norm1. The graphs are the same for all values of blots, but are shown for easy comparison with norm2 and norm3
</p>
</div>
<pre class="r"><code>plot_prob_t1_2(res, ycol=&quot;norm2&quot;, two_d=TRUE)</code></pre>
<div class="figure"><span id="fig:unnamed-chunk-10"></span>
<img src="/quasipub/normalization-inflates-type-i-error_files/figure-html/unnamed-chunk-10-1.png" alt="p-values from t-test of norm2" width="672" />
<p class="caption">
Figure 7: p-values from t-test of norm2
</p>
</div>
<pre class="r"><code>plot_prob_t1_2(res, ycol=&quot;norm3&quot;, two_d=TRUE)</code></pre>
<div class="figure"><span id="fig:unnamed-chunk-11"></span>
<img src="/quasipub/normalization-inflates-type-i-error_files/figure-html/unnamed-chunk-11-1.png" alt="p-values from t-test of norm3" width="672" />
<p class="caption">
Figure 8: p-values from t-test of norm3
</p>
</div>
<p>The general pattern is the same for <span class="math inline">\(n=10\)</span> as for <span class="math inline">\(n=4\)</span> and summarized above in <a href="#summary-of-simulation-results-for-n4">Summary of simulation results for n=4</a></p>
</div>
</div>
</div>
<div id="other-literature" class="section level1">
<h1>Other literature</h1>
<p>I wouldn’t think this is news but I’m not familiar with the literature. Google Scholaring found mostly normalization in microarray/RNAseq type stuff and much of this is concerned with different issues. There is abundant literature on normalizing for body weight in organismal physiology and adjusting for baseline in pre-post designs, but there doesn’t seem to be much acknowledgment within experimental biology of regression to the mean due to normalizing measures like band intensity. I did find this,</p>
<p>Janušonis, S., 2009. Comparing two small samples with an unstable, treatment-independent baseline. Journal of neuroscience methods, 179(2), pp.173-178.</p>
<p>which doesn’t discuss regression to the mean and inflated conditional type I error even though it cites some of this literature.</p>
</div>

              
            </div>
          </div>
          <div id="post-footer" class="post-footer main-content-wrap">
            
              
            
            <div class="post-actions-wrap">
  
      <nav >
        <ul class="post-actions post-action-nav">
          
            <li class="post-action">
              
                <a class="post-action-btn btn btn--disabled">
              
                  <i class="fa fa-angle-left"></i>
                  <span class="hide-xs hide-sm text-small icon-ml">NEXT</span>
                </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--disabled">
              
                  <span class="hide-xs hide-sm text-small icon-mr">PREVIOUS</span>
                  <i class="fa fa-angle-right"></i>
                </a>
            </li>
          
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
        <li class="post-action hide-lg hide-md hide-sm">
          <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions">
            <i class="fa fa-share-alt"></i>
          </a>
        </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=/quasipub/normalization-inflates-type-i-error/">
              <i class="fa fa-facebook-official"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=/quasipub/normalization-inflates-type-i-error/">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://plus.google.com/share?url=/quasipub/normalization-inflates-type-i-error/">
              <i class="fa fa-google-plus"></i>
            </a>
          </li>
        
      
      
        <li class="post-action">
          <a class="post-action-btn btn btn--default" href="#disqus_thread">
            <i class="fa fa-comment-o"></i>
          </a>
        </li>
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  
</div>

            
              
                <div id="disqus_thread">
  <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
              
            
          </div>
        </article>
        <footer id="footer" class="main-content-wrap">
  <span class="copyrights">
    &copy; 2019 <a href="https://github.com/middleprofessor">Jeffrey A. Walker</a>. All Rights Reserved
  </span>
</footer>

      </div>
      <div id="bottom-bar" class="post-bottom-bar" data-behavior="1">
        <div class="post-actions-wrap">
  
      <nav >
        <ul class="post-actions post-action-nav">
          
            <li class="post-action">
              
                <a class="post-action-btn btn btn--disabled">
              
                  <i class="fa fa-angle-left"></i>
                  <span class="hide-xs hide-sm text-small icon-ml">NEXT</span>
                </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--disabled">
              
                  <span class="hide-xs hide-sm text-small icon-mr">PREVIOUS</span>
                  <i class="fa fa-angle-right"></i>
                </a>
            </li>
          
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
        <li class="post-action hide-lg hide-md hide-sm">
          <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions">
            <i class="fa fa-share-alt"></i>
          </a>
        </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=/quasipub/normalization-inflates-type-i-error/">
              <i class="fa fa-facebook-official"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=/quasipub/normalization-inflates-type-i-error/">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://plus.google.com/share?url=/quasipub/normalization-inflates-type-i-error/">
              <i class="fa fa-google-plus"></i>
            </a>
          </li>
        
      
      
        <li class="post-action">
          <a class="post-action-btn btn btn--default" href="#disqus_thread">
            <i class="fa fa-comment-o"></i>
          </a>
        </li>
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  
</div>

      </div>
      <div id="share-options-bar" class="share-options-bar" data-behavior="1">
  <i id="btn-close-shareoptions" class="fa fa-close"></i>
  <ul class="share-options">
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://www.facebook.com/sharer/sharer.php?u=%2Fquasipub%2Fnormalization-inflates-type-i-error%2F">
          <i class="fa fa-facebook-official"></i><span>Share on Facebook</span>
        </a>
      </li>
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://twitter.com/intent/tweet?text=%2Fquasipub%2Fnormalization-inflates-type-i-error%2F">
          <i class="fa fa-twitter"></i><span>Share on Twitter</span>
        </a>
      </li>
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://plus.google.com/share?url=%2Fquasipub%2Fnormalization-inflates-type-i-error%2F">
          <i class="fa fa-google-plus"></i><span>Share on Google&#43;</span>
        </a>
      </li>
    
  </ul>
</div>
<div id="share-options-mask" class="share-options-mask"></div>
    </div>
    
    <div id="about">
  <div id="about-card">
    <div id="about-btn-close">
      <i class="fa fa-remove"></i>
    </div>
    
      <img id="about-card-picture" src="https://www.gravatar.com/avatar/7bbef046c3aca6a4dce979b577e3e165?s=110" alt="Author&#39;s picture" />
    
    <h4 id="about-card-name">R doodles. Some ecology. Some physiology. Much fake data.</h4>
    
      <div id="about-card-bio">Thoughts on R, statistical best practices, and teaching applied statistics to Biology majors.</div>
    
    
      <div id="about-card-job">
        <i class="fa fa-briefcase"></i>
        <br/>
        Jeff Walker, Professor of Biological Sciences
      </div>
    
    
      <div id="about-card-location">
        <i class="fa fa-map-marker"></i>
        <br/>
        University of Southern Maine, Portland, Maine, United States
      </div>
    
  </div>
</div>

    <div id="algolia-search-modal" class="modal-container">
  <div class="modal">
    <div class="modal-header">
      <span class="close-button"><i class="fa fa-close"></i></span>
      <a href="https://algolia.com" target="_blank" rel="noopener" class="searchby-algolia text-color-light link-unstyled">
        <span class="searchby-algolia-text text-color-light text-small">by</span>
        <img class="searchby-algolia-logo" src="https://www.algolia.com/static_assets/images/press/downloads/algolia-light.svg">
      </a>
      <i class="search-icon fa fa-search"></i>
      <form id="algolia-search-form">
        <input type="text" id="algolia-search-input" name="search"
          class="form-control input--large search-input" placeholder="Search" />
      </form>
    </div>
    <div class="modal-body">
      <div class="no-result text-color-light text-center">no post found</div>
      <div class="results">
        
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/10/normalization-results-in-regression-to-the-mean/">
                <h3 class="media-heading">Normalization results in regression to the mean and inflated Type I error conditional on the reference values</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Oct 10, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">Fig 1C of the Replication Study: Melanoma exosomes educate bone marrow progenitor cells toward a pro-metastatic phenotype through MET uses an odd (to me) three stage normalization procedure for the quantified western blots. The authors compared blot values of a treatment (Met or pMet) to a control (shScr) using GAPDH to normalize the values. The three stages of the normalization are
first, the value for the Antibody levels were normalized by the value of a reference (GAPDH) for each Set.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/10/a-comment-on-the-novel-transformation-of-the-response-in-senolytics-decrease-senescent-cells-in-humans-preliminary-report-from-a-clinical-trial-of-dasatinib-plus-quercetin-in-individuals-with-diabetic-kidney-disease/">
                <h3 class="media-heading">A comment on the novel transformation of the response in &#34; Senolytics decrease senescent cells in humans: Preliminary report from a clinical trial of Dasatinib plus Quercetin in individuals with diabetic kidney disease&#34;</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Oct 10, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">Motivation: https://pubpeer.com/publications/8DF6E66FEFAA2C3C7D5BD9C3FC45A2#2 and https://twitter.com/CGATist/status/1175015246282539009
tl;dr: Given the transformation done by the authors, for any response in day_0 that is unusually small, there is automatically a response in day_14 that is unusually big and vice-versa. Consequently, if the mean for day_0 is unusually small, the mean for day_14 is automatically unusually big, hence the elevated type I error with an unpaired t-test. The transformation is necessary and sufficient to produce the result (meaning even in conditions where a paired t-test isn’t needed, the transformation still produces elevated Type I error).</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/08/what-is-the-consequence-of-a-shapiro-wilk-test-of-normality-filter-on-type-i-error-and-power/">
                <h3 class="media-heading">What is the consequence of a Shapiro-Wilk test-of-normality filter on Type I error and Power?</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Aug 8, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">Set up Normal distribution Type I error Power  Right skewed continuous – lognormal What the parameterizations look like Type I error Power    This 1990-wants-you-back doodle explores the effects of a Normality Filter – using a Shapiro-Wilk (SW) test as a decision rule for using either a t-test or some alternative such as a 1) non-parametric Mann-Whitney-Wilcoxon (MWW) test, or 2) a t-test on the log-transformed response.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/07/what-is-bias-in-the-estimation-of-an-effect-giving-an-omitted-interaction-term/">
                <h3 class="media-heading">What is the bias in the estimation of an effect given an omitted interaction term?</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Jul 7, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">Some background (due to Sewall Wright’s method of path analysis) Given a generating model:
\[\begin{equation} y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 \end{equation}\] where \(x_3 = x_1 x_2\); that is, it is an interaction variable.
The total effect of \(x_1\) on \(y\) is \(\beta_1 + \frac{\mathrm{COV}(x_1, x_2)}{\mathrm{VAR}(x_1)} \beta_2 + \frac{\mathrm{COV}(x_1, x_3)}{\mathrm{VAR}(x_1)} \beta_3\).
If \(x_3\) (the interaction) is missing, its component on the total efffect is added to the coefficient of \(x_1\).</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/07/is-the-power-to-test-an-interaction-effect-less-than-that-for-a-main-effect/">
                <h3 class="media-heading">Is the power to test an interaction effect less than that for a main effect?</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Jul 7, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">I was googling around and somehow landed on a page that stated “When effect coding is used, statistical power is the same for all regression coefficients of the same size, whether they correspond to main effects or interactions, and irrespective of the order of the interaction”. Really? How could this be? The p-value for an interaction effect is the same regardless of dummy or effects coding, and, with dummy coding (R’s default), the power of the interaction effect is less than that of the coefficients for the main factors when they have the same magnitude, so my intuition said this statement must be wrong.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/06/analyze-the-mean-or-median-and-not-the-max-response/">
                <h3 class="media-heading">Analyze the mean (or median) and not the max response</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Jun 6, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">This is an update of Paired t-test as a special case of linear model and hierarchical model
Figure 2A of the paper Meta-omics analysis of elite athletes identifies a performance-enhancing microbe that functions via lactate metabolism uses a paired t-test to compare endurance performance in mice treated with a control microbe (Lactobacillus bulgaricus) and a test microbe (Veillonella atypica) in a cross-over design (so each mouse was treated with both bacteria).</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/06/paired-t-test-as-a-special-case-of-linear-model-and-hierarchical-linear-mixed-model/">
                <h3 class="media-heading">Paired t-test as a special case of linear model and hierarchical (linear mixed) model</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Jun 6, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">Update – Fig. 2A is an analysis of the maximum endurance over three trials. This has consequences.
Figure 2A of the paper Meta-omics analysis of elite athletes identifies a performance-enhancing microbe that functions via lactate metabolism uses a paired t-test to compare endurance performance in mice treated with a control microbe (Lactobacillus bulgaricus) and a test microbe (Veillonella atypica) in a cross-over design (so each mouse was treated with both bacteria).</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/06/what-does-cell-biology-data-look-like/">
                <h3 class="media-heading">What does cell biology data look like?</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Jun 6, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">If I’m going to evaluate the widespread use of t-tests/ANOVAs on count data in bench biology then I’d like to know what these data look like, specifically the shape (“overdispersion”) parameter.
Set up library(ggplot2) library(readxl) library(ggpubr) library(cowplot) library(plyr) #mapvalues library(data.table) # glm packages library(MASS) library(pscl) #zeroinfl library(DHARMa) library(mvabund) data_path &lt;- &quot;../data&quot; # notebook, console source(&quot;../../../R/clean_labels.R&quot;) # notebook, console  Data from The enteric nervous system promotes intestinal health by constraining microbiota composition Import read_enteric &lt;- function(sheet_i, range_i, file_path, wide_2_long=TRUE){ dt_wide &lt;- data.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/06/reanalyzing-data-from-human-gut-microbiota-from-autism-spectrum-disorder-promote-behavioral-symptoms-in-mice/">
                <h3 class="media-heading">Reanalyzing data from Human Gut Microbiota from Autism Spectrum Disorder Promote Behavioral Symptoms in Mice</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Jun 6, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">Update - This post has been updated
A very skeletal analysis of
Sharon, G., Cruz, N.J., Kang, D.W., Gandal, M.J., Wang, B., Kim, Y.M., Zink, E.M., Casey, C.P., Taylor, B.C., Lane, C.J. and Bramer, L.M., 2019. Human Gut Microbiota from Autism Spectrum Disorder Promote Behavioral Symptoms in Mice. Cell, 177(6), pp.1600-1618.
which got some attention on pubpeer.
Commenters are questioning the result of Fig1G. It is very hard to infer a p-value from plots like these, where the data are multi-level, regardless of if means and some kind of error bar is presented.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/05/glm-vs-t-tests-vs-non-parametric-tests-if-all-we-care-about-is-nhst-update/">
                <h3 class="media-heading">GLM vs. t-tests vs. non-parametric tests if all we care about is NHST -- Update</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  May 5, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">Update to the earlier post, which was written in response to my own thinking about how to teach stastics to experimental biologists working in fields that are dominated by hypothesis testing instead of estimation. That is, should these researchers learn GLMs or is a t-test on raw or log-transformed data on something like count data good enough – or even superior? My post was written without the benefit of either [Ives](Ives, Anthony R.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
      </div>
    </div>
    <div class="modal-footer">
      <p class="results-count text-medium"
         data-message-zero="no post found"
         data-message-one="1 post found"
         data-message-other="{n} posts found">
         32 posts found
      </p>
    </div>
  </div>
</div>
    
  
    
    <div id="cover" style="background-image:url('/images/Jackson%20copy%202.jpg');"></div>
  


    
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js" integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44=" crossorigin="anonymous"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.7/js/jquery.fancybox.min.js" integrity="sha256-GEAnjcTqVP+vBp3SSc8bEDQqvWAZMiHyUSIorrWwH50=" crossorigin="anonymous"></script>


<script src="/js/script-qi9wbxp2ya2j6p7wx1i6tgavftewndznf4v0hy2gvivk1rxgc3lm7njqb6bz.min.js"></script>


<script lang="javascript">
window.onload = updateMinWidth;
window.onresize = updateMinWidth;
document.getElementById("sidebar").addEventListener("transitionend", updateMinWidth);
function updateMinWidth() {
  var sidebar = document.getElementById("sidebar");
  var main = document.getElementById("main");
  main.style.minWidth = "";
  var w1 = getComputedStyle(main).getPropertyValue("min-width");
  var w2 = getComputedStyle(sidebar).getPropertyValue("width");
  var w3 = getComputedStyle(sidebar).getPropertyValue("left");
  main.style.minWidth = `calc(${w1} - ${w2} - ${w3})`;
}
</script>

<script>
$(document).ready(function() {
  hljs.configure({ classPrefix: '', useBR: false });
  $('pre.code-highlight > code, pre > code').each(function(i, block) {
    if (!$(this).hasClass('codeblock')) {
      $(this).addClass('codeblock');
    }
    hljs.highlightBlock(block);
  });
});
</script>


  
    
      <script>
        var disqus_config = function () {
          this.page.url = '\/quasipub\/normalization-inflates-type-i-error\/';
          
            this.page.identifier = '\/quasipub\/normalization-inflates-type-i-error\/'
          
        };
        (function() {
          
          
          if (window.location.hostname == "localhost") {
            return;
          }
          var d = document, s = d.createElement('script');
          var disqus_shortname = 'r-doodles';
          s.src = '//' + disqus_shortname + '.disqus.com/embed.js';

          s.setAttribute('data-timestamp', +new Date());
          (d.head || d.body).appendChild(s);
        })();
      </script>
    
  



<script src="//yihui.name/js/math-code.js"></script>
<script async
src="//cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
    
  </body>
</html>

