<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Generalized Linear Models on R Doodles</title>
    <link>/tags/generalized-linear-models/</link>
    <description>Recent content in Generalized Linear Models on R Doodles</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 09 Jun 2019 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="/tags/generalized-linear-models/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>What does cell biology data look like?</title>
      <link>/2019/06/what-does-cell-biology-data-look-like/</link>
      <pubDate>Sun, 09 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/06/what-does-cell-biology-data-look-like/</guid>
      <description>


&lt;p&gt;If I’m going to evaluate the widespread use of t-tests/ANOVAs on count data in bench biology then I’d like to know what these data look like, specifically the shape (“overdispersion”) parameter.&lt;/p&gt;
&lt;div id=&#34;set-up&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Set up&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)
library(readxl)
library(ggpubr)
library(cowplot)
library(plyr) #mapvalues
library(data.table)

# glm packages
library(MASS)
library(pscl) #zeroinfl
library(DHARMa)
library(mvabund)

  data_path &amp;lt;- &amp;quot;../data&amp;quot; # notebook, console
  source(&amp;quot;../../../R/clean_labels.R&amp;quot;) # notebook, console&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;data-from-the-enteric-nervous-system-promotes-intestinal-health-by-constraining-microbiota-composition&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data from The enteric nervous system promotes intestinal health by constraining microbiota composition&lt;/h1&gt;
&lt;div id=&#34;import&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Import&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;read_enteric &amp;lt;- function(sheet_i, range_i, file_path, wide_2_long=TRUE){
  dt_wide &amp;lt;- data.table(read_excel(file_path, sheet=sheet_i, range=range_i))
  dt_long &amp;lt;- na.omit(melt(dt_wide, measure.vars=colnames(dt_wide), variable.name=&amp;quot;treatment&amp;quot;, value.name=&amp;quot;count&amp;quot;))
  return(dt_long)
}

folder &amp;lt;- &amp;quot;Data from The enteric nervous system promotes intestinal health by constraining microbiota composition&amp;quot;
fn &amp;lt;- &amp;quot;journal.pbio.2000689.s008.xlsx&amp;quot;
file_path &amp;lt;- paste(data_path, folder, fn, sep=&amp;quot;/&amp;quot;)
fig1c &amp;lt;- read_enteric(sheet_i=&amp;quot;Figure 1&amp;quot;, range_i=&amp;quot;a2:b11&amp;quot;, file_path)
fig1e &amp;lt;- read_enteric(sheet_i=&amp;quot;Figure 1&amp;quot;, range_i=&amp;quot;d2:g31&amp;quot;, file_path)
fig1f &amp;lt;- read_enteric(sheet_i=&amp;quot;Figure 1&amp;quot;, range_i=&amp;quot;i2:l53&amp;quot;, file_path)
fig2a &amp;lt;- read_enteric(sheet_i=&amp;quot;Figure 2&amp;quot;, range_i=&amp;quot;a2:d33&amp;quot;, file_path)
fig2d &amp;lt;- read_enteric(sheet_i=&amp;quot;Figure 2&amp;quot;, range_i=&amp;quot;F2:I24&amp;quot;, file_path)
fig3a &amp;lt;- read_enteric(sheet_i=&amp;quot;Figure 3&amp;quot;, range_i=&amp;quot;a2:c24&amp;quot;, file_path)
fig3b &amp;lt;- read_enteric(sheet_i=&amp;quot;Figure 3&amp;quot;, range_i=&amp;quot;e2:g12&amp;quot;, file_path)
fig4a &amp;lt;- read_enteric(sheet_i=&amp;quot;Figure 4&amp;quot;, range_i=&amp;quot;a2:b125&amp;quot;, file_path)
fig5c &amp;lt;- read_enteric(sheet_i=&amp;quot;Figure 5&amp;quot;, range_i=&amp;quot;i2:l205&amp;quot;, file_path)
fig6d &amp;lt;- read_enteric(sheet_i=&amp;quot;Figure 6&amp;quot;, range_i=&amp;quot;I2:L16&amp;quot;, file_path)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;estimates-of-the-shape-parameter&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Estimates of the shape parameter&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot_enteric &amp;lt;- function(fig_i, fig_num=NULL){
  fit &amp;lt;- glm.nb(count ~ treatment, data=fig_i)

  #fig_num &amp;lt;- names(fig_i)
  if(is.null(fig_num)){
    fig_num &amp;lt;- deparse(substitute(fig_i)) # this works when df is sent but not a list element
  }
  theta &amp;lt;- fit$theta
  fit_title &amp;lt;- paste0(fig_num, &amp;quot; (theta = &amp;quot;, round(theta,1), &amp;quot;)&amp;quot;)
  gg &amp;lt;- ggdotplot(fig_i,
           x=&amp;quot;treatment&amp;quot;, 
           y=&amp;quot;count&amp;quot;,
           color=&amp;quot;treatment&amp;quot;,
           pallete=&amp;quot;jco&amp;quot;,
           add=&amp;quot;mean&amp;quot;) +
    #annotate(&amp;quot;text&amp;quot;, x=1, y= max(fig_i[, count]), label=paste(&amp;quot;theta =&amp;quot;, round(theta,1))) +
    ggtitle(fit_title) +
    rremove(&amp;quot;legend&amp;quot;) +
    NULL
  return(gg)
}

plot_enteric2 &amp;lt;- function(fig_i, fig_num, i){
  fit &amp;lt;- glm.nb(count ~ treatment, data=fig_i[[i]])
  #fig_no &amp;lt;- deparse(substitute(fig_i)) # this works when df is sent but not a list element
  #fig_no &amp;lt;- names(fig_i)
  theta &amp;lt;- fit$theta
  fit_title &amp;lt;- paste0(fig_num[[i]], &amp;quot; (theta = &amp;quot;, round(theta,1), &amp;quot;)&amp;quot;)
  gg &amp;lt;- ggdotplot(fig_i[[i]],
           x=&amp;quot;treatment&amp;quot;, 
           y=&amp;quot;count&amp;quot;,
           color=&amp;quot;treatment&amp;quot;,
           pallete=&amp;quot;jco&amp;quot;,
           add=&amp;quot;mean&amp;quot;) +
    #annotate(&amp;quot;text&amp;quot;, x=1, y= max(fig_i[, count]), label=paste(&amp;quot;theta =&amp;quot;, round(theta,1))) +
    ggtitle(fit_title) +
    rremove(&amp;quot;legend&amp;quot;) +
    NULL
  return(gg)
}

fig_list_names &amp;lt;- c(&amp;quot;fig1c&amp;quot;, &amp;quot;fig1e&amp;quot;, &amp;quot;fig1f&amp;quot;, &amp;quot;fig2a&amp;quot;, &amp;quot;fig2d&amp;quot;, &amp;quot;fig3a&amp;quot;, &amp;quot;fig3b&amp;quot;, &amp;quot;fig4a&amp;quot;, &amp;quot;fig5c&amp;quot;, &amp;quot;fig6d&amp;quot;)
fig_list &amp;lt;- list(fig1c, fig1e, fig1f, fig2a, fig2d, fig3a, fig3b, fig4a, fig5c, fig6d)
names(fig_list) &amp;lt;- fig_list_names # super kludgy
# this doesn&amp;#39;t work
# gg_list &amp;lt;- lapply(fig_list, plot_enteric, names(fig_list))

# this works but requires i in the function which is unsatifying
#gg_list &amp;lt;- lapply(seq_along(fig_list), plot_enteric2, fig_i=fig_list, fig_num=names(fig_list))
gg_list &amp;lt;- list(NULL)
for(i in 1:length(fig_list)){
  gg_list[[i]] &amp;lt;- plot_enteric(fig_list[[i]], names(fig_list)[[i]])
}

plot_grid(plotlist=gg_list, ncol = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-06-09-what-does-cell-biology-data-look-like_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;data-from-organic-cation-transporter-3-oct3-is-a-distinct-catecholamines-clearance-route-in-adipocytes-mediating-the-beiging-of-white-adipose-tissue&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data from Organic cation transporter 3 (Oct3) is a distinct catecholamines clearance route in adipocytes mediating the beiging of white adipose tissue&lt;/h1&gt;
&lt;div id=&#34;import-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Import&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;folder &amp;lt;- &amp;quot;Data from Organic cation transporter 3 (Oct3) is a distinct catecholamines clearance route in adipocytes mediating the beiging of white adipose tissue&amp;quot;
fn &amp;lt;- &amp;quot;journal.pbio.2006571.s012.xlsx&amp;quot;
file_path &amp;lt;- paste(data_path, folder, fn, sep=&amp;quot;/&amp;quot;)
fig5b &amp;lt;- read_enteric(sheet_i=&amp;quot;Fig 5B&amp;quot;, range_i=&amp;quot;b2:c12&amp;quot;, file_path)
plot_enteric(fig5b)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;estimates-of-the-shape-parameter-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Estimates of the shape parameter&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;plots-of-simulated-samples-that-differ-in-mu-and-theta&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Plots of simulated samples that differ in &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;&lt;/h1&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>GLM vs. t-tests vs. non-parametric tests if all we care about is NHST -- Update</title>
      <link>/2019/05/glm-vs-t-tests-vs-non-parametric-tests-if-all-we-care-about-is-nhst-update/</link>
      <pubDate>Thu, 30 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/05/glm-vs-t-tests-vs-non-parametric-tests-if-all-we-care-about-is-nhst-update/</guid>
      <description>


&lt;p&gt;&lt;a href=&#34;../../../2019/01/glm-vs-non-parametric-tests-if-all-we-care-about-is-nhst/&#34;&gt;Update to the earlier post&lt;/a&gt;, which was written in response to my own thinking about how to teach stastics to experimental biologists working in fields that are dominated by hypothesis testing instead of estimation. That is, should these researchers learn GLMs or is a t-test on raw or log-transformed data on something like count data good enough – or even superior? My post was written without the benefit of either [Ives](Ives, Anthony R. “For testing the significance of regression coefficients, go ahead and log‐transform count data.” Methods in Ecology and Evolution 6, no. 7 (2015): 828-835) or &lt;a href=&#34;Warton,%20D.I.,%20Lyons,%20M.,%20Stoklosa,%20J.%20and%20Ives,%20A.R.,%202016.%20Three%20points%20to%20consider%20when%20choosing%20a%20LM%20or%20GLM%20test%20for%20count%20data.%20Methods%20in%20Ecology%20and%20Evolution,%207(8),%20pp.882-890&#34;&gt;Warton et al.&lt;/a&gt;. With hindsight, I do vaguely recall Ives, and my previous results support his conclusions, but I was unaware of Warton.&lt;/p&gt;
&lt;p&gt;Warton et al is a fabulous paper. A must read. A question that I have is, &lt;em&gt;under the null&lt;/em&gt; isn’t the response itself exchangeable, so that residuals are unnecessary? Regardless, the implementation in the mvabund package is way faster than my own R-scripted permutation. So here is my earlier simulation in light of Warton et al.&lt;/p&gt;
&lt;p&gt;TL;DR – If we live and die by NHST, then we want to choose a test with good Type I error control but has high power. The quasi-poisson both estimates an interpretable effect (unlike a t-test of log(y +1)) and has good Type I control with high power.&lt;/p&gt;
&lt;p&gt;A bit longer: The quasi-poisson LRT and the permutation NB have good Type I control and high power. The NB Wald and LRT have too liberal Type I control. The t-test of log response has good Type I control and high power at low &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; but is slightly inferior to the glm with increased &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;. The t-test, Welch, and Wilcoxan have conservative Type I control. Of these, the Wilcoxan has higher power than the t-test and Welch but not as high as the GLMs or log-transformed response.&lt;/p&gt;
&lt;div id=&#34;load-libraries&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;load libraries&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)
library(ggpubr)
library(MASS)
library(mvabund)
library(lmtest)
library(nlme)
library(data.table)
library(cowplot)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;the-simulation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The simulation&lt;/h2&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Single factor with two levels and a count (negative binomial) response.&lt;/li&gt;
&lt;li&gt;Relative effect sizes of 0%, 100%, and 200%&lt;/li&gt;
&lt;li&gt;Ref count of 4&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; of 5 and 10&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;em&gt;p&lt;/em&gt;-values computed from&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;t-test on raw response&lt;/li&gt;
&lt;li&gt;Welch t-test on raw response&lt;/li&gt;
&lt;li&gt;t-test on log transformed response&lt;/li&gt;
&lt;li&gt;Wilcoxan test&lt;/li&gt;
&lt;li&gt;glm with negative binomial family and log-link using Wald test&lt;/li&gt;
&lt;li&gt;glm with negative binomial family and log-link using LRT&lt;/li&gt;
&lt;li&gt;glm with negative binomial family and permutation test (using PIT residuals)&lt;a href=&#34;#fn1&#34; class=&#34;footnoteRef&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;glm with quasi-poisson family and log-link using LRT&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;do_sim &amp;lt;- function(sim_space=NULL, niter=1000, nperm=1000, algebra=FALSE){
  # the function was run with n=1000 and the data saved. on subsequent runs
  # the data are loaded from a file
  # the function creates three different objects to return, the object
  # return is specified by &amp;quot;return_object&amp;quot; = NULL, plot_data1, plot_data2
  
  set.seed(1)
  
  methods &amp;lt;- c(&amp;quot;t&amp;quot;, &amp;quot;Welch&amp;quot;, &amp;quot;log&amp;quot;, &amp;quot;Wilcoxan&amp;quot;, &amp;quot;nb&amp;quot;, &amp;quot;nb.x2&amp;quot;, &amp;quot;nb.perm&amp;quot;, &amp;quot;qp&amp;quot;)
  p_table &amp;lt;- data.table(NULL)
  
  if(is.null(sim_space)){
    mu_0_list &amp;lt;- c(4) # control count
    theta_list &amp;lt;- c(0.5) # dispersion
    effect_list &amp;lt;- c(1) # effect size will be 1X, 1.5X, 2X, 3X
    n_list &amp;lt;- c(10) # sample size
    sim_space &amp;lt;- data.table(expand.grid(theta=theta_list, mu_0=mu_0_list, effect=effect_list, n=n_list))
  }
  
  res_table &amp;lt;- data.table(NULL)
  i &amp;lt;- 1 # this is just for debugging
  for(i in 1:nrow(sim_space)){
    # construct clean results table 
    p_table_part &amp;lt;- matrix(NA, nrow=niter, ncol=length(methods))
    colnames(p_table_part) &amp;lt;- methods
    
    # parameters of simulation
    theta_i &amp;lt;- sim_space[i, theta]
    mu_0_i &amp;lt;- sim_space[i, mu_0]
    effect_i &amp;lt;- sim_space[i, effect]
    n_i &amp;lt;- sim_space[i, n]
    treatment &amp;lt;- rep(c(&amp;quot;Cn&amp;quot;, &amp;quot;Trt&amp;quot;), each=n_i)
    fd &amp;lt;- data.table(treatment=treatment)
    
    # mu (using algebra)
    if(algebra==TRUE){
      X &amp;lt;- model.matrix(~treatment)
      beta_0 &amp;lt;- log(mu_0_i)
      beta_1 &amp;lt;- log(effect_i*mu_0_i) - beta_0
      beta &amp;lt;- c(beta_0, beta_1)
      mu_i &amp;lt;- exp((X%*%beta)[,1])
    }else{ #  using R
      mu_vec &amp;lt;- c(mu_0_i, mu_0_i*effect_i)
      mu_i &amp;lt;- rep(mu_vec, each=n_i)
    }
    nb.error &amp;lt;- numeric(niter)
    
    for(iter in 1:niter){
      set.seed(niter*(i-1) + iter)
      fd[, y:=rnegbin(n=n_i*2, mu=mu_i, theta=theta_i)]
      fd[, log_yp1:=log10(y+1)]
      
      p.t &amp;lt;- t.test(y~treatment, data=fd, var.equal=TRUE)$p.value
      p.welch &amp;lt;- t.test(y~treatment, data=fd, var.equal=FALSE)$p.value
      p.log &amp;lt;- t.test(log_yp1~treatment, data=fd, var.equal=TRUE)$p.value
      p.wilcox &amp;lt;- wilcox.test(y~treatment, data=fd, exact=FALSE)$p.value
      
      # weighted lm, this will be ~same as welch for k=2 groups
      # fit &amp;lt;- gls(y~treatment, data=fd, weights = varIdent(form=~1|treatment), method=&amp;quot;ML&amp;quot;)
      # p.wls &amp;lt;- coef(summary(fit))[&amp;quot;treatmentTrt&amp;quot;, &amp;quot;p-value&amp;quot;]
      
      # negative binomial
      # default test using summary is Wald.
      # anova(fit) uses chisq of sequential fit, but using same estimate of theta
      # anova(fit2, fit1), uses chisq but with different estimate of theta
      # lrtest(fit) same as anova(fit2, fit1)
      
      # m1 &amp;lt;- glm.nb(y~treatment, data=fd)
      # m0 &amp;lt;- glm.nb(y~1, data=fd)
      # p.nb.x2 &amp;lt;- anova(m0, m1)[2, &amp;quot;Pr(Chi)&amp;quot;]
      # lr &amp;lt;- 2*(logLik(m1) - logLik(m0))
      # df.x2 = m0$df.residual-m1$df.residual
      # p.nb.x2 &amp;lt;- pchisq(lr, df=df.x2, lower.tail = F)
                
      m1 &amp;lt;- manyglm(y~treatment, data=fd) # default theta estimation &amp;quot;PHI&amp;quot;
      m0 &amp;lt;- manyglm(y~1, data=fd)
      lr &amp;lt;- 2*(logLik(m1) - logLik(m0))
      df.x2 = m0$df.residual-m1$df.residual
      p.nb &amp;lt;- coef(summary(m1))[&amp;quot;treatmentTrt&amp;quot;, &amp;quot;Pr(&amp;gt;wald)&amp;quot;] # Wald
      p.nb.x2 &amp;lt;- as.numeric(pchisq(lr, df=df.x2, lower.tail = F))
      p.nb.perm &amp;lt;- (anova(m0, m1, nBoot=nperm, show.time=&amp;#39;none&amp;#39;, p.uni=&amp;quot;unadjusted&amp;quot;)$uni.p)[2,1]

      # p.nb.x2 &amp;lt;- lrtest(fit)[2, &amp;quot;Pr(&amp;gt;Chisq)&amp;quot;] # doesn&amp;#39;t work with a data.table
      
      # quasipoisson
      fit &amp;lt;- glm(y~treatment, data=fd, family=quasipoisson)
      p.qp &amp;lt;- coeftest(fit)[2, &amp;quot;Pr(&amp;gt;|z|)&amp;quot;]
      
      p_table_part[iter,] &amp;lt;- c(p.t, p.welch, p.log, p.wilcox, p.nb, p.nb.x2, p.nb.perm, p.qp)
      
    } # niter
    p_table &amp;lt;- rbind(p_table, data.table(combo=i,
                                         mu_0=mu_0_i,
                                         effect=effect_i,
                                         n=n_i,
                                         theta=theta_i,
                                         nb.error=nb.error,
                                         p_table_part))
    
  } # combos
  
  return(p_table)
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Algebra is slower (duh!)
# start_time &amp;lt;- Sys.time()
# do_sim(niter=niter, algebra=FALSE)
# end_time &amp;lt;- Sys.time()
# end_time - start_time
# 
# start_time &amp;lt;- Sys.time()
# do_sim(niter=niter, algebra=TRUE)
# end_time &amp;lt;- Sys.time()
# end_time - start_time

n_iter &amp;lt;- 2000
n_perm &amp;lt;- 2000
mu_0_list &amp;lt;- c(4) # control count
theta_list &amp;lt;- c(0.5) # dispersion
effect_list &amp;lt;- c(1, 2, 4) # effect size will be 1X, 1.5X, 2X, 3X
n_list &amp;lt;- c(5, 10) # sample size
sim_space &amp;lt;- data.table(expand.grid(theta=theta_list, mu_0=mu_0_list, effect=effect_list, n=n_list))

do_it &amp;lt;- FALSE # if FALSE the results are available as a file
if(do_it==TRUE){
  p_table &amp;lt;- do_sim(sim_space, niter=n_iter, nperm=n_perm)
  write.table(p_table, &amp;quot;../output/glm-v-lm.0004.txt&amp;quot;, row.names = FALSE, quote=FALSE)
}else{
  p_table &amp;lt;- fread(&amp;quot;../output/glm-v-lm.0001.txt&amp;quot;)
  p_table[, combo:=paste(effect, n, sep=&amp;quot;-&amp;quot;)]
  ycols &amp;lt;- setdiff(colnames(p_table), c(&amp;quot;combo&amp;quot;, &amp;quot;mu_0&amp;quot;, &amp;quot;effect&amp;quot;, &amp;quot;n&amp;quot;, &amp;quot;theta&amp;quot;))
  res_table &amp;lt;- data.table(NULL)
  for(i in p_table[, unique(combo)]){
    p_table_part &amp;lt;- p_table[combo==i, ]
    mu_0_i &amp;lt;- p_table_part[1, mu_0]
    effect_i &amp;lt;- p_table_part[1, effect]
    n_i &amp;lt;- p_table_part[1, n]
    theta_i &amp;lt;- p_table_part[1, theta]
    n_iter_i &amp;lt;- nrow(p_table_part)
    p_sum &amp;lt;- apply(p_table_part[, .SD, .SDcols=ycols], 2, function(x) length(which(x &amp;lt;= 0.05))/n_iter_i)
    res_table &amp;lt;- rbind(res_table, data.table(mu_0 = mu_0_i,
                                             effect = effect_i,
                                             n = n_i,
                                             theta = theta_i,
                                             t(p_sum)))    
  }
  res_table[, n:=factor(n)]
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;type-i-error&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Type I error&lt;/h1&gt;
&lt;p&gt;Key: 1. “nb” uses the Wald test of negative binomial model. 2. “nb.x2” uses the LRT of negative binomial model. 3. “nb.perm” uses a permutation test on PIT residuals of negative binomial model 4. qp uses a LRT of quasi-poisson model&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;knitr::kable(res_table[effect==1,],
             caption = &amp;quot;Type 1 error as a function of n&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;caption&gt;&lt;span id=&#34;tab:type-1-table&#34;&gt;Table 1: &lt;/span&gt;Type 1 error as a function of n&lt;/caption&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;right&#34;&gt;mu_0&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;effect&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;n&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;theta&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;nb.error&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;t&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Welch&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;log&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Wilcoxan&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;nb&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;nb.x2&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;nb.perm&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;qp&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.032&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0175&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0475&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0270&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1280&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1015&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0515&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.054&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.036&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0295&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0505&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0435&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0675&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0695&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0460&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.053&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;power&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Power&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;knitr::kable(res_table[effect!=1,],
             caption = &amp;quot;Power as a function of n&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;caption&gt;&lt;span id=&#34;tab:unnamed-chunk-1&#34;&gt;Table 2: &lt;/span&gt;Power as a function of n&lt;/caption&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;right&#34;&gt;mu_0&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;effect&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;n&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;theta&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;nb.error&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;t&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Welch&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;log&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Wilcoxan&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;nb&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;nb.x2&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;nb.perm&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;qp&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0465&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0240&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0845&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0540&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1710&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1565&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0825&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0960&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1055&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0475&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1950&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1310&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.3310&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.3295&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1860&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1800&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0900&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0750&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1150&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1025&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1730&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1850&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1285&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1480&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.3120&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.2600&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.3780&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.3235&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5255&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5345&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.4190&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.4405&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;plot&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;plot&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;res &amp;lt;- melt(res_table, 
            id.vars=c(&amp;quot;mu_0&amp;quot;, &amp;quot;effect&amp;quot;, &amp;quot;n&amp;quot;, &amp;quot;theta&amp;quot;, &amp;quot;nb.error&amp;quot;),
            measure.vars=c(&amp;quot;t&amp;quot;, &amp;quot;Welch&amp;quot;, &amp;quot;log&amp;quot;, &amp;quot;Wilcoxan&amp;quot;, &amp;quot;nb&amp;quot;, &amp;quot;nb.x2&amp;quot;, &amp;quot;nb.perm&amp;quot;, &amp;quot;qp&amp;quot;),
            variable.name=&amp;quot;model&amp;quot;,
            value.name=&amp;quot;frequency&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gg &amp;lt;- ggplot(data=res[effect==1,], aes(x=n, y=frequency, group=model, color=model)) +
  geom_line() +
  facet_grid(. ~ effect, labeller=label_both) +
  NULL
gg&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-05-30-glm-vs-t-tests-vs-non-parametric-tests-if-all-we-care-about-is-nhst-update_files/figure-html/type-1-plot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gg &amp;lt;- ggplot(data=res[effect!=1,], aes(x=n, y=frequency, group=model, color=model)) +
  geom_line() +
  facet_grid(. ~ effect, labeller=label_both) +
  NULL
gg&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-05-30-glm-vs-t-tests-vs-non-parametric-tests-if-all-we-care-about-is-nhst-update_files/figure-html/plower-plot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Warton, D.I., Thibaut, L., Wang, Y.A., 2017. The PIT-trap—A “model-free” bootstrap procedure for inference about regression models with discrete, multivariate responses. PLOS ONE 12, e0181790. &lt;a href=&#34;https://doi.org/10.1371/journal.pone.0181790&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1371/journal.pone.0181790&lt;/a&gt;&lt;a href=&#34;#fnref1&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>GLM vs. t-tests vs. non-parametric tests if all we care about is NHST</title>
      <link>/2019/01/glm-vs-non-parametric-tests-if-all-we-care-about-is-nhst/</link>
      <pubDate>Mon, 07 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/01/glm-vs-non-parametric-tests-if-all-we-care-about-is-nhst/</guid>
      <description>


&lt;p&gt;&lt;a href=&#34;../../../2019/05/glm-vs-t-tests-vs-non-parametric-tests-if-all-we-care-about-is-nhst-update/&#34;&gt;This post has been updated&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;A skeleton simulation of different strategies for NHST for count data if all we care about is a p-value, as in bench biology where p-values are used to simply give one confidence that something didn’t go terribly wrong (similar to doing experiments in triplicate – it’s not the effect size that matters only “we have experimental evidence of a replicable effect”).&lt;/p&gt;
&lt;p&gt;tl;dr - At least for Type I error at small &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;, log(response) and Wilcoxan have the best performance over the simulation space. T-test is a bit conservative. Welch is even more conservative. glm-nb is too liberal.&lt;/p&gt;
&lt;div id=&#34;load-libraries&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;load libraries&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)
library(ggpubr)
library(MASS)
library(data.table)
library(cowplot)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;the-simulation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The simulation&lt;/h2&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Single factor with two levels and a count (negative binomial) response.&lt;/li&gt;
&lt;li&gt;Relative effect sizes of 0%, 50%, 100%, and 200%&lt;/li&gt;
&lt;li&gt;Ref count of 4, 10, 100&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; of 5, 10, 20, 40&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;em&gt;p&lt;/em&gt;-values computed from&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;t-test on raw response&lt;/li&gt;
&lt;li&gt;Welch t-test on raw response&lt;/li&gt;
&lt;li&gt;t-test on log transformed response&lt;/li&gt;
&lt;li&gt;Wilcoxan test&lt;/li&gt;
&lt;li&gt;glm with negative binomial family and log-link&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;do_sim &amp;lt;- function(niter=1, return_object=NULL){
  # the function was run with n=1000 and the data saved. on subsequent runs
  # the data are loaded from a file
  # the function creates three different objects to return, the object
  # return is specified by &amp;quot;return_object&amp;quot; = NULL, plot_data1, plot_data2
  methods &amp;lt;- c(&amp;quot;t&amp;quot;, &amp;quot;Welch&amp;quot;, &amp;quot;log&amp;quot;, &amp;quot;Wilcoxan&amp;quot;, &amp;quot;nb&amp;quot;)
  p_table_part &amp;lt;- matrix(NA, nrow=niter, ncol=length(methods))
  colnames(p_table_part) &amp;lt;- methods
  p_table &amp;lt;- data.table(NULL)
  
  res_table &amp;lt;- data.table(NULL)
  beta_0_list &amp;lt;- c(4, 10, 100) # control count
  theta_list &amp;lt;- c(0.5, 1, 100) # dispersion
  effect_list &amp;lt;- c(1:3, 5) # relative effect size will be 0%, 50%, 100%, 200%
  n_list &amp;lt;- c(5, 10, 20, 40) # sample size
  n_rows &amp;lt;- length(beta_0_list)*length(theta_list)*length(effect_list)*length(n_list)*niter
  sim_space &amp;lt;- expand.grid(theta_list, beta_0_list, effect_list, n_list)
  plot_data1 &amp;lt;- data.table(NULL)
  plot_data2 &amp;lt;- data.table(NULL)
  debug_table &amp;lt;- data.table(matrix(NA, nrow=niter, ncol=2))
  setnames(debug_table, old=colnames(debug_table), new=c(&amp;quot;seed&amp;quot;,&amp;quot;model&amp;quot;))
  debug_table[, seed:=as.integer(seed)]
  debug_table[, model:=as.character(model)]
  i &amp;lt;- 0
  for(theta_i in theta_list){
    for(beta_0 in beta_0_list){
      # first get plots of distributions given parameters
      y &amp;lt;- rnegbin(n=10^4, mu=beta_0, theta=theta_i)
      x_i &amp;lt;- seq(min(y), max(y), by=1)
      prob_x_i &amp;lt;- dnbinom(x_i, size=theta_i, mu=beta_0)
      plot_data1 &amp;lt;- rbind(plot_data1, data.table(
        theta=theta_i,
        mu=beta_0,
        x=x_i,
        prob_x=prob_x_i
      ))
      # the simulation
      for(effect in effect_list){
        for(n in n_list){
          beta_1 &amp;lt;- (effect-1)*beta_0/2 # 0% 50% 100%

          do_manual &amp;lt;- FALSE
          if(do_manual==TRUE){
            theta_i &amp;lt;- res_table[row, theta]
            beta_0 &amp;lt;- res_table[row, beta_0]
            beta_1 &amp;lt;- res_table[row, beta_1]
            n &amp;lt;- res_table[row, n]
          }
          
          beta &amp;lt;- c(beta_0, beta_1)
          treatment &amp;lt;- rep(c(&amp;quot;Cn&amp;quot;, &amp;quot;Trt&amp;quot;), each=n)
          X &amp;lt;- model.matrix(~treatment)
          mu &amp;lt;- (X%*%beta)[,1]
          fd &amp;lt;- data.table(treatment=treatment, y=NA)
          for(iter in 1:niter){
            i &amp;lt;- i+1
            set.seed(i)
            fd[, y:=rnegbin(n=n*2, mu=mu, theta=theta_i)]
            fd[, log_yp1:=log10(y+1)]
            p.t &amp;lt;- t.test(y~treatment, data=fd, var.equal=TRUE)$p.value
            p.welch &amp;lt;- t.test(y~treatment, data=fd, var.equal=FALSE)$p.value
            p.log &amp;lt;- t.test(log_yp1~treatment, data=fd, var.equal=TRUE)$p.value
            p.wilcox &amp;lt;- wilcox.test(y~treatment, data=fd, exact=FALSE)$p.value
            fit &amp;lt;- glm.nb(y~treatment, data=fd)
            debug_table[iter, seed:=i]
            debug_table[iter, model:=&amp;quot;glm.nb&amp;quot;]
            #if(fit$th.warn == &amp;quot;iteration limit reached&amp;quot;){
            if(!is.null(fit$th.warn)){
              fit &amp;lt;- glm(y~treatment, data=fd, family=poisson)
              debug_table[iter, model:=&amp;quot;poisson&amp;quot;]
            }
            p.nb &amp;lt;- coef(summary(fit))[&amp;quot;treatmentTrt&amp;quot;, &amp;quot;Pr(&amp;gt;|z|)&amp;quot;]
            p_table_part[iter,] &amp;lt;- c(p.t, p.welch, p.log, p.wilcox, p.nb)
          }
          p_table &amp;lt;- rbind(p_table, data.table(p_table_part, debug_table))
          p_sum &amp;lt;- apply(p_table_part, 2, function(x) length(which(x &amp;lt;= 0.05))/niter)
          res_table &amp;lt;- rbind(res_table, data.table(beta_0=beta_0,
                                                   beta_1=beta_1,
                                                   n=n,
                                                   theta=theta_i,
                                                   t(p_sum)))
        } # n
      } # effect
      plot_data2 &amp;lt;- rbind(plot_data2, data.table(
        theta=theta_i,
        mu=beta_0,
        n_i=n,
        beta1=beta_1,
        x=treatment,
        y=fd[, y]
      ))
    }
  }
  if(is.null(return_object)){return(res_table)}else{
    if(return_object==&amp;quot;plot_data1&amp;quot;){return(plot_data1)}
    if(return_object==&amp;quot;plot_data2&amp;quot;){return(plot_data2)}
    
  }
  
}

do_it &amp;lt;- FALSE # if FALSE the results are available as a file
if(do_it==TRUE){
  res_table &amp;lt;- do_sim(niter=1000)
  write.table(res_table, &amp;quot;../output/glm-t-wilcoxon.txt&amp;quot;, row.names = FALSE, quote=FALSE)
}else{
  plot_data &amp;lt;- do_sim(niter=1, return_object=&amp;quot;plot_data2&amp;quot;)
  res_table &amp;lt;- fread(&amp;quot;../output/glm-t-wilcoxon.txt&amp;quot;)
  res_table[, n:=factor(n)]
}
#res_table&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Distribution of the response for the 3 x 3 simulation space&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# extreme inelegance
mu_levels &amp;lt;- unique(plot_data[, mu])
theta_levels &amp;lt;- unique(plot_data[, theta])
show_function &amp;lt;- FALSE
show_violin &amp;lt;- TRUE

if(show_function==TRUE){
  gg1 &amp;lt;- qplot(x=x, y=prob_x, data=plot_data[mu==mu_levels[1] &amp;amp; theta==theta_levels[1],], geom=&amp;quot;line&amp;quot;)
  gg2 &amp;lt;- qplot(x=x, y=prob_x, data=plot_data[mu==mu_levels[2] &amp;amp; theta==theta_levels[1],], geom=&amp;quot;line&amp;quot;)
  gg3 &amp;lt;- qplot(x=x, y=prob_x, data=plot_data[mu==mu_levels[3] &amp;amp; theta==theta_levels[1],], geom=&amp;quot;line&amp;quot;)
  gg4 &amp;lt;- qplot(x=x, y=prob_x, data=plot_data[mu==mu_levels[1] &amp;amp; theta==theta_levels[2],], geom=&amp;quot;line&amp;quot;)
  gg5 &amp;lt;- qplot(x=x, y=prob_x, data=plot_data[mu==mu_levels[2] &amp;amp; theta==theta_levels[2],], geom=&amp;quot;line&amp;quot;)
  gg6 &amp;lt;- qplot(x=x, y=prob_x, data=plot_data[mu==mu_levels[3] &amp;amp; theta==theta_levels[2],], geom=&amp;quot;line&amp;quot;)
  gg7 &amp;lt;- qplot(x=x, y=prob_x, data=plot_data[mu==mu_levels[1] &amp;amp; theta==theta_levels[3],], geom=&amp;quot;line&amp;quot;)
  gg8 &amp;lt;- qplot(x=x, y=prob_x, data=plot_data[mu==mu_levels[2] &amp;amp; theta==theta_levels[3],], geom=&amp;quot;line&amp;quot;)
  gg9 &amp;lt;- qplot(x=x, y=prob_x, data=plot_data[mu==mu_levels[3] &amp;amp; theta==theta_levels[3],], geom=&amp;quot;line&amp;quot;)
}

if(show_violin==TRUE){
  gg1 &amp;lt;- ggviolin(x=&amp;quot;x&amp;quot;, y=&amp;quot;y&amp;quot;, data=plot_data[mu==mu_levels[1] &amp;amp; theta==theta_levels[1],], add=&amp;quot;jitter&amp;quot;)
  gg2 &amp;lt;- ggviolin(x=&amp;quot;x&amp;quot;, y=&amp;quot;y&amp;quot;, data=plot_data[mu==mu_levels[2] &amp;amp; theta==theta_levels[1],], add=&amp;quot;jitter&amp;quot;)
  gg3 &amp;lt;- ggviolin(x=&amp;quot;x&amp;quot;, y=&amp;quot;y&amp;quot;, data=plot_data[mu==mu_levels[3] &amp;amp; theta==theta_levels[1],], add=&amp;quot;jitter&amp;quot;)
  gg4 &amp;lt;- ggviolin(x=&amp;quot;x&amp;quot;, y=&amp;quot;y&amp;quot;, data=plot_data[mu==mu_levels[1] &amp;amp; theta==theta_levels[2],], add=&amp;quot;jitter&amp;quot;)
  gg5 &amp;lt;- ggviolin(x=&amp;quot;x&amp;quot;, y=&amp;quot;y&amp;quot;, data=plot_data[mu==mu_levels[2] &amp;amp; theta==theta_levels[2],], add=&amp;quot;jitter&amp;quot;)
  gg6 &amp;lt;- ggviolin(x=&amp;quot;x&amp;quot;, y=&amp;quot;y&amp;quot;, data=plot_data[mu==mu_levels[3] &amp;amp; theta==theta_levels[2],], add=&amp;quot;jitter&amp;quot;)
  gg7 &amp;lt;- ggviolin(x=&amp;quot;x&amp;quot;, y=&amp;quot;y&amp;quot;, data=plot_data[mu==mu_levels[1] &amp;amp; theta==theta_levels[3],], add=&amp;quot;jitter&amp;quot;)
  gg8 &amp;lt;- ggviolin(x=&amp;quot;x&amp;quot;, y=&amp;quot;y&amp;quot;, data=plot_data[mu==mu_levels[2] &amp;amp; theta==theta_levels[3],], add=&amp;quot;jitter&amp;quot;)
  gg9 &amp;lt;- ggviolin(x=&amp;quot;x&amp;quot;, y=&amp;quot;y&amp;quot;, data=plot_data[mu==mu_levels[3] &amp;amp; theta==theta_levels[3],], add=&amp;quot;jitter&amp;quot;)
}

gg_example &amp;lt;- plot_grid(gg1, gg2, gg3, gg4, gg5, gg6, gg7, gg8, gg9, 
          nrow=3,
          labels=c(paste0(&amp;quot;mu=&amp;quot;, mu_levels[1], &amp;quot;; theta=&amp;quot;, theta_levels[1]),
                   paste0(&amp;quot;mu=&amp;quot;, mu_levels[2], &amp;quot;; theta=&amp;quot;, theta_levels[1]),
                   paste0(&amp;quot;mu=&amp;quot;, mu_levels[3], &amp;quot;; theta=&amp;quot;, theta_levels[1]),
                   paste0(&amp;quot;mu=&amp;quot;, mu_levels[1], &amp;quot;; theta=&amp;quot;, theta_levels[2]),
                   paste0(&amp;quot;mu=&amp;quot;, mu_levels[2], &amp;quot;; theta=&amp;quot;, theta_levels[2]),
                   paste0(&amp;quot;mu=&amp;quot;, mu_levels[3], &amp;quot;; theta=&amp;quot;, theta_levels[2]),
                   paste0(&amp;quot;mu=&amp;quot;, mu_levels[1], &amp;quot;; theta=&amp;quot;, theta_levels[3]),
                   paste0(&amp;quot;mu=&amp;quot;, mu_levels[2], &amp;quot;; theta=&amp;quot;, theta_levels[3]),
                   paste0(&amp;quot;mu=&amp;quot;, mu_levels[3], &amp;quot;; theta=&amp;quot;, theta_levels[3])),
          label_size = 10, label_x=0.1)
gg_example&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-01-07-glm-vs-non-parametric-tests-if-all-we-care-about-is-nhst_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;type-i-error&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Type I error&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;res &amp;lt;- melt(res_table, 
            id.vars=c(&amp;quot;beta_0&amp;quot;, &amp;quot;beta_1&amp;quot;, &amp;quot;n&amp;quot;, &amp;quot;theta&amp;quot;),
            measure.vars=c(&amp;quot;t&amp;quot;, &amp;quot;Welch&amp;quot;, &amp;quot;log&amp;quot;, &amp;quot;Wilcoxan&amp;quot;, &amp;quot;nb&amp;quot;),
            variable.name=&amp;quot;model&amp;quot;,
            value.name=&amp;quot;frequency&amp;quot;)
# res[, beta_0:=factor(beta_0)]
# res[, beta_1:=factor(beta_1)]
# res[, theta:=factor(theta)]
# res[, n:=factor(n)]&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gg &amp;lt;- ggplot(data=res[beta_1==0], aes(x=n, y=frequency, group=model, color=model)) +
  geom_line() +
  facet_grid(beta_0 ~ theta, labeller=label_both) +
  NULL
gg&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-01-07-glm-vs-non-parametric-tests-if-all-we-care-about-is-nhst_files/figure-html/type%20I-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Ouch. glm-nb with hih error rates especially when n is small and the scale parameter is small&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;power&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Power&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;b0_levels &amp;lt;- unique(res$beta_0)
# small count
gg1 &amp;lt;- ggplot(data=res[beta_0==b0_levels[1] &amp;amp; beta_1 &amp;gt; 0], aes(x=n, y=frequency, group=model, color=model)) +
  geom_line() +
  facet_grid(beta_1 ~ theta, labeller=label_both) +
  NULL

# large count
gg2 &amp;lt;- ggplot(data=res[beta_0==b0_levels[3] &amp;amp; beta_1 &amp;gt; 0], aes(x=n, y=frequency, group=model, color=model)) +
  geom_line() +
  facet_grid(beta_1 ~ theta, labeller=label_both) +
  NULL

gg1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-01-07-glm-vs-non-parametric-tests-if-all-we-care-about-is-nhst_files/figure-html/power-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gg2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-01-07-glm-vs-non-parametric-tests-if-all-we-care-about-is-nhst_files/figure-html/power-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;glm-nb has higher power, especially at small n, but at a type I cost.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Should the model-averaged prediction be computed on the link or response scale in a GLM?</title>
      <link>/2018/05/should-the-model-averaged-prediction-be-computed-on-the-link-or-response-scale-in-a-glm/</link>
      <pubDate>Sun, 13 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/05/should-the-model-averaged-prediction-be-computed-on-the-link-or-response-scale-in-a-glm/</guid>
      <description>


&lt;p&gt;[updated to include additional output from MuMIn, BMA, and BAS]&lt;/p&gt;
&lt;p&gt;This post is a follow up &lt;a href=&#34;/2018/05/model-averaged-coefficients-of-a-glm&#34;&gt;to my inital post&lt;/a&gt;, which was written as as a way for me to pen my mental thoughts on the recent review of &lt;a href=&#34;https://esajournals.onlinelibrary.wiley.com/doi/abs/10.1002/ecm.1309&#34; target=&#34;_blank&#34;&gt;“Model averaging in ecology: a review of Bayesian, information‐theoretic and tactical approaches for predictive inference”&lt;/a&gt;. It was also written without contacting and discussing the issue with the authors. This post benefits from a series of e-mails with the lead author Carsten Dormann and the last author Florian Hartig.&lt;/p&gt;
&lt;p&gt;The Dormann et al. paper focuses on model-averaged predictions, but has a short discussion on problems with model-averaged coefficients in the supplement. It is in the supplement, that the authors state that for generalized linear models (GLMs) “coefficient averaging is not equivalent to prediction averaging”. Brian Cade&lt;a href=&#34;#fn1&#34; class=&#34;footnoteRef&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; also makes this argument.&lt;/p&gt;
&lt;p&gt;In my previous post, I argued that this statement is wrong – predictions from a parameter-averaged model is mathematically identical to averaging predictions. It was hard for me to understand how this was not immediately obvious until my e-mail exchange with Carsten and Florian. In short, I assume that all averaging is done on the link scale and then the predictions are back-transformed to the response scale. Carsten and Florian (and Brian Cade?) argue that this is the “wrong” way to compute averaged predictions.&lt;/p&gt;
&lt;p&gt;The summary of our differences is&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Carsten and Florian argue that predictions should be computed on the link scale, back-transformed to the response scale, and then averaged on the response scale. I understand their reason to be that first, this is how everyone outside of ecology does it, and second, predictions have to be averaged on the response scale for non-linear models because there is no link scale, and, since, GLMs are non-linear models, they should be averaged on the response scale.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;I argue that because a GLM model is a function of a linear predictor, any subsequent averaging should be on the linear scale, so that additive relationships remain additive and not multiplicative. Averaging on the link (linear) scale maintains consistency with the meaning of the fit parameters.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;[update] Perhaps &lt;em&gt;the&lt;/em&gt; reason for averaging on the response scale, at least in a Bayesian framework, is eq. 1 of Hoeting et al. 1999, which is&lt;/p&gt;
&lt;span class=&#34;math display&#34;&gt;\[\begin{equation}
\textrm{pr}(\Delta | D) = \sum_{k=1}^K \textrm{pr}(\Delta | M_k, D) \textrm{pr}(M_k | D)
\end{equation}\]&lt;/span&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\Delta\)&lt;/span&gt; is a prediction. For a GLM, these &lt;span class=&#34;math inline&#34;&gt;\(\Delta\)&lt;/span&gt; are on the response scale because the models are &lt;span class=&#34;math inline&#34;&gt;\(\textrm{E}(Y) = \mu = g^{-1}(X\beta)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Some final thoughts using equation S2 from Dormann et al. 2018&lt;/p&gt;
&lt;span class=&#34;math display&#34;&gt;\[\begin{equation}
\frac{1}{m} \sum_{i=1}^m{g^{-1}(Xb_i)} \ne g^{-1}(X \frac{\sum_{i=1}^m{b_i}}{m})
\end{equation}\]&lt;/span&gt;
&lt;ol start=&#34;3&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Dormann et al. advocate averaging using the LHS of eq. S2, I advocate using the RHS.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;If using the RHS of S2 to average predictors, &lt;a href=&#34;/2018/05/model-averaged-coefficients-of-a-glm&#34;&gt;then averaging the predictors or computing the predictor from averaged coefficients are mathematically equivalent&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;GLMs are unlike non-linear models in that non-linear models do not have link functions although some can be linearized. There is no linear model that is fit. Consquently, for non-linear models, averging the predictors of non-linear models on the “response scale” is consistent with the fit model. So in my opinion, this isn’t good justification for averaging GLMs on the response scale.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Because Carsten and Florian (and presumably the other co-authors of Dormann et al.) argue that predictions should be model averaged on the response scale, this raises questions about the default output for MuMIn and BAS which default to predictions on the link scale that were averaged on the link scale (both do produce predictions averaged on the response scale with type=‘response’). This raises one question and one concern. What “good” is a prediction averaged on the link scale – the default output of MuMIn and BAS? If we want a ma-prediction on the link scale, we can get this two ways: log transform the ma-predictions that were averaged on the response scale or simply average on the link scale. The second way does not produce predictions that are direct transformations with those on the response scale, so which is the correct way?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The concern raised above. The default prediction (if “type=” is not specified) for the MuMIn or BAS package is the prediction averaged on the link scale. Probably most researchers would want to interpret predictions on the response scale and the team that publishes this may achieve this by, perhaps naively, simply back-transforming the default predictions. This is the RHS of eq. S2. Someone comes along to reproduce the results, takes the same data, and specifies type=’response’. They get slightly different results, because they’ve used the LHS of eq. S1.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;I think this argument from Russell Lenth, the author of the amazingly useful emmeans (formerly lsmeans) package, supports my argument for averaging on the link scale. Here, Lenth comments on why &lt;a href=&#34;https://cran.r-project.org/web/packages/emmeans/vignettes/transformations.html&#34;&gt;the package computes marginal means on the link and not response scale for GLMs&lt;/a&gt;:&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;The model is our best guide&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;This choice of timing is based on the idea that the model is right. In particular, the fact that the response is transformed suggests that the transformed scale is the best scale to be working with. In addition, the model specifies that the effects of source and percent are linear on the transformed scale; inasmuch as marginal averaging to obtain EMMs is a linear operation, that averaging is best done on the transformed scale. For those two good reasons, back-transforming to the response scale is delayed until the very end by default.&amp;quot;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol start=&#34;9&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;The difference in predicted values computed on the link vs. response scale is trivially small for the example below, and perhaps in most real examples, and if this is the case, our argument doesn’t really matter. There are much bigger sources of error in modeling than this.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Finally, in response to an exchange with Florian, I wanted to make sure that my understanding of MuMIn is correct (it seems to be), so below are five ways to compute a simple count (poisson) example using fake data in addition to the computation from MuMIn.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Like MuMIn, The BAS package defaults to averaging on the link scale without back-transformation to the response scale – see the code at the bottom. Unlike MuMIn, BAS outputs the predictions on the response scale averaged on the response scale – these are not equal to the back-transformation of the default predictions on the link scale. I couldn’t find this documented.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;I also explore the BMA and AICcmodelavg packages.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div id=&#34;how-does-mumin-model-average-predictions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;How does MuMIn model average predictions?&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)
library(MuMIn)
library(BMA)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: survival&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: leaps&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: robustbase&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &amp;#39;robustbase&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following object is masked from &amp;#39;package:survival&amp;#39;:
## 
##     heart&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: inline&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: rrcov&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Scalable Robust Estimators with High Breakdown Point (version 1.4-3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(BAS)
library(AICcmodavg)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &amp;#39;AICcmodavg&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following objects are masked from &amp;#39;package:MuMIn&amp;#39;:
## 
##     AICc, DIC, importance&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(data.table)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A simple model of counts&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;  set.seed(1)
  n &amp;lt;- 100
  exp_beta_0 &amp;lt;- 175 # mean Y on response scale
  exp_beta_1 &amp;lt;- 0.99 # effect on response scale
  exp_beta_2 &amp;lt;- 0.99 # effect on response sacle
  
  # create correlated x1 and x2 due to common factor z
  z &amp;lt;- rnorm(n) # common factor to correlate X1 and X2
  r &amp;lt;- 0.6 # correlation between x1 and x2
  alpha &amp;lt;- sqrt(r) # &amp;quot;effect&amp;quot; of Z on X1 and X2
  x1 &amp;lt;- alpha*z + sqrt(1-r)*rnorm(n)
  x2 &amp;lt;- alpha*z + sqrt(1-r)*rnorm(n)

  # expected count in link space
  E_log_count &amp;lt;- log(exp_beta_0) + log(exp_beta_1)*x1 + log(exp_beta_2)*x2 # expected log count
  # observed counts
  count &amp;lt;- rpois(n=n, lambda=exp(E_log_count))

  # create data.table and fit 
  dt &amp;lt;- data.table(count=count, x1=x1, x2=x2)
  fit &amp;lt;- glm(count ~ x1 + x2, family=poisson(link = &amp;quot;log&amp;quot;), data=dt,na.action=na.fail )
  X &amp;lt;- model.matrix(fit)
  
  # all model regression using MuMIn
  fit.mm &amp;lt;- dredge(fit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Fixed term is &amp;quot;(Intercept)&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;  model_set &amp;lt;- get.models(fit.mm, subset=TRUE) # all models
  fit.avg &amp;lt;- model.avg(model_set) # coeffcients are on link scale
  fit.avg&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## model.avg(object = model_set)
## 
## Component models: 
## &amp;#39;2&amp;#39;      &amp;#39;12&amp;#39;     &amp;#39;1&amp;#39;      &amp;#39;(Null)&amp;#39;
## 
## Coefficients: 
##        (Intercept)          x2           x1
## full      5.168167 -0.02107276 -0.002326521
## subset    5.168167 -0.02288317 -0.007265122&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;  # (0) MuMIn predict
  yhat.default &amp;lt;- predict(fit.avg)
  yhat.MuMIn1 &amp;lt;- predict(fit.avg, type=&amp;#39;response&amp;#39;)
  yhat.MuMIn2 &amp;lt;- exp(predict(fit.avg, type=&amp;#39;link&amp;#39;))
  yhat.MuMIn3 &amp;lt;- predict(fit.avg, backtransform=TRUE)
  yhat.MuMIn4 &amp;lt;- exp(predict(fit.avg, backtransform=FALSE))
  head(data.table(default=exp(yhat.default),
                  MuMIn1=yhat.MuMIn1, 
                  MuMIn2=yhat.MuMIn2,
                  MuMIn3=yhat.MuMIn3,
                  MuMIn4=yhat.MuMIn4
                  ))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     default   MuMIn1   MuMIn2   MuMIn3   MuMIn4
## 1: 176.7927 176.7934 176.7927 176.7927 176.7927
## 2: 171.1034 171.1072 171.1034 171.1034 171.1034
## 3: 174.7764 174.7805 174.7764 174.7764 174.7764
## 4: 171.3024 171.3036 171.3024 171.3024 171.3024
## 5: 180.1184 180.1233 180.1184 180.1184 180.1184
## 6: 171.9407 171.9422 171.9407 171.9407 171.9407&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;  #is this averaged on link or response scale? And is it the coefficients or the prediction that is averaged?
  
  # (1) average coefficients on link scale. compute prediction on link scale. transform predictions to response scale
  b &amp;lt;- fit.avg$coefficients[&amp;#39;full&amp;#39;,][colnames(X)]
  yhat1 &amp;lt;- exp((X%*%b)[,1]) #
  b_ma_link &amp;lt;- b

  # (2) compute predictions for each model on link scale. Average on link scale. Backtransform to response scale
  yhat2a &amp;lt;- exp(predict(fit.avg, backtransform=FALSE))
  w &amp;lt;- fit.mm$weight
  yhat2b.each_model.link_scale &amp;lt;- sapply(model_set, predict)
  yhat2b.link_scale &amp;lt;- (yhat2b.each_model.link_scale%*%w)[,1]
  yhat2b &amp;lt;- exp(yhat2b.link_scale)
  
  # (3) compute predictions for each model on link scale. Backtransform to response scale. Average on response scale. This is method of Dormann et al.
  yhat3.each_model.response_scale &amp;lt;- exp(yhat2b.each_model.link_scale)
  yhat3 &amp;lt;- (yhat3.each_model.response_scale%*%w)[,1]
  
  # (4) backtransform coefficients to response scale. Average coefficients on response scale. Compute prediction on response scale.
  B &amp;lt;- exp(fit.mm[,colnames(X)])
  B[is.na(B)] &amp;lt;- 0.0
  b_ma &amp;lt;- t(B)%*%w
  yhat4 &amp;lt;- (X%*%b_ma)[,1] #

  # (5) average coefficients on link scale. backtransform to response scale. compute prediction on response scale
  b &amp;lt;- exp(fit.avg$coefficients[&amp;#39;full&amp;#39;,][colnames(X)])
  yhat5 &amp;lt;- (X%*%b)[,1] #&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;results&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Results&lt;/h3&gt;
&lt;p&gt;The first few rows of the results matrix of the predictions using five different methods for their computation.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##       MuMIn MuMIn.rs    yhat1    yhat2    yhat3    yhat4    yhat5
## 1: 176.7927 176.7934 176.7927 176.7927 176.7934 175.1100 174.4955
## 2: 171.1034 171.1072 171.1034 171.1034 171.1072 176.7358 176.9463
## 3: 174.7764 174.7805 174.7764 174.7764 174.7805 175.5243 174.7209
## 4: 171.3024 171.3036 171.3024 171.3024 171.3036 176.9411 177.9302
## 5: 180.1184 180.1233 180.1184 180.1184 180.1233 174.4711 174.2690
## 6: 171.9407 171.9422 171.9407 171.9407 171.9422 176.5958 176.9982&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Column Keys&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;MuMIn = MuMIn’s default prediction backtransformed to response scale&lt;/p&gt;
&lt;p&gt;MuMIn.rs = MuMIn with type = ‘response’&lt;/p&gt;
&lt;p&gt;yhat1 = Coefficients averaged on link scale. Predictions computed on link scale from averaged coefficients and then backtransformed to response scale. My preferred method. RHS of eq. S2.&lt;/p&gt;
&lt;p&gt;yhat2 = Predictions computed on link scale for each model and then averaged on link scale and then backtransformed to response scale. Alternative to my preferred method.&lt;/p&gt;
&lt;p&gt;yhat3 = Predictions computed on link scale for each model and then backtransformed to response scale and then averaged on response scale. This is the method of Dormann et al. 2018 and Cade 2015&lt;/p&gt;
&lt;p&gt;yhat4 = Coefficients backtransformed to response scale and then averaged on response scale. Predictions computed on response scale from averaged coefficients.&lt;/p&gt;
&lt;p&gt;yhat5 = Coefficients averaged on link scale and then backtransformed to response scale, which are used to compute averaged predictions.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;how-does-bic.glm-model-average-predictions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;How does bic.glm model average predictions?&lt;/h2&gt;
&lt;p&gt;This simulation uses the fake data generated above.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit.bma &amp;lt;- bic.glm(count ~ x1 + x2, glm.family=poisson(link = &amp;quot;log&amp;quot;), data=dt)
# (0) BMA predict
yhat.default &amp;lt;- predict(fit.bma, newdata=dt) # these are on the response scale

# (1) use model averaged B to get prediction on link scale. Backtransform to response scale (eq. s2 RHS of appendix)
b = fit.bma$postmean
Xb &amp;lt;- X%*%b
yhat1 &amp;lt;- exp(Xb) # averaged predictions backtransformed to response

res &amp;lt;- data.table(default=yhat.default, yhat1=yhat1)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;how-does-the-bas-package-model-average-predictions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;How does the BAS package model-average predictions?&lt;/h2&gt;
&lt;p&gt;This simulation uses the fake data generated above.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;  # fit using BMA
  packageVersion(&amp;quot;BAS&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;#39;1.5.0&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;  # fit &amp;lt;- glm(count ~ x1 + x2, family=poisson(link = &amp;quot;log&amp;quot;), data=dt,na.action=na.fail )
  fit.bma &amp;lt;- bas.glm(count ~ x1 + x2, family=poisson(link = &amp;quot;log&amp;quot;), data=dt)
 
  res.bma.rs &amp;lt;- predict(fit.bma, type=&amp;#39;response&amp;#39;)
  res.bma0.rs &amp;lt;- res.bma.rs$fit[,1]
  res.bma1.rs.ls &amp;lt;- res.bma.rs$Ybma[,1]
  res.bma1.rs.exp.ls &amp;lt;- exp(res.bma1.rs.ls)
  
  res.bma.ls &amp;lt;- predict(fit.bma)
  res.bma0.ls &amp;lt;- res.bma.ls$fit[,1]
  res.bma1.ls.ls &amp;lt;- res.bma.ls$Ybma[,1]
  res.bma1.ls.exp.ls &amp;lt;- exp(res.bma1.ls.ls)
  
  
  bas.res1 &amp;lt;- data.table(
    default.fit=res.bma0.ls,
    default.Ybma=res.bma1.ls.ls,
    default.exp.Ybma=res.bma1.ls.exp.ls,
    response.fit=res.bma0.rs,
    response.Ybma=res.bma1.rs.ls,
    response.exp.Ybma=res.bma1.rs.exp.ls
  )
  
  res.bma &amp;lt;- predict(fit.bma)
  yhat.bma.response &amp;lt;- res.bma$fit[,1]
  yhat.bma.link &amp;lt;- res.bma$Ybma[,1]
  YHAT &amp;lt;- t(res.bma$Ypred)
  w &amp;lt;- res.bma$postprobs
  # averaged on response scale
  yhat1.bma.response &amp;lt;- (exp(YHAT)%*%w)[,1]
  # averaged on link scale and then backtransformed
  yhat2.bma.link &amp;lt;- (YHAT%*%w)[,1]
  yhat2.bma.response &amp;lt;- exp(yhat2.bma.link)

  bas.res2 &amp;lt;- data.table(yhat0=yhat.bma.response,
             yhat1=yhat1.bma.response,
             yhat2=yhat2.bma.response)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;result-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Result 1&lt;/h3&gt;
&lt;p&gt;predict.basglm seems to have the same output regardless of the type=‘response’ specification. The prediction on the link scale is in “Ybma” and the prediction on the response scale is in “fit”. Note that &lt;span class=&#34;math inline&#34;&gt;\(exp(Ybma) \ne fit\)&lt;/span&gt;. s&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(bas.res1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    default.fit default.Ybma default.exp.Ybma response.fit response.Ybma
## 1:    176.5610     5.173649         176.5580     176.5610      5.173649
## 2:    173.0640     5.153591         173.0518     173.0640      5.153591
## 3:    175.7336     5.168932         175.7271     175.7336      5.168932
## 4:    172.5097     5.150390         172.4988     172.5097      5.150390
## 5:    177.8421     5.180803         177.8256     177.8421      5.180803
## 6:    173.3129     5.155058         173.3059     173.3129      5.155058
##    response.exp.Ybma
## 1:          176.5580
## 2:          173.0518
## 3:          175.7271
## 4:          172.4988
## 5:          177.8256
## 6:          173.3059&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;result-2&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Result 2&lt;/h3&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(fit\)&lt;/span&gt; is indeed the predictions averaged on the response scale and not &lt;span class=&#34;math inline&#34;&gt;\(exp(Ybma)\)&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(bas.res2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       yhat0    yhat1    yhat2
## 1: 176.5610 176.5610 176.5580
## 2: 173.0640 173.0640 173.0518
## 3: 175.7336 175.7336 175.7271
## 4: 172.5097 172.5097 172.4988
## 5: 177.8421 177.8421 177.8256
## 6: 173.3129 173.3129 173.3059&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Key:&lt;/p&gt;
&lt;p&gt;yhat0 - “fit”, which is the prediction on the response scale&lt;/p&gt;
&lt;p&gt;yhat1 - my manual computation of the average on the response scale&lt;/p&gt;
&lt;p&gt;yhat2 - my manual computation of the average on the link scale and then back-transformed to the response scale.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;how-does-the-aiccmodavg-package-model-average-predictions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;How does the AICcmodavg package model-average predictions?&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(min.trap)
##assign &amp;quot;UPLAND&amp;quot; as the reference level as in Mazerolle (2006)
min.trap$Type &amp;lt;- relevel(min.trap$Type, ref = &amp;quot;UPLAND&amp;quot;)
##set up candidate models
Cand.mod &amp;lt;- list()
Cand.mod[[1]] &amp;lt;- glm(Num_anura ~ Type + log.Perimeter + Num_ranatra,
                     family = poisson, offset = log(Effort),
                     data = min.trap)
Cand.mod[[2]] &amp;lt;- glm(Num_anura ~ Type + log.Perimeter, family = poisson,
                     offset = log(Effort), data = min.trap)
Cand.mod[[3]] &amp;lt;- glm(Num_anura ~ Type + Num_ranatra, family = poisson,
                     offset = log(Effort), data = min.trap)
Cand.mod[[4]] &amp;lt;- glm(Num_anura ~ Type, family = poisson,
                     offset = log(Effort), data = min.trap)
Cand.mod[[5]] &amp;lt;- glm(Num_anura ~ log.Perimeter + Num_ranatra,
                     family = poisson, offset = log(Effort),
                     data = min.trap)

Cand.mod[[6]] &amp;lt;- glm(Num_anura ~ log.Perimeter, family = poisson,
                     offset = log(Effort), data = min.trap)
Cand.mod[[7]] &amp;lt;- glm(Num_anura ~ Num_ranatra, family = poisson,
                     offset = log(Effort), data = min.trap)
Cand.mod[[8]] &amp;lt;- glm(Num_anura ~ 1, family = poisson,
                     offset = log(Effort), data = min.trap)
##check c-hat for global model
c_hat(Cand.mod[[1]], method = &amp;quot;pearson&amp;quot;) #uses Pearson&amp;#39;s chi-square/df&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;#39;c-hat&amp;#39; 1.04 (method: pearson estimator)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;##note the very low overdispersion: in this case, the analysis could be
##conducted without correcting for c-hat as its value is reasonably close
##to 1
##assign names to each model
Modnames &amp;lt;- c(&amp;quot;type + logperim + invertpred&amp;quot;, &amp;quot;type + logperim&amp;quot;,
              &amp;quot;type + invertpred&amp;quot;, &amp;quot;type&amp;quot;, &amp;quot;logperim + invertpred&amp;quot;,
              &amp;quot;logperim&amp;quot;, &amp;quot;invertpred&amp;quot;, &amp;quot;intercept only&amp;quot;)
##model selection table based on AICc
aictab(cand.set = Cand.mod, modnames = Modnames)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Model selection based on AICc:
## 
##                              K  AICc Delta_AICc AICcWt Cum.Wt     LL
## type + invertpred            3 54.03       0.00   0.60   0.60 -23.42
## type + logperim + invertpred 4 56.57       2.54   0.17   0.77 -23.23
## logperim + invertpred        3 57.91       3.88   0.09   0.86 -25.35
## invertpred                   2 58.63       4.60   0.06   0.92 -27.03
## type + logperim              3 59.38       5.35   0.04   0.96 -26.09
## type                         2 59.74       5.71   0.03   1.00 -27.58
## intercept only               1 65.47      11.44   0.00   1.00 -31.65
## logperim                     2 67.27      13.24   0.00   1.00 -31.35&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat.pred &amp;lt;- data.frame(Type = factor(c(&amp;quot;BOG&amp;quot;, &amp;quot;UPLAND&amp;quot;)),
                       log.Perimeter = mean(min.trap$log.Perimeter),
                       Num_ranatra = mean(min.trap$Num_ranatra),
                       Effort = mean(min.trap$Effort))
yhat.response &amp;lt;- modavgPred(cand.set = Cand.mod, modnames = Modnames,
           newdata = min.trap, type = &amp;quot;response&amp;quot;)
yhat.link &amp;lt;- modavgPred(cand.set = Cand.mod, modnames = Modnames,
           newdata = min.trap, type = &amp;quot;link&amp;quot;)
yhat.default &amp;lt;- modavgPred(cand.set = Cand.mod, modnames = Modnames,
           newdata = min.trap)

res &amp;lt;- data.table(response=yhat.response$mod.avg.pred, 
                  link=exp(yhat.link$mod.avg.pred),
                  default=yhat.default$mod.avg.pred)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Cade, B.S. (2015). Model averaging and muddled multimodel inferences. Ecology 96, 2370–2382.&lt;a href=&#34;#fnref1&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>