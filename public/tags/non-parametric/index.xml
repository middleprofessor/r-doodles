<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Non Parametric on R Doodles</title>
    <link>/tags/non-parametric/</link>
    <description>Recent content in Non Parametric on R Doodles</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 08 Aug 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/non-parametric/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>What is the consequence of a Shapiro-Wilk test-of-normality filter on Type I error and Power?</title>
      <link>/2019/08/what-is-the-consequence-of-a-shapiro-wilk-test-of-normality-filter-on-type-i-error-and-power/</link>
      <pubDate>Thu, 08 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/08/what-is-the-consequence-of-a-shapiro-wilk-test-of-normality-filter-on-type-i-error-and-power/</guid>
      <description>TL;DR – Meh. Using a Shapiro-Wilk filter isn’t going to lead to either better or worse inference. That said, there are more powerful methods than a t-test on log-transformed data or Mann-Whitney-Wilcoxan.. Any update will include a test using a generalized linear model estimate of the effect and uncertainty.
And of course, none of this addresses estimation itself, just the NHST approach to discovery. This quote is relevant:
“The major limitation on the t-test and linear regression for inference about associations is not a distributional one, but whether detecting and estimating a difference in the mean of the outcome answers the scientific question at hand.</description>
    </item>
    
    <item>
      <title>GLM vs. t-tests vs. non-parametric tests if all we care about is NHST -- Update</title>
      <link>/2019/05/glm-vs-t-tests-vs-non-parametric-tests-if-all-we-care-about-is-nhst-update/</link>
      <pubDate>Thu, 30 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/05/glm-vs-t-tests-vs-non-parametric-tests-if-all-we-care-about-is-nhst-update/</guid>
      <description>Update to the earlier post, which was written in response to my own thinking about how to teach stastics to experimental biologists working in fields that are dominated by hypothesis testing instead of estimation. That is, should these researchers learn GLMs or is a t-test on raw or log-transformed data on something like count data good enough – or even superior? My post was written without the benefit of either [Ives](Ives, Anthony R.</description>
    </item>
    
    <item>
      <title>GLM vs. t-tests vs. non-parametric tests if all we care about is NHST</title>
      <link>/2019/01/glm-vs-non-parametric-tests-if-all-we-care-about-is-nhst/</link>
      <pubDate>Mon, 07 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/01/glm-vs-non-parametric-tests-if-all-we-care-about-is-nhst/</guid>
      <description>This post has been updated.
A skeleton simulation of different strategies for NHST for count data if all we care about is a p-value, as in bench biology where p-values are used to simply give one confidence that something didn’t go terribly wrong (similar to doing experiments in triplicate – it’s not the effect size that matters only “we have experimental evidence of a replicable effect”).
tl;dr - At least for Type I error at small \(n\), log(response) and Wilcoxan have the best performance over the simulation space.</description>
    </item>
    
  </channel>
</rss>