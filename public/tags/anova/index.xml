<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Anova on R Doodles</title>
    <link>/tags/anova/</link>
    <description>Recent content in Anova on R Doodles</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 02 Jul 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/anova/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Is the power to test an interaction effect less than that for a main effect?</title>
      <link>/2019/07/is-the-power-to-test-an-interaction-effect-less-than-that-for-a-main-effect/</link>
      <pubDate>Tue, 02 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/07/is-the-power-to-test-an-interaction-effect-less-than-that-for-a-main-effect/</guid>
      <description>I was googling around and somehow landed on a page that stated “When effect coding is used, statistical power is the same for all regression coefficients of the same size, whether they correspond to main effects or interactions, and irrespective of the order of the interaction”. Really? How could this be? The p-value for an interaction effect is the same regardless of dummy or effects coding, and, with dummy coding (R’s default), the power of the interaction effect is less than that of the coefficients for the main factors when they have the same magnitude, so my intuition said this statement must be wrong.</description>
    </item>
    
  </channel>
</rss>