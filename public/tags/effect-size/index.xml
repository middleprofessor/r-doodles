<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Effect Size on R Doodles</title>
    <link>/tags/effect-size/</link>
    <description>Recent content in Effect Size on R Doodles</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 16 Oct 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/effect-size/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Normalization results in regression to the mean</title>
      <link>/2019/10/normalization-results-in-regression-to-the-mean/</link>
      <pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/10/normalization-results-in-regression-to-the-mean/</guid>
      <description>I’m trying to understand the role of statistics in experimental (cell, micro) biology because I’m working with students and PIs who do this type of research. This led me to thinking about reproducibility which led me to the cancer reproducibility project. What a terrific site.
I downloaded the article and data for Fig 1C for Replication Study: Melanoma exosomes educate bone marrow progenitor cells toward a pro-metastatic phenotype through MET just to explore.</description>
    </item>
    
    <item>
      <title>What is the bias in the estimation of an effect given an omitted interaction term?</title>
      <link>/2019/07/what-is-bias-in-the-estimation-of-an-effect-giving-an-omitted-interaction-term/</link>
      <pubDate>Wed, 31 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/07/what-is-bias-in-the-estimation-of-an-effect-giving-an-omitted-interaction-term/</guid>
      <description>Some background (due to Sewall Wright’s method of path analysis) Given a generating model:
\[\begin{equation} y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 \end{equation}\] where \(x_3 = x_1 x_2\); that is, it is an interaction variable.
The total effect of \(x_1\) on \(y\) is \(\beta_1 + \frac{\mathrm{COV}(x_1, x_2)}{\mathrm{VAR}(x_1)} \beta_2 + \frac{\mathrm{COV}(x_1, x_3)}{\mathrm{VAR}(x_1)} \beta_3\).
If \(x_3\) (the interaction) is missing, its component on the total efffect is added to the coefficient of \(x_1\).</description>
    </item>
    
    <item>
      <title>Should we be skeptical of a &#34;large&#34; effect size if p &gt; 0.05?</title>
      <link>/2019/05/should-we-be-skeptical-of-a-large-effect-size-if-p-0-05/</link>
      <pubDate>Tue, 28 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/05/should-we-be-skeptical-of-a-large-effect-size-if-p-0-05/</guid>
      <description>Motivator: A twitter comment “Isn’t the implication that the large effect size is a direct byproduct of the lack of power? i.e. that if the the study had more power, the effect size would have been found to be smaller.”1 2
A thought: our belief in the magnitude of an observed effect should be based on our priors, which, hopefully, are formed from good mechanistic models and not sample size“.</description>
    </item>
    
    <item>
      <title>Reporting effects as relative differences...with a confidence interval</title>
      <link>/2018/11/reporting-effects-as-relative-differences-with-a-confidence-interval/</link>
      <pubDate>Wed, 14 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/11/reporting-effects-as-relative-differences-with-a-confidence-interval/</guid>
      <description>Researchers frequently report results as relative effects, for example,
“Male flies from selected lines had 50% larger upwind flight ability than male flies from control lines (Control mean: 117.5 cm/s; Selected mean 176.5 cm/s).”
where a relative effect is
\[\begin{equation} 100 \frac{\bar{y}_B - \bar{y}_A}{\bar{y}_A} \end{equation}\] If we are to follow best practices, we should present this effect with a measure of uncertainty, such as a confidence interval. The absolute effect is 59.</description>
    </item>
    
    <item>
      <title>Combining data, distribution summary, model effects, and uncertainty in a single plot</title>
      <link>/2018/03/combining-data-distribution-summary-model-effects-and-uncertainty-in-a-single-plot/</link>
      <pubDate>Tue, 27 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/03/combining-data-distribution-summary-model-effects-and-uncertainty-in-a-single-plot/</guid>
      <description>A Harrell plot combines a forest plot of estimated treatment effects and uncertainty, a dot plot of raw data, and a box plot of the distribution of the raw data into a single plot. A Harrell plot encourages best practices such as exploration of the distribution of the data and focus on effect size and uncertainty, while discouraging bad practices such as ignoring distributions and focusing on \(p\)-values. Consequently, a Harrell plot should replace the bar plots and Cleveland dot plots that are currently ubiquitous in the literature.</description>
    </item>
    
  </channel>
</rss>