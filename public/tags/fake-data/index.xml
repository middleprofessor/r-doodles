<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Fake Data on R Doodles</title>
    <link>/tags/fake-data/</link>
    <description>Recent content in Fake Data on R Doodles</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 30 May 2019 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="/tags/fake-data/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>GLM vs. t-tests vs. non-parametric tests if all we care about is NHST -- Update</title>
      <link>/2019/05/glm-vs-t-tests-vs-non-parametric-tests-if-all-we-care-about-is-nhst-update/</link>
      <pubDate>Thu, 30 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/05/glm-vs-t-tests-vs-non-parametric-tests-if-all-we-care-about-is-nhst-update/</guid>
      <description>


&lt;p&gt;&lt;a href=&#34;../../../2019/01/glm-vs-non-parametric-tests-if-all-we-care-about-is-nhst/&#34;&gt;Update to the earlier post&lt;/a&gt;, which was written in response to my own thinking about how to teach stastics to experimental biologists working in fields that are dominated by hypothesis testing instead of estimation. That is, should these researchers learn GLMs or is a t-test on raw or log-transformed data on something like count data good enough – or even superior? My post was written without the benefit of either [Ives](Ives, Anthony R. “For testing the significance of regression coefficients, go ahead and log‐transform count data.” Methods in Ecology and Evolution 6, no. 7 (2015): 828-835) or &lt;a href=&#34;Warton,%20D.I.,%20Lyons,%20M.,%20Stoklosa,%20J.%20and%20Ives,%20A.R.,%202016.%20Three%20points%20to%20consider%20when%20choosing%20a%20LM%20or%20GLM%20test%20for%20count%20data.%20Methods%20in%20Ecology%20and%20Evolution,%207(8),%20pp.882-890&#34;&gt;Warton et al.&lt;/a&gt;. With hindsight, I do vaguely recall Ives, and my previous results support his conclusions, but I was unaware of Warton.&lt;/p&gt;
&lt;p&gt;Warton et al is a fabulous paper. A must read. A question that I have is, &lt;em&gt;under the null&lt;/em&gt; isn’t the response itself exchangeable, so that residuals are unnecessary? Regardless, the implementation in the mvabund package is way faster than my own R-scripted permutation. So here is my earlier simulation in light of Warton et al.&lt;/p&gt;
&lt;p&gt;TL;DR – If we live and die by NHST, then we want to choose a test with good Type I error control but has high power. The quasi-poisson both estimates an interpretable effect (unlike a t-test of log(y +1)) and has good Type I control with high power.&lt;/p&gt;
&lt;p&gt;A bit longer: The quasi-poisson LRT and the permutation NB have good Type I control and high power. The NB Wald and LRT have too liberal Type I control. The t-test of log response has good Type I control and high power at low &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; but is slightly inferior to the glm with increased &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;. The t-test, Welch, and Wilcoxan have conservative Type I control. Of these, the Wilcoxan has higher power than the t-test and Welch but not as high as the GLMs or log-transformed response.&lt;/p&gt;
&lt;div id=&#34;load-libraries&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;load libraries&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)
library(ggpubr)
library(MASS)
library(mvabund)
library(lmtest)
library(nlme)
library(data.table)
library(cowplot)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;the-simulation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The simulation&lt;/h2&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Single factor with two levels and a count (negative binomial) response.&lt;/li&gt;
&lt;li&gt;Relative effect sizes of 0%, 100%, and 200%&lt;/li&gt;
&lt;li&gt;Ref count of 4&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; of 5 and 10&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;em&gt;p&lt;/em&gt;-values computed from&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;t-test on raw response&lt;/li&gt;
&lt;li&gt;Welch t-test on raw response&lt;/li&gt;
&lt;li&gt;t-test on log transformed response&lt;/li&gt;
&lt;li&gt;Wilcoxan test&lt;/li&gt;
&lt;li&gt;glm with negative binomial family and log-link using Wald test&lt;/li&gt;
&lt;li&gt;glm with negative binomial family and log-link using LRT&lt;/li&gt;
&lt;li&gt;glm with negative binomial family and permutation test (using PIT residuals)&lt;a href=&#34;#fn1&#34; class=&#34;footnoteRef&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;glm with quasi-poisson family and log-link using LRT&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;do_sim &amp;lt;- function(sim_space=NULL, niter=1000, nperm=1000, algebra=FALSE){
  # the function was run with n=1000 and the data saved. on subsequent runs
  # the data are loaded from a file
  # the function creates three different objects to return, the object
  # return is specified by &amp;quot;return_object&amp;quot; = NULL, plot_data1, plot_data2
  
  set.seed(1)
  
  methods &amp;lt;- c(&amp;quot;t&amp;quot;, &amp;quot;Welch&amp;quot;, &amp;quot;log&amp;quot;, &amp;quot;Wilcoxan&amp;quot;, &amp;quot;nb&amp;quot;, &amp;quot;nb.x2&amp;quot;, &amp;quot;nb.perm&amp;quot;, &amp;quot;qp&amp;quot;)
  p_table &amp;lt;- data.table(NULL)
  
  if(is.null(sim_space)){
    mu_0_list &amp;lt;- c(4) # control count
    theta_list &amp;lt;- c(0.5) # dispersion
    effect_list &amp;lt;- c(1) # effect size will be 1X, 1.5X, 2X, 3X
    n_list &amp;lt;- c(10) # sample size
    sim_space &amp;lt;- data.table(expand.grid(theta=theta_list, mu_0=mu_0_list, effect=effect_list, n=n_list))
  }
  
  res_table &amp;lt;- data.table(NULL)
  i &amp;lt;- 1 # this is just for debugging
  for(i in 1:nrow(sim_space)){
    # construct clean results table 
    p_table_part &amp;lt;- matrix(NA, nrow=niter, ncol=length(methods))
    colnames(p_table_part) &amp;lt;- methods
    
    # parameters of simulation
    theta_i &amp;lt;- sim_space[i, theta]
    mu_0_i &amp;lt;- sim_space[i, mu_0]
    effect_i &amp;lt;- sim_space[i, effect]
    n_i &amp;lt;- sim_space[i, n]
    treatment &amp;lt;- rep(c(&amp;quot;Cn&amp;quot;, &amp;quot;Trt&amp;quot;), each=n_i)
    fd &amp;lt;- data.table(treatment=treatment)
    
    # mu (using algebra)
    if(algebra==TRUE){
      X &amp;lt;- model.matrix(~treatment)
      beta_0 &amp;lt;- log(mu_0_i)
      beta_1 &amp;lt;- log(effect_i*mu_0_i) - beta_0
      beta &amp;lt;- c(beta_0, beta_1)
      mu_i &amp;lt;- exp((X%*%beta)[,1])
    }else{ #  using R
      mu_vec &amp;lt;- c(mu_0_i, mu_0_i*effect_i)
      mu_i &amp;lt;- rep(mu_vec, each=n_i)
    }
    nb.error &amp;lt;- numeric(niter)
    
    for(iter in 1:niter){
      set.seed(niter*(i-1) + iter)
      fd[, y:=rnegbin(n=n_i*2, mu=mu_i, theta=theta_i)]
      fd[, log_yp1:=log10(y+1)]
      
      p.t &amp;lt;- t.test(y~treatment, data=fd, var.equal=TRUE)$p.value
      p.welch &amp;lt;- t.test(y~treatment, data=fd, var.equal=FALSE)$p.value
      p.log &amp;lt;- t.test(log_yp1~treatment, data=fd, var.equal=TRUE)$p.value
      p.wilcox &amp;lt;- wilcox.test(y~treatment, data=fd, exact=FALSE)$p.value
      
      # weighted lm, this will be ~same as welch for k=2 groups
      # fit &amp;lt;- gls(y~treatment, data=fd, weights = varIdent(form=~1|treatment), method=&amp;quot;ML&amp;quot;)
      # p.wls &amp;lt;- coef(summary(fit))[&amp;quot;treatmentTrt&amp;quot;, &amp;quot;p-value&amp;quot;]
      
      # negative binomial
      # default test using summary is Wald.
      # anova(fit) uses chisq of sequential fit, but using same estimate of theta
      # anova(fit2, fit1), uses chisq but with different estimate of theta
      # lrtest(fit) same as anova(fit2, fit1)
      
      # m1 &amp;lt;- glm.nb(y~treatment, data=fd)
      # m0 &amp;lt;- glm.nb(y~1, data=fd)
      # p.nb.x2 &amp;lt;- anova(m0, m1)[2, &amp;quot;Pr(Chi)&amp;quot;]
      # lr &amp;lt;- 2*(logLik(m1) - logLik(m0))
      # df.x2 = m0$df.residual-m1$df.residual
      # p.nb.x2 &amp;lt;- pchisq(lr, df=df.x2, lower.tail = F)
                
      m1 &amp;lt;- manyglm(y~treatment, data=fd) # default theta estimation &amp;quot;PHI&amp;quot;
      m0 &amp;lt;- manyglm(y~1, data=fd)
      lr &amp;lt;- 2*(logLik(m1) - logLik(m0))
      df.x2 = m0$df.residual-m1$df.residual
      p.nb &amp;lt;- coef(summary(m1))[&amp;quot;treatmentTrt&amp;quot;, &amp;quot;Pr(&amp;gt;wald)&amp;quot;] # Wald
      p.nb.x2 &amp;lt;- as.numeric(pchisq(lr, df=df.x2, lower.tail = F))
      p.nb.perm &amp;lt;- (anova(m0, m1, nBoot=nperm, show.time=&amp;#39;none&amp;#39;, p.uni=&amp;quot;unadjusted&amp;quot;)$uni.p)[2,1]

      # p.nb.x2 &amp;lt;- lrtest(fit)[2, &amp;quot;Pr(&amp;gt;Chisq)&amp;quot;] # doesn&amp;#39;t work with a data.table
      
      # quasipoisson
      fit &amp;lt;- glm(y~treatment, data=fd, family=quasipoisson)
      p.qp &amp;lt;- coeftest(fit)[2, &amp;quot;Pr(&amp;gt;|z|)&amp;quot;]
      
      p_table_part[iter,] &amp;lt;- c(p.t, p.welch, p.log, p.wilcox, p.nb, p.nb.x2, p.nb.perm, p.qp)
      
    } # niter
    p_table &amp;lt;- rbind(p_table, data.table(combo=i,
                                         mu_0=mu_0_i,
                                         effect=effect_i,
                                         n=n_i,
                                         theta=theta_i,
                                         nb.error=nb.error,
                                         p_table_part))
    
  } # combos
  
  return(p_table)
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Algebra is slower (duh!)
# start_time &amp;lt;- Sys.time()
# do_sim(niter=niter, algebra=FALSE)
# end_time &amp;lt;- Sys.time()
# end_time - start_time
# 
# start_time &amp;lt;- Sys.time()
# do_sim(niter=niter, algebra=TRUE)
# end_time &amp;lt;- Sys.time()
# end_time - start_time

n_iter &amp;lt;- 2000
n_perm &amp;lt;- 2000
mu_0_list &amp;lt;- c(4) # control count
theta_list &amp;lt;- c(0.5) # dispersion
effect_list &amp;lt;- c(1, 2, 4) # effect size will be 1X, 1.5X, 2X, 3X
n_list &amp;lt;- c(5, 10) # sample size
sim_space &amp;lt;- data.table(expand.grid(theta=theta_list, mu_0=mu_0_list, effect=effect_list, n=n_list))

do_it &amp;lt;- FALSE # if FALSE the results are available as a file
if(do_it==TRUE){
  p_table &amp;lt;- do_sim(sim_space, niter=n_iter, nperm=n_perm)
  write.table(p_table, &amp;quot;../output/glm-v-lm.0004.txt&amp;quot;, row.names = FALSE, quote=FALSE)
}else{
  p_table &amp;lt;- fread(&amp;quot;../output/glm-v-lm.0001.txt&amp;quot;)
  p_table[, combo:=paste(effect, n, sep=&amp;quot;-&amp;quot;)]
  ycols &amp;lt;- setdiff(colnames(p_table), c(&amp;quot;combo&amp;quot;, &amp;quot;mu_0&amp;quot;, &amp;quot;effect&amp;quot;, &amp;quot;n&amp;quot;, &amp;quot;theta&amp;quot;))
  res_table &amp;lt;- data.table(NULL)
  for(i in p_table[, unique(combo)]){
    p_table_part &amp;lt;- p_table[combo==i, ]
    mu_0_i &amp;lt;- p_table_part[1, mu_0]
    effect_i &amp;lt;- p_table_part[1, effect]
    n_i &amp;lt;- p_table_part[1, n]
    theta_i &amp;lt;- p_table_part[1, theta]
    n_iter_i &amp;lt;- nrow(p_table_part)
    p_sum &amp;lt;- apply(p_table_part[, .SD, .SDcols=ycols], 2, function(x) length(which(x &amp;lt;= 0.05))/n_iter_i)
    res_table &amp;lt;- rbind(res_table, data.table(mu_0 = mu_0_i,
                                             effect = effect_i,
                                             n = n_i,
                                             theta = theta_i,
                                             t(p_sum)))    
  }
  res_table[, n:=factor(n)]
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;type-i-error&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Type I error&lt;/h1&gt;
&lt;p&gt;Key: 1. “nb” uses the Wald test of negative binomial model. 2. “nb.x2” uses the LRT of negative binomial model. 3. “nb.perm” uses a permutation test on PIT residuals of negative binomial model 4. qp uses a LRT of quasi-poisson model&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;knitr::kable(res_table[effect==1,],
             caption = &amp;quot;Type 1 error as a function of n&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;caption&gt;&lt;span id=&#34;tab:type-1-table&#34;&gt;Table 1: &lt;/span&gt;Type 1 error as a function of n&lt;/caption&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;right&#34;&gt;mu_0&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;effect&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;n&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;theta&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;nb.error&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;t&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Welch&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;log&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Wilcoxan&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;nb&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;nb.x2&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;nb.perm&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;qp&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.032&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0175&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0475&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0270&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1280&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1015&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0515&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.054&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.036&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0295&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0505&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0435&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0675&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0695&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0460&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.053&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;power&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Power&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;knitr::kable(res_table[effect!=1,],
             caption = &amp;quot;Power as a function of n&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;caption&gt;&lt;span id=&#34;tab:unnamed-chunk-1&#34;&gt;Table 2: &lt;/span&gt;Power as a function of n&lt;/caption&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;right&#34;&gt;mu_0&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;effect&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;n&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;theta&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;nb.error&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;t&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Welch&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;log&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Wilcoxan&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;nb&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;nb.x2&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;nb.perm&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;qp&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0465&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0240&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0845&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0540&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1710&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1565&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0825&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0960&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1055&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0475&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1950&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1310&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.3310&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.3295&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1860&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1800&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0900&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0750&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1150&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1025&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1730&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1850&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1285&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1480&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.3120&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.2600&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.3780&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.3235&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5255&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5345&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.4190&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.4405&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;plot&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;plot&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;res &amp;lt;- melt(res_table, 
            id.vars=c(&amp;quot;mu_0&amp;quot;, &amp;quot;effect&amp;quot;, &amp;quot;n&amp;quot;, &amp;quot;theta&amp;quot;, &amp;quot;nb.error&amp;quot;),
            measure.vars=c(&amp;quot;t&amp;quot;, &amp;quot;Welch&amp;quot;, &amp;quot;log&amp;quot;, &amp;quot;Wilcoxan&amp;quot;, &amp;quot;nb&amp;quot;, &amp;quot;nb.x2&amp;quot;, &amp;quot;nb.perm&amp;quot;, &amp;quot;qp&amp;quot;),
            variable.name=&amp;quot;model&amp;quot;,
            value.name=&amp;quot;frequency&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gg &amp;lt;- ggplot(data=res[effect==1,], aes(x=n, y=frequency, group=model, color=model)) +
  geom_line() +
  facet_grid(. ~ effect, labeller=label_both) +
  NULL
gg&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-05-30-glm-vs-t-tests-vs-non-parametric-tests-if-all-we-care-about-is-nhst-update_files/figure-html/type-1-plot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gg &amp;lt;- ggplot(data=res[effect!=1,], aes(x=n, y=frequency, group=model, color=model)) +
  geom_line() +
  facet_grid(. ~ effect, labeller=label_both) +
  NULL
gg&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-05-30-glm-vs-t-tests-vs-non-parametric-tests-if-all-we-care-about-is-nhst-update_files/figure-html/plower-plot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Warton, D.I., Thibaut, L., Wang, Y.A., 2017. The PIT-trap—A “model-free” bootstrap procedure for inference about regression models with discrete, multivariate responses. PLOS ONE 12, e0181790. &lt;a href=&#34;https://doi.org/10.1371/journal.pone.0181790&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1371/journal.pone.0181790&lt;/a&gt;&lt;a href=&#34;#fnref1&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>The statistical significance filter</title>
      <link>/2019/04/the-statistical-significance-filter/</link>
      <pubDate>Wed, 17 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/04/the-statistical-significance-filter/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#why-reported-effect-sizes-are-inflated&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;1&lt;/span&gt; Why reported effect sizes are inflated&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#setup&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2&lt;/span&gt; Setup&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#exploration-1&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3&lt;/span&gt; Exploration 1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#unconditional-means-power-and-sign-error&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;4&lt;/span&gt; Unconditional means, power, and sign error&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#conditional-means&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;5&lt;/span&gt; Conditional means&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#filter-0.05&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;5.1&lt;/span&gt; filter = 0.05&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#filter-0.2&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;5.2&lt;/span&gt; filter = 0.2&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;why-reported-effect-sizes-are-inflated&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;1&lt;/span&gt; Why reported effect sizes are inflated&lt;/h1&gt;
&lt;p&gt;This post is motivated by many discussions in Gelman’s blog &lt;a href=&#34;https://statmodeling.stat.columbia.edu/2011/09/10/the-statistical-significance-filter/&#34;&gt;but start here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;When we estimate an effect&lt;a href=&#34;#fn1&#34; class=&#34;footnoteRef&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;, the estimate will be a little inflated or a little diminished relative to the true effect but the expectation of the effect is the true effect. If all effects were reported, there would be no bias toward inflated effects. Reported effects are inflated if we use p-values to decide which to report and which to archive in the file drawer.&lt;/p&gt;
&lt;p&gt;The magnitude of an estimate of an effect is a function of its true effect size plus sampling error (this is with a perfectly designed and executed study. In any real study there will be biases of various sorts). The absolute magnitude of sampling error is bigger with smaller &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;. The relative magnitude is bigger for smaller true effect size. Consequently, estimates in low powered studies (some combination of low &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; and small true effect size) can be wildly off, especially relative to the true effect size. In low powered studies, it is these “wildly-off” estimates that are big enough to have &lt;span class=&#34;math inline&#34;&gt;\(p &amp;lt; 0.05\)&lt;/span&gt;. This phenomenon attenuates as power increases because estimates are less and less wildely-off.&lt;/p&gt;
&lt;p&gt;Here is a simulation of this&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;setup&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;2&lt;/span&gt; Setup&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)
library(GGally)
library(data.table)

source(&amp;quot;../R/fake_x.R&amp;quot;) # bookdown&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;exploration-1&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;3&lt;/span&gt; Exploration 1&lt;/h1&gt;
&lt;p&gt;Modeling a typical set of experiments in ecology or physiology with &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; independent responses each with the same standardized effect size. How big are the reported effect sizes for the subset with &lt;span class=&#34;math inline&#34;&gt;\(p.val &amp;lt; 0.05\)&lt;/span&gt; (with or without correction for multiple testing). Make this a function of power.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n &amp;lt;- 20 # per treatment level. power will be a function of effect size
np1 &amp;lt;- n+1
N &amp;lt;- 2*n
niter &amp;lt;- 100 # number of iterations for each combination of fake data parameters
treatment_levels &amp;lt;- c(&amp;quot;Cn&amp;quot;, &amp;quot;Tr&amp;quot;)
Treatment &amp;lt;- rep(treatment_levels, each=n)
p &amp;lt;- 50
b &amp;lt;- pval &amp;lt;- numeric(p)
combo &amp;lt;- 0 # which treatment combo
res_table &amp;lt;- data.table(NULL)
for(beta_1 in c(0.05, 0.15, 0.5, 1)){
  combo &amp;lt;- combo + 1
  j1 &amp;lt;- 0
  j &amp;lt;- 0
  res &amp;lt;- matrix(NA, nrow=niter*p, ncol=3)
  colnames(res) &amp;lt;- c(&amp;quot;ID&amp;quot;, &amp;quot;b&amp;quot;, &amp;quot;pval&amp;quot;)
  for(iter in 1:niter){
    j1 &amp;lt;- j1 + j # completed row -- start row will be this plus 1
    Y &amp;lt;- matrix(rnorm(n*2*p), nrow=n*2, ncol=p)
    Y[np1:N,] &amp;lt;- Y[np1:N,] + beta_1
    fit &amp;lt;- lm(Y ~ Treatment)
    fit.coefs &amp;lt;- coef(summary(fit))
    for(j in 1:p){# inefficient...how do I extract this without a 
      res[j1 + j, &amp;quot;ID&amp;quot;] &amp;lt;- niter*(combo - 1) + iter
      res[j1 + j, &amp;quot;b&amp;quot;] &amp;lt;- fit.coefs[[j]][&amp;quot;TreatmentTr&amp;quot;, &amp;quot;Estimate&amp;quot;]
      res[j1 + j, &amp;quot;pval&amp;quot;] &amp;lt;- fit.coefs[[j]][&amp;quot;TreatmentTr&amp;quot;, &amp;quot;Pr(&amp;gt;|t|)&amp;quot;]
    }
  } # iter
  res_table &amp;lt;- rbind(res_table, data.table(beta=beta_1, res))
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;unconditional-means-power-and-sign-error&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;4&lt;/span&gt; Unconditional means, power, and sign error&lt;/h1&gt;
&lt;p&gt;beta is the true effect. The unconditional mean is the mean of the estimated effect. The absolute value of the estimated effect is the measure of “size” or magnitude and the mean of the absolute values of the effect size will be bigger then the mean effect size if the true effect size is near zero.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;table1 &amp;lt;- res_table[, .(mean_unconditional=mean(b),
              mean_abs_unconditional=mean(abs(b)),
              power = sum(pval &amp;lt; 0.05 &amp;amp; b &amp;gt; 0)/niter/p,
              sign.error=sum(pval &amp;lt; 0.05 &amp;amp; b &amp;lt; 0)/niter/p), by=.(beta)]
knitr::kable(table1, digits=c(2, 2, 2, 2, 3))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;right&#34;&gt;beta&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;mean_unconditional&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;mean_abs_unconditional&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;power&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sign.error&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;0.05&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.05&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.25&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.04&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.017&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;0.15&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.15&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.28&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.07&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.008&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;0.50&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.50&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.51&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.34&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.001&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;1.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.01&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.01&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.88&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.000&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;conditional-means&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;5&lt;/span&gt; Conditional means&lt;/h1&gt;
&lt;p&gt;The conditional mean is the mean effect size conditional on pval &amp;lt; filter. Again, beta is the true effect. And again, the absolute estimate (&lt;span class=&#34;math inline&#34;&gt;\(|b|\)&lt;/span&gt;) is the measure of effect “size”.&lt;/p&gt;
&lt;div id=&#34;filter-0.05&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;5.1&lt;/span&gt; filter = 0.05&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;table2 &amp;lt;- res_table[pval &amp;lt; 0.05, .(mean_conditional=mean(b),
                         mean_abs.conditional=mean(abs(b)),
                         multiplier = mean(abs(b))/beta), by=.(beta)]
knitr::kable(table2, digits=c(2, 2, 2, 1))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;right&#34;&gt;beta&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;mean_conditional&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;mean_abs.conditional&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;multiplier&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;0.05&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.29&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.73&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;14.5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;0.15&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.59&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.74&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4.9&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;0.50&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.83&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.83&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.7&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;1.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.08&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.08&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;filter-0.2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;5.2&lt;/span&gt; filter = 0.2&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;table3 &amp;lt;- res_table[pval &amp;lt; 0.2, .(mean_conditional=mean(b),
                         mean_abs.conditional=mean(abs(b)),
                         multiplier = mean(abs(b))/beta), by=.(beta)]
knitr::kable(table3, digits=c(2, 2, 2, 1))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;right&#34;&gt;beta&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;mean_conditional&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;mean_abs.conditional&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;multiplier&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;0.05&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.15&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.55&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;11.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;0.15&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.42&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.57&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.8&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;0.50&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.69&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.69&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;1.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.03&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.03&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;for example, in an experiment, if we compare the mean response between a control group and a treated group, the difference in means is the effect. More generally, an effect is the coefficient of a linear model&lt;a href=&#34;#fnref1&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Paired line plots</title>
      <link>/2019/01/paired-line-plots/</link>
      <pubDate>Tue, 22 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/01/paired-line-plots/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#load-libraries&#34;&gt;load libraries&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#make-some-fake-data&#34;&gt;make some fake data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#make-a-plot-with-ggplot&#34;&gt;make a plot with ggplot&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;ggplot scripts to draw figures like those in the Dynamic Ecology post &lt;a href=&#34;https://dynamicecology.wordpress.com/2019/01/21/paired-line-plots-a-k-a-reaction-norms-to-visualize-likert-data/#comments&#34;&gt;Paired line plots (a.k.a. “reaction norms”) to visualize Likert data&lt;/a&gt;&lt;/p&gt;
&lt;div id=&#34;load-libraries&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;load libraries&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)
library(ggpubr)
library(data.table)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;make-some-fake-data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;make some fake data&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(3)
n &amp;lt;- 40
self &amp;lt;- rbinom(n, 5, 0.25) + 1
others &amp;lt;- self + rbinom(n, 3, 0.5)
fd &amp;lt;- data.table(id=factor(rep(1:n, 2)),
                 who=factor(rep(c(&amp;quot;self&amp;quot;, &amp;quot;others&amp;quot;), each=n)),
                 stigma &amp;lt;- c(self, others))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;make-a-plot-with-ggplot&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;make a plot with ggplot&lt;/h1&gt;
&lt;p&gt;The students are identified by the column “id”. Each students’ two responses (“self” and “others”) are joined by a line using geom_line(), which knows who to join with the “group=id” statement in the aes function in line 1. The alpha setting draws transparent lines (alpha=1 is opaque) so the more lines that are superimposed the darker the line. The lines are slightly jittered in the vertical direction so that overlapping lines appear wider.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;jitter_mag &amp;lt;- 0.03
gg &amp;lt;- ggplot(data=fd, aes(x=who, y=stigma, group=id)) +
  geom_line(size=1,
            alpha=0.3, 
            position=position_jitter(w=0, h=jitter_mag)) +
  ylab(&amp;quot;Amount of stigma (1=low, 6=high)&amp;quot;) +
  xlab(&amp;quot;Responding about views of others or self&amp;quot;) +
  theme_pubr() +
  NULL
gg&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-01-22-paired-line-plots_files/figure-html/ggplot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>A simple ggplot of some measure against depth</title>
      <link>/2018/09/a-simple-ggplot-of-some-measure-against-depth/</link>
      <pubDate>Mon, 10 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/09/a-simple-ggplot-of-some-measure-against-depth/</guid>
      <description>


&lt;div id=&#34;set-up&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;set up&lt;/h1&gt;
&lt;p&gt;The goal is to plot the measure of something, say O2 levels, against depth (soil or lake), with the measures taken on multiple days&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)
library(data.table)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;first-create-fake-data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;First – create fake data&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;depths &amp;lt;- c(0, seq(10,100, by=10))
dates &amp;lt;- c(&amp;quot;Jan-18&amp;quot;, &amp;quot;Mar-18&amp;quot;, &amp;quot;May-18&amp;quot;, &amp;quot;Jul-18&amp;quot;)
x &amp;lt;- expand.grid(date=dates, depth=depths)
n &amp;lt;- nrow(x)
head(x)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     date depth
## 1 Jan-18     0
## 2 Mar-18     0
## 3 May-18     0
## 4 Jul-18     0
## 5 Jan-18    10
## 6 Mar-18    10&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;X &amp;lt;- model.matrix(formula(~date + depth), data=x)
head(X)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   (Intercept) dateMar-18 dateMay-18 dateJul-18 depth
## 1           1          0          0          0     0
## 2           1          1          0          0     0
## 3           1          0          1          0     0
## 4           1          0          0          1     0
## 5           1          0          0          0    10
## 6           1          1          0          0    10&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;beta &amp;lt;- c(0,1,2,3,0.5)
y &amp;lt;- X%*%beta + rnorm(n, sd=5)
fake_data &amp;lt;- data.frame(O2=y, x)
head(fake_data)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          O2   date depth
## 1 -5.618861 Jan-18     0
## 2 13.885828 Mar-18     0
## 3  1.309404 May-18     0
## 4  4.442890 Jul-18     0
## 5  6.504647 Jan-18    10
## 6  5.378927 Mar-18    10&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;second-make-ggplot&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Second – make ggplot&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gg &amp;lt;- ggplot(data=fake_data, aes(x=depth, y=O2, group=date, color=date)) +
  geom_point() +
  geom_line() +
  coord_flip() +
  # coord_flip does not make the y-axis the x-axis but the horizontal axis. 
  # so still need to refer to &amp;quot;y&amp;quot; to modify O2
  # specify position=&amp;quot;right&amp;quot; to flip the y axis to the top after coord_flip
  scale_y_continuous(position = &amp;quot;right&amp;quot;) +
  # reverse the depth axis, which makes it go down instead of up
  scale_x_reverse() +
  xlab(&amp;quot;Depth&amp;quot;) +
  ylab(expression(O[2])) +
  theme_minimal() +
  NULL
gg&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-09-10-a-simple-ggplot-of-some-measure-against-depth_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>