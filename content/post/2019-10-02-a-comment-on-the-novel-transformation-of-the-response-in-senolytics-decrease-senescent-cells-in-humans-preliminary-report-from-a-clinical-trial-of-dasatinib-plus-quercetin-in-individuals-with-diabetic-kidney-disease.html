---
title: 'A comment on the novel transformation of the response in " Senolytics decrease
  senescent cells in humans: Preliminary report from a clinical trial of Dasatinib
  plus Quercetin in individuals with diabetic kidney disease"'
author: Jeff Walker
date: '2019-10-02'
slug: a-comment-on-the-novel-transformation-of-the-response-in-senolytics-decrease-senescent-cells-in-humans-preliminary-report-from-a-clinical-trial-of-dasatinib-plus-quercetin-in-individuals-with-diabetic-kidney-disease
categories:
  - stats 101
tags:
  - fake data
keywords:
  - tech
---



<p>Motivation: <a href="https://pubpeer.com/publications/8DF6E66FEFAA2C3C7D5BD9C3FC45A2#2" class="uri">https://pubpeer.com/publications/8DF6E66FEFAA2C3C7D5BD9C3FC45A2#2</a> and <a href="https://twitter.com/CGATist/status/1175015246282539009" class="uri">https://twitter.com/CGATist/status/1175015246282539009</a></p>
<p>tl;dr: Given the transformation done by the authors, for any response in day_0 that is unusually small, there is automatically a response in day_14 that is unusually big and vice-versa. Consequently, if the mean for day_0 is unusually small, the mean for day_14 is automatically unusually big, hence the elevated type I error with an unpaired t-test. The transformation is necessary and sufficient to produce the result (meaning <strong>even in conditions where a paired t-test isn’t needed, the transformation still produces elevated Type I error</strong>).</p>
<p>Pubpeer and Twitter alerted the world to interesting looking figures from a recent publication. The paper itself is on a pair of drugs that target senescent cells to reduce the number of senescent cells in a tissue. The raw response is a count of senescent cells before (day 0) and after (day 14) treatment. I read the paper quickly but don’t see a control.</p>
<p>The figures in the paper (and tweeted) clearly show that the 1) analyzed response is not a raw count and 2) the value of the two responses for individual <span class="math inline">\(i\)</span> are symmetric about the mean response. A pubpeer query got this response from an author:</p>
<p><code>To test for effects on % reduction in senescent cells WITHIN subjects without confounding effects of variations of initial senescent cell burden among subjects, data are expressed as % of values at day 0 + day 14 for each subject, i.e. value at time 0 for subject 1 is: absolute value at day 0 for subject 1/(absolute value at day 0 for subject 1 + absolute value at day 14 for subject 1) x 100. Thus, % at day 0 + % at day 14 for subject 1 = 100.</code></p>
<p>It’s pretty easy to see this is the case looking at the figures. I commented to twitter</p>
<div class="figure">
<img src="/post/2019-10-02-a-comment-on-the-novel-transformation-of-the-response-in-senolytics-decrease-senescent-cells-in-humans-preliminary-report-from-a-clinical-trial-of-dasatinib-plus-quercetin-in-individuals-with-diabetic-kidney-disease_files/twitter.png" />

</div>
<p>Some later responses noted the perfect, negative correlation among the response, but the underlying problem is, fundamentally, the perfect, negative correlation <em>within individuals</em>, which occurs because the transformation necessarily makes an individual’s day 0 and day 14 measures symetric about the mean (that is “perfect, negative correlation within individuals”) – see the two figures at the end of this post. Given the transformation, then, for any response in day_0 that is unusually small, there is automatically a response in day_14 that is unusually big and vice-versa. <strong>Consequently, if the mean for day_0 is unusually small, the mean for day_14 is automatically unusually big, hence the elevated type I error.</strong></p>
<p>Anyway, my response went un-noticed and, motivated by a new twitter post from Andrew Althouse, I decided to revisit the issue <strong>using a simulation to check my understanding</strong> of what the transformation does and why it inflates Type I error.</p>
<div id="normal-conditional-response" class="section level1">
<h1>normal conditional response</h1>
<p>The response is a count, which is not Gaussian. Regardless, this initial simulation uses a normal (conditional) response.</p>
<pre class="r"><code>n &lt;- 9
mu &lt;- 100 # overall mean
sigma_w &lt;- 10 # variation within ID
amp_vals &lt;- c(0.001, 0.66, 1) # rho = 0, ~0.3, 0.5
n_iter &lt;- 10^4
p.norm_unpaired &lt;- numeric(n_iter)
p.norm_paired &lt;- numeric(n_iter)
p.count_unpaired &lt;- numeric(n_iter)
p.count_paired &lt;- numeric(n_iter)
r &lt;- numeric(n_iter)

t1_table &lt;- data.frame(matrix(NA, nrow=6, ncol=length(amp_vals)))
row.names(t1_table) &lt;- c(&quot;Among:Within&quot;, &quot;rho&quot;, &quot;trans unpaired&quot;, &quot;trans paired&quot;, &quot;raw unpaired&quot;, &quot;raw paired&quot;)

set.seed(1)
for(amp in amp_vals){
  sigma_a &lt;- amp*sigma_w # variation among ID
  rho &lt;- (amp*sigma_w)^2/((amp*sigma_w)^2 + sigma_w^2)
  t1_table[&quot;Among:Within&quot;, which(amp_vals==amp)] &lt;- amp^2
  t1_table[&quot;rho&quot;, which(amp_vals==amp)] &lt;- rho
  
  # not a super efficient simulation but the for loop is more readable
  for(iter in 1:n_iter){
    mu_i &lt;- rnorm(n=n, mean=mu, sd=sigma_a) # means of each ID
    count_0 &lt;- rnorm(n, mean=mu_i, sd=sigma_w) # counts at day 0
    count_14 &lt;- rnorm(n, mean=mu_i, sd=sigma_w) # counts at day 14
    norm_0 &lt;- count_0/(count_0 + count_14)
    norm_14 &lt;- count_14/(count_0 + count_14)
    r[iter] &lt;- cor(count_0, count_14)
    p.norm_unpaired[iter] &lt;- t.test(norm_0, norm_14, var.equal=FALSE)$p.value
    p.norm_paired[iter] &lt;- t.test(norm_0, norm_14, paired=TRUE)$p.value
    p.count_unpaired[iter] &lt;- t.test(count_0, count_14, var.equal=FALSE)$p.value
    p.count_paired[iter] &lt;- t.test(count_0, count_14, paired=TRUE)$p.value
  }

  t1_table[3:6, which(amp_vals==amp)] &lt;- c(
    sum(p.norm_unpaired &lt; 0.05)/n_iter,
    sum(p.norm_paired &lt; 0.05)/n_iter,
    sum(p.count_unpaired &lt; 0.05)/n_iter,
    sum(p.count_paired &lt; 0.05)/n_iter
  )
}</code></pre>
<table>
<caption><span id="tab:unnamed-chunk-2">Table 1: </span>Table of Type I errors. The first row is the ratio of the among-ID variance to within-ID variance. The among-ID variance is VAR(mu). The second row is the expected correlation given the among:within variance</caption>
<thead>
<tr class="header">
<th></th>
<th align="right">Sim1</th>
<th align="right">Sim2</th>
<th align="right">Sim3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Among:Within</td>
<td align="right">0.000</td>
<td align="right">0.436</td>
<td align="right">1.000</td>
</tr>
<tr class="even">
<td>rho</td>
<td align="right">0.000</td>
<td align="right">0.303</td>
<td align="right">0.500</td>
</tr>
<tr class="odd">
<td>trans unpaired</td>
<td align="right">0.169</td>
<td align="right">0.170</td>
<td align="right">0.176</td>
</tr>
<tr class="even">
<td>trans paired</td>
<td align="right">0.048</td>
<td align="right">0.052</td>
<td align="right">0.050</td>
</tr>
<tr class="odd">
<td>raw unpaired</td>
<td align="right">0.048</td>
<td align="right">0.023</td>
<td align="right">0.009</td>
</tr>
<tr class="even">
<td>raw paired</td>
<td align="right">0.048</td>
<td align="right">0.053</td>
<td align="right">0.051</td>
</tr>
</tbody>
</table>
<p>The table of type I errors shows</p>
<ol style="list-style-type: decimal">
<li>As expected, the unpaired t-test is conservative (fewer type I errors than nominal alpha) only when there is a correlation between the day 0 and day 14 measures and this conservativeness is a function of the correlation. This is expected because the correlation is a function of the extra among ID variance and in the first simulation there is no extra ID variance. It is the problem of the among-ID variance that the authors were trying to solve with their transformation. The logic of the transformation is okay, but it results in the perfect negative within-ID correlations (see the images below) that I mentioned in my initial twitter response. And this leads to</li>
<li>The type I error on the transformed response using the unpaired t-test is highly inflated <em>regardless</em> of the among-ID variance. That is, even when the condition for an unpaired t-test is valid (when the among ID variance is zero), the Type I error is still inflated. This is why I stated in the pubpeer commment that is the transformation that is the problem.</li>
</ol>
</div>
<div id="figures-of-the-within-id-negative-correlation" class="section level1">
<h1>Figures of the within-ID negative correlation</h1>
<p>Here are the residuals of the linear model version of the unpaired t-test. The y-axis is the residual and the x-axis is the ID. The residuals are perfectly symmetric about zero, with one value of each individual above zero and the other below zero.</p>
<pre class="r"><code>day &lt;- as.factor(rep(c(&quot;day_0&quot;, &quot;day_14&quot;), each=n))
count &lt;- c(norm_0, norm_14)
id &lt;- as.character(rep(1:n, times=2))
m1 &lt;- lm(count ~ day)
res &lt;- residuals(m1)
qplot(id, res, color=day) +
  ylab(&quot;Residuals&quot;) +
  NULL</code></pre>
<p><img src="/post/2019-10-02-a-comment-on-the-novel-transformation-of-the-response-in-senolytics-decrease-senescent-cells-in-humans-preliminary-report-from-a-clinical-trial-of-dasatinib-plus-quercetin-in-individuals-with-diabetic-kidney-disease_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>The perfect, negative correlation of the residuals is more explicitly shown with a scatterplot of day_14 residuals vs. day_0 residuals.</p>
<p><img src="/post/2019-10-02-a-comment-on-the-novel-transformation-of-the-response-in-senolytics-decrease-senescent-cells-in-humans-preliminary-report-from-a-clinical-trial-of-dasatinib-plus-quercetin-in-individuals-with-diabetic-kidney-disease_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
</div>
<div id="conclusion" class="section level1">
<h1>conclusion</h1>
<p>There is some discussion on twitter and pubpeer on the mechanism of the inflated type I error; is it 1) the unpaired t-test, 2) the transformation, or 3) combination of both? The unpaired t-test is <em>not</em> the mechanism, because without the transformation, the unpaired t-test is conservative (fewer type I error than nominal) not liberal. It is the transformation that inflates the error. But, because of what a paired t-test does (it tests b-a = 0), it is unaffected by the transformation.</p>
</div>
