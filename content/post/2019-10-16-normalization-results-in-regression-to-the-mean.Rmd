---
title: 'Normalization results in regression to the mean and inflated Type I error conditional on the reference values'
author: Jeff Walker
date: '2019-10-16'
slug: normalization-results-in-regression-to-the-mean
categories:
  - reproducibility
  - stats 101
tags:
  - ancova
  - effect size
  - fake data
  - regression to the mean
  - bias
keywords:
  - tech
---
This not fully fleshed out post has two tl;drs, the first is specific to the paper (see below), the second is very general, for anyone normalizing gel/blot/etc. data.

tl;dr 1  The linear model with Gapdh as covariate fit to the empirical data from the paper is inconclusive while the model with the normalization used by the authors has a very low p-value for both Met and pMet

tl;dr 2 Standard procedure in labs is to normalize values from gels/blots/etc by some standard that is expected to be constant across treatments. A problem with this is *regression to the mean*, which results in inflated Type I error. This means t-tests and such are too liberal, that is, we reject the null too often, or we too often conclude "an effect exists" when the evidence doesn't favor this conclusion. The correct way to achieve the same goals as normalization is a linear model with the reference value as a covariate.

I would think this isn't news but I'm not familiar with the literature. Google Scholaring found mostly normalization in microarray/RNAseq type stuff and much of this is concerned with different issues. There is abundant literature on normalizng on body weight and adjusting for baseline in pre-post designs, but there doesn't seem to be much acknowledgment of regression to the mean within experimental biology. I did find this, 

Janu≈°onis, S., 2009. Comparing two small samples with an unstable, treatment-independent baseline. Journal of neuroscience methods, 179(2), pp.173-178.

which doesn't seem to recognize the issue of regression to the mean and inflated conditional type I error.

##  Background
I was having an internal conversation with myself, which led me to thinking about reproducibility in bench biology, which led me to the [cancer reproducibility project](https://elifesciences.org/collections/9b1e83d1/reproducibility-project-cancer-biology). What a terrific site.

I downloaded the article and data for Fig 1C of the [Replication Study: Melanoma exosomes educate bone marrow progenitor cells toward a pro-metastatic phenotype through MET](https://elifesciences.org/articles/39944) just to explore. Without looking at the author's code, I wrote my own script to replicate Fig 1C. My numbers weren't quite right so I looked at the author's script and realized that I needed to re-scale within Blot in addition to Antibody and Type. Once I did this, my code reproduces the author's results. My method for preparing the data is *very* different from the authors (my code is very data.table-ish), which is pretty typical of any R analysis -- ask 10 R scripters how to get something done and you'll recieve 20 different answers.

Anyway, I'm curious about the normalization since this seems to be very common yet my intuition thinks it can lead to regression to the mean. The normalization here had 2 steps: 1) first, the value for the Antibody levels were normalized by the value of a reference (Gapdh) for each Set. This is the typical normalization throughout bench biology. And 2) second, the Gapdh-normalized values were rescaled by the mean of the Gapdh-normalized values for the shScr Condition within each combination of Antibody+Type+Blot and then *all* values in the shScr were assigned to 1 (since the mean within the Condition level is 1). The statistical test then is a one-sample t-test of shMet with $\mu=1$.

Intuition 1: Step one of this normalization would seem to introduce a biased estimate of the effect, conditional on the mean difference in Gapdh between treatment and control values, very similar to the biased estimate of a change score (or change from pre to post) conditional on pre-treatment values [in a pre-post design](https://www.middleprofessor.com/files/quasipubs/change_scores.html).

Intuition 2: Step two would just seem to introduce type I error since we're removing variance from the 2nd sample.

The proper way to avoid the conditional bias in a pre-post design is to add the pre-treatment value as a covariate. I don't know if Normalization by a reference sample is conditionally biased but I re-analyzed the data using the Gapdh value as a covariate in a linear model. I also just re-ran a t-test of the normalized response (step 1) without the re-scaling in step 2. Both the linear model and t-test results *for these data* were very different from the original results. I plotted the data and it's pretty easy to see why, but it's hard for me to generalize from this one example. So I did a simulation to check my intuition above.

Indeed, both my intutions turn out to be true. All analysis is below. I parameterized the distribution of Gapdh and the other values so they looked something like the actual values in the paper. I don't know how much my results would change given different parameterizations of these distributions.

## Reproducibility
```{r setup, include=FALSE}
library(here)
library(janitor)
library(data.table)
library(lmerTest)
library(emmeans)
library(ggpubr)
library(cowplot)

here <- here::here
data_path <- "content/data"
output_path <- "content/output"

simulate_it=FALSE # False indicates the simulations were done and written to disc
```

```{r import}
folder <- "Data from Generation and characterization of shMet B16-F10 cells and exosomes"
filename <- "Study_42_Figure_1_WB_quant_Data.csv"
file_path <- here(data_path, folder, filename)
exp1 <- fread(file_path)
#View(exp1)
```

Create normalized values

1. Value.norm is the conventional normalization using the reference (Gapdh) value.
2. value.norm.2 is Value.norm rescaled by the mean of shScr
3. value.norm.3 is setting all rescalings of shScr to = 1

```{r reproducibility}
# get Gapdh ref for each row to rescale ("normalize") by Gapdh
gapdh_ref.dt <- exp1[Antibody=="Gapdh", .(gapdh_ref=mean(Value)), by=Set]
exp1.v1 <- merge(exp1, gapdh_ref.dt, by="Set")
exp1.v1[, Value.norm:=Value/gapdh_ref]

# get mean shScr for each Antibody:Type:Blot to rescale by mean shScr 
shScr_ref.dt <- exp1.v1[Condition=="shScr", .(shScr_ref=mean(Value.norm)), by=.(Antibody, Type, Blot)]
exp1.v1 <- merge(exp1.v1, shScr_ref.dt, by=c("Antibody", "Type", "Blot"))
exp1.v1[, value.norm.2:=Value.norm/shScr_ref]
exp1.v1[, value.norm.3:=ifelse(Condition=="shScr", 1, value.norm.2)]
#View(exp1.v1)

gg1 <- ggbarplot(data=exp1.v1[Antibody=="Met" & Type=="Cells"], 
                 x="Condition", 
                 y="value.norm.2",
          add=c("mean_se")) +
  ylab("Met") +
  NULL
gg2 <- ggbarplot(data=exp1.v1[Antibody=="pMet" & Type=="Cells",],
                 x="Condition", 
                 y="value.norm.2",
                 add=c("mean_se")) +
  ylab("pMet") +
  NULL

gg3 <- ggbarplot(data=exp1.v1[Antibody=="Met" & Type=="Cells"], 
                 x="Condition", 
                 y="value.norm.3",
          add=c("mean_se")) +
  ylab("Met") +
  NULL
gg4 <- ggbarplot(data=exp1.v1[Antibody=="pMet" & Type=="Cells",],
                 x="Condition", 
                 y="value.norm.3",
                 add=c("mean_se")) +
  ylab("pMet") +
  NULL

plot_grid(gg1, gg2, gg3, gg4, nrow=2)


```

The two bottom plots reproduce Fig 1C from the paper. The two top plots are scaled by Gapdh but not shScr

## What are the consequences of normalization? Compare to linear model with Gapdh as covariate

tl;dr Big. The linear model with Gapdh as covariate is inconclusive while the model with the normalization used by the authors has a very low p-value.

### linear models
#### Met
m1 is the preferred method. m2 is conventional normalization. m4 is what the author's did.

```{r covariate-v-normalization-met}
# linear model with ref as covariate
m1 <- lm(Value ~ gapdh_ref + Condition, data=exp1.v1[Antibody=="Met" & Type=="Cells"])
# linear model with no accounting for ref
m2 <- lm(Value ~ Condition, data=exp1.v1[Antibody=="Met" & Type=="Cells"])
# linear model using Gapdh normalized values
m3 <- lm(Value.norm ~ Condition, data=exp1.v1[Antibody=="Met" & Type=="Cells"])
# linear model using Gapdh normalized rescaled to shScr values
m4 <- lm(value.norm.3 ~ Condition, data=exp1.v1[Antibody=="Met" & Type=="Cells"])
coef(summary(m1))
coef(summary(m2))
coef(summary(m3))
coef(summary(m4))
```

#### pMet
m1 is the preferred method. m2 is conventional normalization. m4 is what the author's did.

```{r covariate-v-normalization-pmet-1}
# linear model with ref as covariate
m1 <- lm(Value ~ gapdh_ref + Condition, data=exp1.v1[Antibody=="pMet" & Type=="Cells"])
# linear model with no accounting for ref
m2 <- lm(Value ~ Condition, data=exp1.v1[Antibody=="pMet" & Type=="Cells"])
# linear model using Gapdh normalized values
m3 <- lm(Value.norm ~ Condition, data=exp1.v1[Antibody=="pMet" & Type=="Cells"])
# linear model using Gapdh normalized rescaled to shScr values
m4 <- lm(value.norm.3 ~ Condition, data=exp1.v1[Antibody=="pMet" & Type=="Cells"])
coef(summary(m1))
coef(summary(m2))
coef(summary(m3))
coef(summary(m4))
```

#### some plots of what's going on
```{r}
gg6 <- ggplot(data=exp1.v1[Antibody=="Met" & Type=="Cells"], aes(x=gapdh_ref, y=Value, color=Condition)) +
  geom_point() +
  ylab("Met") +
  theme_minimal() +
  NULL

gg7 <- ggplot(data=exp1.v1[Antibody=="Met"], aes(x=gapdh_ref, y=Value, color=Condition, shape=Type)) +
  geom_point() +
  ylab("Met") +
  theme_minimal() +
  NULL

gg8 <- ggplot(data=exp1.v1[Antibody=="pMet" & Type=="Cells"], aes(x=gapdh_ref, y=Value, color=Condition)) +
  geom_point() +
  ylab("pMet") +
  theme_minimal() +
  NULL

gg9 <- ggplot(data=exp1.v1[Antibody=="pMet"], aes(x=gapdh_ref, y=Value, color=Condition, shape=Type)) +
  geom_point() +
  ylab("pMet") +
  theme_minimal() +
  NULL
plot_grid(gg6, gg8, nrow=1)

```

It's pretty hard to figure out systemic bias due to normalization with a sample size of 3 or 4 so...

## Simulations

Simulate the experiment in Fig 1 C of the paper. Effectively, this simulates an experiment with one control level, one treatment level, and a sample size of 4 (per level). Control and treatment levels are adjusted using a reference level (simulating Gapdh). The adjustments are 1) lm (linear model with Gapdh has covariate), 2) norm1 (the ratio of the control or treatment level divided by Gapdh level), 3) norm2 (norm1 rescaled  to the control mean and then all control levels reset to equal one.)

### Simulation functions

```{r simulation-rho-explore, echo=FALSE, eval=FALSE}
n <- 10^3
rho=0.5
alpha_gapdh <- 80
beta_gapdh <- 100
alpha_met <- 30
beta_met <- 100
y1 <- rgamma(n, shape=alpha_gapdh - rho*sqrt(alpha_gapdh*alpha_met), rate=1)
y2 <- rgamma(n, shape=alpha_met - rho*sqrt(alpha_gapdh*alpha_met), rate=1)
y3 <- rgamma(n, shape=rho*sqrt(alpha_gapdh*alpha_met), rate=1)
gapdh <- beta_gapdh*(y1+y3)
value <- beta_met*(y2+y3)
qplot(y1)
qplot(y2)
qplot(y3)
qplot(gapdh)
qplot(value)
cor(gapdh, value)
```

The main function for generating a data set with a control, a treatment, and a reference for normalization.

```{r simulation-gamma}
simulate_experiment <- function(
  n=10, # number of replicates per treatment level
  rho=0.5, # correlation between the reference value and that of a control level
  s_kappa=1, # effect of treatment on shape (this is multiplicative so 1 = no effect)
  s_theta=1, # effect of treatment on scale (this is multiplicative so 1 = no effect
  kappa_0=80, # shape parameter for reference
  theta_0=100, # scale parameter for reference
  kappa_1=30, # shape parameter for control
  theta_1=100 # scale parameter for control
){
  kappa_1_i <- rep(c(kappa_1, kappa_1*s_kappa), each=n)
  theta_1_i <- rep(c(theta_1, theta_1*s_theta), each=n)
  # control
  y1 <- rgamma(n*2, shape=kappa_0 - rho*sqrt(kappa_0*kappa_1), scale=1)
  y2 <- rgamma(n*2, shape=kappa_1_i - rho*sqrt(kappa_0*kappa_1_i), scale=1)
  y3 <- rgamma(n*2, shape=rho*sqrt(kappa_0*kappa_1), scale=1)
  fd <- data.table(
    treatment=rep(c("cn", "tr"), each=n),
    gapdh=theta_0*(y1+y3),
    value=theta_1_i*(y2+y3)
  )
  fd[, norm1:=value/gapdh]
  cn_ref <- mean(fd[treatment=="cn", norm1])
  fd[, norm2:=norm1/cn_ref]
  return(fd)
}
```

Script to explore parameterization. To turn on, change eval to TRUE
```{r simulate-explore, eval=FALSE}
n=10^4 # number of replicates per treatment level
rho=0.5 # correlation between the reference value and that of a control level
s_kappa=1.1 # effect of treatment on shape (this is multiplicative so 1 = no effect)
s_theta=1.1 # effect of treatment on scale (this is multiplicative so 1 = no effect
kappa_0=80 # shape parameter for reference
theta_0=100 # scale parameter for reference
kappa_1=30 # shape parameter for control
theta_1=100 # scale parameter for control
(s_kappa*kappa_1*s_theta*theta_1 - kappa_1*theta_1)/(sqrt(kappa_1*theta_1^2))

fd <- simulate_experiment(
  n, # number of replicates per treatment level
  rho, # correlation between the reference value and that of a control level
  s_kappa, # effect of treatment on shape (this is multiplicative so 1 = no effect)
  s_theta, # effect of treatment on scale (this is multiplicative so 1 = no effect
  kappa_0, # shape parameter for reference
  theta_0, # scale parameter for reference
  kappa_1, # shape parameter for control
  theta_1 # scale parameter for control
)

# quick and dirty cohen's
kappa_1*theta_1
s_kappa*kappa_1*s_theta*theta_1
(means_table <- fd[, .(cell_mean=mean(value), cell_sd=sd(value)), by=treatment])
(means_table[treatment=="tr", cell_mean] - means_table[treatment=="cn", cell_mean])/means_table[treatment=="cn", cell_sd]
```

Script to generate simulated data *n_iter* times and output tables of effects and p-values.

```{r iterate-simulation}
iterate_experiment <- function(
  n=10, # number of replicates per treatment level
  niter=2000, # number of iterations
  rho=0.5, # correlation between the reference value and that of a control level
  s_kappa=1, # effect of treatment on shape (this is multiplicative so 1 = no effect)
  s_theta=1, # effect of treatment on scale (this is multiplicative so 1 = no effect
  kappa_0=80, # shape parameter for reference
  theta_0=100, # scale parameter for reference
  kappa_1=30, # shape parameter for control
  theta_1=100 # scale parameter for control
  ){
  # Given a western blot with three "treatments": reference (Gapdh) is the set of values for normaliztion
  # control is the set of values for a control. The treatment value is determined by beta_1 -- the effect
  prob_cols <- c("lm", "norm1", "norm2")
  prob <- data.table(matrix(-9999, nrow=niter, ncol=length(prob_cols)))
  setnames(prob, old=colnames(prob), new=prob_cols)
  effect_cols <- c("delta_gapdh", "effect_lm", "effect_norm1", "effect_norm2")
  effects_dt <- data.table(matrix(-9999, nrow=niter, ncol=length(effect_cols)))
  setnames(effects_dt, old=colnames(effects_dt), new=effect_cols)
  # effect_lm <- numeric(niter) # effect size using lm with gapdh as covariate
  # effect_norm1 <- numeric(niter) # effect size using standard normalization against gapdh
  # effect_norm2 <- numeric(niter) # effect size using re-scaling to control (shSrc in this case)
  # delta_gapdh <- numeric(niter) # the difference between control and treatment gapdh
  kappa_1_i <- rep(c(kappa_1, kappa_1*s_kappa), each=n)
  for(iter in 1:niter){
    fd <- simulate_experiment(
      n, # number of replicates per treatment level
      rho, # correlation between the reference value and that of a control level
      s_kappa, # effect of treatment on shape (this is multiplicative so 1 = no effect)
      s_theta, # effect of treatment on scale (this is multiplicative so 1 = no effect
      kappa_0, # shape parameter for reference
      theta_0, # scale parameter for reference
      kappa_1, # shape parameter for control
      theta_1 # scale parameter for control
    )

    m1 <- lm(value ~ gapdh + treatment, data=fd)
    prob[iter, lm := coef(summary(m1))["treatmenttr", "Pr(>|t|)"]]
    prob[iter, norm1 := t.test(fd[treatment=="cn", norm1], fd[treatment=="tr", norm1], var.equal=TRUE)$p.value]
    prob[iter, norm2 := t.test(x=fd[treatment=="tr", norm2], mu=1)$p.value]
    
    effects_dt[iter, delta_gapdh := mean(fd[treatment=="tr", gapdh]) - mean(fd[treatment=="cn", gapdh])]
    effects_dt[iter, effect_lm := coef(summary(m1))["treatmenttr", "Estimate"]]
    effects_dt[iter, effect_norm1 := mean(fd[treatment=="tr", norm1]) - mean(fd[treatment=="cn", norm1])]
    effects_dt[iter, effect_norm2 := mean(fd[treatment=="tr", norm2]) - 1]
  }
  return(
    cbind(prob, effects_dt)
  )
}

```
### functions to plot simulation results

```{r plot-functions}
plot_effects <- function(res){
  prob_cols <- c("lm", "norm1", "norm2")
  niter <- nrow(res)
  apply(res[,.SD, .SDcols=prob_cols], 2, function(x) sum(x < 0.05)/niter)
  gg1 <- qplot(x=res$delta_gapdh/10^3, y=res$effect_lm) +
    geom_smooth(method="lm") +
    ggtitle("Linear model") +
    xlab(expression(paste(Gapdh[t] - Gapdh[c],  "(X 1000)"))) +
    ylab("Effect") +
    theme_minimal() +
    NULL
  gg2 <- qplot(x=res$delta_gapdh/10^3, y=res$effect_norm1) +
    geom_smooth(method="lm") +
    ggtitle("Norm1") +
    xlab(expression(paste(Gapdh[t] - Gapdh[c],  "(X 1000)"))) +
    ylab("Effect") +
    theme_minimal() +
    NULL
  gg3 <- qplot(x=res$delta_gapdh/10^3, y=res$effect_norm2) +
    geom_smooth(method="lm") +
    ggtitle("Norm2") +
    xlab(expression(paste(Gapdh[t] - Gapdh[c],  "(X 1000)"))) +
    ylab("Effect") +
    theme_minimal() +
    NULL
  gg <- plot_grid(gg1, gg2, gg3, nrow=1)
  return(gg)
}

plot_prob_t1 <- function(res){
  res[, t1.lm:=ifelse(lm <= 0.05, 1, 0)]
  res[, t1.norm1:=ifelse(norm1 <= 0.05, 1, 0)]
  res[, t1.norm2:=ifelse(norm2 <= 0.05, 1, 0)]
  gg1 <- ggplot(data=res, aes(x=abs(delta_gapdh), y=t1.lm)) +
    geom_smooth(method='glm', method.args=list(family='binomial')) +
    ylab("Prob(Type I): linear model") +
    xlab(expression(paste("|",Gapdh[t] - Gapdh[c],"|"))) +
    theme_minimal()
  gg2 <- ggplot(data=res, aes(x=abs(delta_gapdh), y=t1.norm1)) +
    geom_smooth(method='glm', method.args=list(family='binomial')) +
    ylab("Prob(Type I): norm1") +
    xlab(expression(paste("|",Gapdh[t] - Gapdh[c],"|"))) +
    theme_minimal()
  gg3 <- ggplot(data=res, aes(x=abs(delta_gapdh), y=t1.norm2)) +
    geom_smooth(method='glm', method.args=list(family='binomial')) +
    ylab("Prob(Type I): norm2") +
    xlab(expression(paste("|",Gapdh[t] - Gapdh[c],"|"))) +
    theme_minimal()
  gg <- plot_grid(gg1, gg2, gg3, nrow=1)
  return(gg)
}
```


### Results and consequences
#### Cor with Gapdh=0, no treatment effect

This simulates a case where there is no correlation between the reference level and the experimental (control and treatment) levels. Wouldn't need to normalize if this were the case but I include here to show how patterns are created by normalization.

```{r simulation1}
set.seed(1)
file_path <- here(output_path, "normalization_res1.rds")
if(simulate_it==TRUE){
  res <- iterate_experiment(
  n=4, # number of replicates per treatment level
  niter=5000, # number of iterations
  rho=0, # correlation between the reference value and that of a control level
  s_kappa=1, # effect of treatment on shape (this is multiplicative so 1 = no effect)
  s_theta=1, # effect of treatment on scale (this is multiplicative so 1 = no effect
  kappa_0=80, # shape parameter for reference
  theta_0=100, # scale parameter for reference
  kappa_1=30, # shape parameter for control
  theta_1=100 # scale parameter for control
)
  saveRDS(res, file = file_path)
}else{
  res <- readRDS(file = file_path)
}

```

Unconditional Type I error in the three methods. "Unconditional" means not conditional on the observed difference in Gapdh value between treatment and control.
```{r}
prob_cols <- c("lm", "norm1", "norm2")
niter <- nrow(res)
type_1 <- apply(res[,.SD, .SDcols=prob_cols], 2, function(x) sum(x < 0.05)/niter)
knitr::kable(type_1, col.names="Type I")
```

Treatment effect size as a function of observed difference in Gapdh value between treatment and control $\Delta Gapdh$. A slope indicates a **conditional bias** of the effect on $\Delta Gapdh$, which results because of regression to the mean. The treatment effect of both norm1 and norm2 normalization is strongly conditionally biased.
```{r}
plot_effects(res)
# coef(summary(lm(effect_lm ~ delta_gapdh, data=res)))
```

The probability of Type I error as a function of observed difference in Gapdh value between treatment and control $\Delta Gapdh$. The nominal probability is 0.05. The plots show that the conditional Type I error (conditional on $\Delta Gapdh$) increases to exceedingly high values as the magnitude of $\Delta Gapdh$ increases for both Norm1 and Norm 2 normalization procedures.

```{r}
plot_prob_t1(res)
```

#### Cor with Gapdh=0.5, no treatment effect

A correlation between Gapdh value and that of the control or treatment is expected (and the reason why normalization is done).
```{r simulation2}
set.seed(1)
file_path <- here(output_path, "normalization_res2.rds")
if(simulate_it==TRUE){
  res <- iterate_experiment(
  n=4, # number of replicates per treatment level
  niter=5000, # number of iterations
  rho=0.5, # correlation between the reference value and that of a control level
  s_kappa=1, # effect of treatment on shape (this is multiplicative so 1 = no effect)
  s_theta=1, # effect of treatment on scale (this is multiplicative so 1 = no effect
  kappa_0=80, # shape parameter for reference
  theta_0=100, # scale parameter for reference
  kappa_1=30, # shape parameter for control
  theta_1=100 # scale parameter for control
)
  saveRDS(res, file = file_path)
}else{
  res <- readRDS(file = file_path)
}

```

Unconditional Type I error in the three methods. "Unconditional" means not conditional on the observed difference in Gapdh value between treatment and control.
```{r}
prob_cols <- c("lm", "norm1", "norm2")
niter <- nrow(res)
type_1 <- apply(res[,.SD, .SDcols=prob_cols], 2, function(x) sum(x < 0.05)/niter)
knitr::kable(type_1, col.names="Type I")
```

Treatment effect size as a function of observed difference in Gapdh value between treatment and control $\Delta Gapdh$. A slope indicates a **conditional bias** of the effect on $\Delta Gapdh$, which results because of regression to the mean. The treatment effect of both norm1 and norm2 normalization is strongly conditionally biased.
```{r}
plot_effects(res)
# coef(summary(lm(effect_lm ~ delta_gapdh, data=res)))
```

The probability of Type I error as a function of observed difference in Gapdh value between treatment and control $\Delta Gapdh$. The nominal probability is 0.05. The plots show that the conditional Type I error (conditional on $\Delta Gapdh$) increases to exceedingly high values as the magnitude of $\Delta Gapdh$ increases for both Norm1 and Norm 2 normalization procedures.

```{r}
plot_prob_t1(res)
```

Interesting. The linear model method gets a wee bit conservative with increasing $\Delta Gapdh$ while norm1 is a little liberal. Norm2 is liberal across the range of $\Delta Gapdh$.

#### Cor with Gapdh=0, treatment effect ~ 1 (cohen's d)

```{r simulation3}
set.seed(1)
file_path <- here(output_path, "normalization_res3.rds")
if(simulate_it==TRUE){
  res <- iterate_experiment(
  n=4, # number of replicates per treatment level
  niter=5000, # number of iterations
  rho=0, # correlation between the reference value and that of a control level
  s_kappa=1.1, # effect of treatment on shape (this is multiplicative so 1 = no effect)
  s_theta=1.1, # effect of treatment on scale (this is multiplicative so 1 = no effect
  kappa_0=80, # shape parameter for reference
  theta_0=100, # scale parameter for reference
  kappa_1=30, # shape parameter for control
  theta_1=100 # scale parameter for control
)
  saveRDS(res, file = file_path)
}else{
  res <- readRDS(file = file_path)
}

```

Since there is a true treatment effect, this is the power (instead of Type I error). Linear model has slightly more power than norm1. norm2 has most power but this is at cost of high Type I error.

```{r}
prob_cols <- c("lm", "norm1", "norm2")
niter <- nrow(res)
type_1 <- apply(res[,.SD, .SDcols=prob_cols], 2, function(x) sum(x < 0.05)/niter)
knitr::kable(type_1, col.names="Power")

```

We would hope the estimate of the effect would not change with $\Delta Gapdh$ (that is, it's not conditional on this). The conditional effects for both normalizations are interesting. I can't do the math to figure out what the E(effect) is for either normalization (except in the case when E(effect)=0 as above) but assuming these results are like the case with E(effect)=0 above, then effects are inflated when $\Delta Gapdh < 0$ and supressed when $\Delta Gapdh > 0$

```{r}
plot_effects(res)

```

### Cor with Gapdh=0.5, treatment effect ~ 1 (cohen's d)

```{r simulation4}
set.seed(1)
file_path <- here(output_path, "normalization_res4.rds")
if(simulate_it==TRUE){
  res <- iterate_experiment(
  n=4, # number of replicates per treatment level
  niter=5000, # number of iterations
  rho=0, # correlation between the reference value and that of a control level
  s_kappa=1, # effect of treatment on shape (this is multiplicative so 1 = no effect)
  s_theta=1, # effect of treatment on scale (this is multiplicative so 1 = no effect
  kappa_0=80, # shape parameter for reference
  theta_0=100, # scale parameter for reference
  kappa_1=30, # shape parameter for control
  theta_1=100 # scale parameter for control
)
  saveRDS(res, file = file_path)
}else{
  res <- readRDS(file = file_path)
}


```

Power.
```{r}
prob_cols <- c("lm", "norm1", "norm2")
niter <- nrow(res)
type_1 <- apply(res[,.SD, .SDcols=prob_cols], 2, function(x) sum(x < 0.05)/niter)
knitr::kable(type_1, col.names="Power")

```

```{r}
plot_effects(res)

```



