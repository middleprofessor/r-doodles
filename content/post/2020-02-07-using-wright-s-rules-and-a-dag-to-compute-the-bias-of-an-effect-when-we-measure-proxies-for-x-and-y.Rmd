---
title: Using Wright's rules and a DAG to compute the bias of an effect when we measure
  proxies for X and Y
author: Jeff Walker
date: '2020-02-07'
slug: using-wright-s-rules-and-a-dag-to-compute-the-bias-of-an-effect-when-we-measure-proxies-for-x-and-y
categories:
  - causal analysis
tags:
  - causal graph
  - fake data
  - Wright style path analysis
keywords:
  - tech
---

This is a skeletal post to work up an answer to a twitter question using Wright's rules of path models. Using this figure

```{r, echo=FALSE, eval=FALSE}
fn <- "proxy_dag.png"
#fig_path <- here::here("images", fn)
fig_path <- paste0("images/", fn)
knitr::include_graphics(fig_path)
```

![from Panel A of a figure from [Hernan and Cole. The scribbled red path coefficients are added](https://academic.oup.com/aje/article/170/8/959/145135)](/post/2020-02-07-using-wright-s-rules-and-a-dag-to-compute-the-bias-of-an-effect-when-we-measure-proxies-for-x-and-y_files/dag_of_proxy.png)

the question is `I want to know about A->Y but I measure A* and Y*. So in figure A, is the bias the backdoor path from A* to Y* through A and Y?`

Short answer: the bias is the path as stated *divided by* the path from A to Y.

Medium answer: We want to estimate $\beta$, the true effect of $A$ on $Y$. We have measured the proxies, $A^\star$ and $Y^\star$. The true effect of $A$ on $A^\star$ is $\alpha_1$ and the true effect of $Y$ on $Y^\star$ is $\alpha_2$. 

So what we want is $\beta$ but what we estimate is $\alpha_1 \beta \alpha_2$ (the path from $A^\star$ to $Y^\star$) so the bias is $\alpha_1 \alpha_2$.

But, this is really only true for standardized effects. If the variables are not variance-standardized (and why should they be?), the bias is a bit more complicated.

TL;DR answer: In terms of $\beta$ the estimated effect is

\begin{equation}
\alpha_1 \alpha_2 \frac{\sigma_A^2}{\sigma_{A^\star}^2} \beta
\end{equation}

so the bias is

\begin{equation}
k = \alpha_1 \alpha_2 \frac{\sigma_A^2}{\sigma_{A^\star}^2}
\end{equation}

The deriviation is scratched out here:

![Old fashion doodle deriving the bias of the estimate of $\beta$ when proxies of A and Y are measured. The bias is k.](/post/2020-02-07-using-wright-s-rules-and-a-dag-to-compute-the-bias-of-an-effect-when-we-measure-proxies-for-x-and-y_files/dag of proxy derivation.png)

![Part 2 of the derivation. Substituting the non-standardized coefficients in for the standardized coefficients.](/post/2020-02-07-using-wright-s-rules-and-a-dag-to-compute-the-bias-of-an-effect-when-we-measure-proxies-for-x-and-y_files/dag of proxy derivation part 2.png)

# If the data are standardized (all variables have unit variance)
This is easy and just uses Wright's rules of adding up effects along a path

```{r standardized fake data}
n <- 10^6
beta <- 0.6 # true effect
alpha_1 <- 0.9 # standardized effect of A on A* -- this is the correlation of A with proxy
alpha_2 <- 0.8 # standardized effect of Y o Y* -- this is the correlation of Y with proxy
A <- rnorm(n)
Y <- beta*A + sqrt(1 - beta^2)*rnorm(n)
astar <- alpha_1*A + sqrt(1 - alpha_1^2)*rnorm(n) # proxy for A
ystar <- alpha_2*Y + sqrt(1 - alpha_2^2)*rnorm(n) # proxy for Y
```

$\beta$ is the true effect and the expected estimated effect is $\alpha_1 \beta \alpha_2$ (using Wright rules) so $\alpha_1 \alpha_2$ is the bias. Note this isn't added to the true effect as in omitted variable bias (confounding). We can check this with the fake data.

```{r check the bias for standardized data}
alpha_1*beta*alpha_2 # expected measured effect
coef(lm(ystar ~ astar)) # measured effect
```

check some other measures

```{r}
var(A) # should be 1
var(Y) # should be 1
var(astar) # should be 1
var(ystar) # should be 1
cor(ystar, astar) # should be equal to expected measured effect


```

# if the data are not standardized

```{r non-standardized fake data}
n <- 10^5
rho_alpha_1 <- 0.9 # correlation of A and A*
rho_alpha_2 <- 0.8 # correlation of Y and Y*
rho_b <- 0.6 # standardized true effect of A on Y
sigma_A <- 2 # total variation in A
sigma_Y <- 10 # total variation in Y
sigma_astar <- 2.2 # total variation in A*
sigma_ystar <- 20 # total variation in Y* 
alpha_1 <- rho_alpha_1*sigma_astar/sigma_A # effect of A on astar
alpha_2 <- rho_alpha_2*sigma_ystar/sigma_Y # effect of Y on ystar
beta <- rho_b*sigma_Y/sigma_A # effect of A on Y (the thing we want)
A <- rnorm(n, sd=sigma_A)
R2_Y <- (beta*sigma_A)^2/sigma_Y^2 # R^2 for E(Y|A)
Y <- beta*A + sqrt(1-R2_Y)*rnorm(n, sd=sigma_Y)
R2_astar <- (alpha_1*sigma_A)^2/sigma_astar^2 # R^2 for E(astar|A)
astar <- alpha_1*A + sqrt(1-R2_astar)*rnorm(n, sd=sigma_astar)
R2_ystar <- (alpha_2*sigma_Y)^2/sigma_ystar^2 # R^2 for E(ystar|Y)
ystar <- alpha_2*Y + sqrt(1-R2_ystar)*rnorm(n, sd=sigma_ystar)
```

Now let's check our math in the figure above. Here is the estimated effect

```{r}
coef(lm(ystar ~ astar))
```

And the expected estimated effect using just the standardized coefficients

```{r}
rho_alpha_1*rho_alpha_2*rho_b*sigma_ystar/sigma_astar
```

And the expected estimated effect using the equation $k \beta$, where k is the bias (and equal to everything in )
```{r}
k <- rho_alpha_1*sigma_A/sigma_Y*rho_alpha_2*sigma_ystar/sigma_astar
k*beta
```

And finally, the expected estimated effect using the bias as a function of the unstandardized variables (derived in the part 2 image above)

```{r}
k <- alpha_1*alpha_2*sigma_A^2/sigma_astar^2
k*beta
```

And the true effect?

```{r}
beta
```

Some other checks
```{r}
coef(lm(ystar ~ Y))
alpha_2
```

```{r}
coef(lm(ystar ~ A))
alpha_2*beta
```

```{r}
coef(lm(astar ~ A))
alpha_1
```


```{r}
sd(A)
sd(Y)
sd(astar)
sd(ystar)
cor(A, astar)
cor(Y, ystar)
```


```

