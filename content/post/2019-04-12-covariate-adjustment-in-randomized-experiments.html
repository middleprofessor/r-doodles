---
title: Covariate adjustment in randomized experiments
author: Jeff Walker
date: '2019-04-12'
slug: covariate-adjustment-in-randomized-experiments
categories:
  - stats 101
tags:
  - ancova
  - categorical X
---



<p><a href="https://twitter.com/statsepi/status/1115902270888128514">The post motivated by a tweetorial from Darren Dahly</a></p>
<p>In an experiment, do we adjust for covariates that differ between treatment levels measured pre-experiment (“imbalance” in random assignment), where a difference is inferred from a t-test with p &lt; 0.05? Or do we adjust for all covariates, regardless of differences pre-test? Or do we adjust only for covariates that have sustantial correlation with the outcome? Or do we not adjust at all?</p>
<p>The original tweet focussed on Randomized Clinical Trials, which typically have large sample size. Here I simulate experimental biology, which typically has much smaller n.</p>
<pre class="r"><code>library(ggplot2)
library(GGally)
library(data.table)

source(&quot;../R/fake_x.R&quot;) # bookdown</code></pre>
<div id="fake-data" class="section level1">
<h1>Fake data</h1>
<p>Generate <span class="math inline">\(p\)</span> correlated variables and assign the first to the response (<span class="math inline">\(\mathbf{y}\)</span>) and the rest to the covariates (<span class="math inline">\(\mathbf{X}\)</span>). Construct a treatment variable and effect and add this to the response.</p>
<pre class="r"><code>n &lt;- 100 # per treatment level - this is modified below
p &lt;- 3 # number of covariates (columns of the data)
pp1 &lt;- p+1
beta_0 &lt;- 0 # intercept

niter &lt;- 2000 # modified below
measure_cols &lt;- c(&quot;no_adjust&quot;, &quot;imbalance&quot;, &quot;all_covariates&quot;, &quot;weak_covariates&quot;, &quot;strong_covariates&quot;)

xcols &lt;- paste0(&quot;X&quot;, 1:p)
build_ycols &lt;- c(&quot;Y_o&quot;, xcols)
cor_ycols &lt;- c(&quot;Y&quot;, xcols)

b_mat &lt;- data.table(NULL)
se_mat &lt;- data.table(NULL)
p_mat &lt;- data.table(NULL)
ci_mat &lt;- data.table(NULL)

for(beta_1 in c(0, 0.2, 0.8)){ # treatment effect on standardized scale
  beta &lt;- c(beta_0, beta_1)
  for(n in c(6, 10, 50)){
    # larger iterations with smaller n
    niter &lt;- round((3*10^4)/sqrt(n), 0)
    niter &lt;- 2000
    
    # repopulate with NA each n
    b &lt;- se &lt;- pval &lt;- ci &lt;- matrix(NA, nrow=niter, ncol=length(measure_cols))
    colnames(b) &lt;- colnames(se) &lt;- colnames(pval) &lt;- colnames(ci) &lt;- measure_cols
    
    Treatment &lt;- rep(c(&quot;Cn&quot;, &quot;Tr&quot;), each=n)
    X &lt;- model.matrix(formula(&quot;~ Treatment&quot;))
    
    for(iter in 1:niter){
      # generate p random, correlated variables. The first is assigned to Y
      fake_data &lt;- fake.X(n*2, pp1, fake.eigenvectors(pp1), fake.eigenvalues(pp1))
      colnames(fake_data) &lt;- build_ycols
      
      # resacale so that var(Y) = 1, where Y is the first column
      fake_data &lt;- fake_data/sd(fake_data[,1])
      
      fake_data &lt;- data.table(fake_data)
      
      # view the scatterplots
      #gg &lt;- ggpairs(X,progress = ggmatrix_progress(clear = FALSE))
      show_it &lt;- FALSE
      if(show_it ==TRUE){
        gg &lt;- ggpairs(fake_data)
        print(gg, progress = F)
      }
      
      # add the treatment effect
      fake_data[, Y:=Y_o + X%*%beta]
      fake_data[, Treatment:=Treatment]
      
      # model 1 - just the treatment
      fit1 &lt;- lm(Y ~ Treatment, data=fake_data)
      res &lt;- coef(summary(fit1))[&quot;TreatmentTr&quot;, ]
      b[iter, 1] &lt;- res[&quot;Estimate&quot;]
      se[iter, 1] &lt;- res[&quot;Std. Error&quot;]
      pval[iter, 1] &lt;-res[&quot;Pr(&gt;|t|)&quot;]
      ci_i &lt;- confint(fit1)[&quot;TreatmentTr&quot;,]
      ci[iter, 1] &lt;- ifelse(beta_1 &gt;= ci_i[1] &amp; beta_1 &lt;= ci_i[2], 1, 0)
      res1 &lt;- copy(res)
      
      # model 2 - adjust for imablance
      inc_xcols &lt;- NULL
      for(i in 1:p){
        formula &lt;- paste0(xcols[i], &quot; ~ Treatment&quot;)
        fit2a &lt;- lm(formula, data=fake_data)
        if(coef(summary(fit2a))[&quot;TreatmentTr&quot;, &quot;Pr(&gt;|t|)&quot;] &lt; 0.05){
          inc_xcols &lt;- c(inc_xcols, xcols[i])
        }
      }
      if(length(inc_xcols) &gt; 0){ # if any signifianct effects refit, otherwise use old fit
        formula &lt;- paste0(&quot;Y ~ Treatment + &quot;, paste(inc_xcols, collapse=&quot; + &quot;))
        fit2b &lt;- lm(formula, data=fake_data)
        res &lt;- coef(summary(fit2b))[&quot;TreatmentTr&quot;, ]
        ci_i &lt;- confint(fit2b)[&quot;TreatmentTr&quot;,]
      }else{
        res &lt;- res1
      }
      b[iter, 2] &lt;- res[&quot;Estimate&quot;]
      se[iter, 2] &lt;- res[&quot;Std. Error&quot;]
      pval[iter, 2] &lt;-res[&quot;Pr(&gt;|t|)&quot;]
      ci[iter, 2] &lt;- ifelse(beta_1 &gt;= ci_i[1] &amp; beta_1 &lt;= ci_i[2], 1, 0)
      
      
      # model 3- adjust for covariates
      (ycor &lt;- abs(cor(fake_data[, .SD, .SDcols=cor_ycols])[2:pp1, 1]))
      mean(ycor)
      
      j &lt;- 2
      for(target_cor in c(0, .2, .4)){
        j &lt;- j+1
        if(target_cor == 0.2){
          inc &lt;- which(ycor &lt; target_cor) # include only weak covariates
        }else{
          inc &lt;- which(ycor &gt; target_cor) # include all OR strong covariates
        }
        if(length(inc) &gt; 0){  # if matches refit, otherwise use old fit
          inc_xcols &lt;- xcols[inc]
          formula &lt;- paste0(&quot;Y ~ Treatment + &quot;, paste(inc_xcols, collapse=&quot; + &quot;))
          fit3 &lt;- lm(formula, data=fake_data)
          res &lt;- coef(summary(fit3))[&quot;TreatmentTr&quot;, ]
          ci_i &lt;- confint(fit3)[&quot;TreatmentTr&quot;,]
        }else{
          res &lt;- res1
        }
        b[iter, j] &lt;- res[&quot;Estimate&quot;]
        se[iter, j] &lt;- res[&quot;Std. Error&quot;]
        pval[iter, j] &lt;-res[&quot;Pr(&gt;|t|)&quot;]
        ci[iter, j] &lt;- ifelse(beta_1 &gt;= ci_i[1] &amp; beta_1 &lt;= ci_i[2], 1, 0)
      }
    }  
    b_mat &lt;- rbind(b_mat, data.table(n=n, beta_1=beta_1, b))
    se_mat &lt;- rbind(se_mat, data.table(n=n, beta_1=beta_1, se))
    p_mat &lt;- rbind(p_mat, data.table(n=n, beta_1=beta_1, pval))
    ci_mat &lt;- rbind(ci_mat, data.table(n=n, beta_1=beta_1, ci))
  }
}

p_long &lt;- melt(p_mat, measure.vars=measure_cols, variable.name=&quot;method&quot;, value.name=&quot;p&quot;)
ci_long &lt;- melt(ci_mat, measure.vars=measure_cols, variable.name=&quot;method&quot;, value.name=&quot;covers&quot;)
b_long &lt;- melt(b_mat, measure.vars=measure_cols, variable.name=&quot;method&quot;, value.name=&quot;b&quot;)
se_long &lt;- melt(se_mat, measure.vars=measure_cols, variable.name=&quot;method&quot;, value.name=&quot;se&quot;)


#ci_long[, .(coverage=sum(covers)/niter), by=.(method, n, beta_1)]</code></pre>
</div>
<div id="distribution-of-estimates" class="section level1">
<h1>Distribution of estimates</h1>
<pre class="r"><code>pd &lt;- position_dodge(0.8)
gg &lt;- ggplot(data=b_long, aes(x=factor(n), y=b, fill=method)) +
  geom_boxplot(position=pd) +
  xlab(&quot;sample size (per treatment level)&quot;) +
  NULL
gg</code></pre>
<p><img src="/post/2019-04-12-covariate-adjustment-in-randomized-experiments_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
</div>
<div id="distribution-of-se-of-estimate" class="section level1">
<h1>Distribution of SE of estimate</h1>
<pre class="r"><code>pd &lt;- position_dodge(0.8)
gg &lt;- ggplot(data=se_long, aes(x=factor(n), y=se, fill=method)) +
  geom_boxplot(position=pd) +
  xlab(&quot;sample size (per treatment level)&quot;) +
  NULL
gg</code></pre>
<p><img src="/post/2019-04-12-covariate-adjustment-in-randomized-experiments_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
</div>
<div id="type-i-error" class="section level1">
<h1>Type I error</h1>
<pre class="r"><code># type I
p_sum &lt;- p_long[, .(error=sum(p &lt; 0.05)/niter), by=.(method, n, beta_1)]
pd &lt;- position_dodge(0.8)
gg &lt;- ggplot(data=p_sum[beta_1==0], aes(x=factor(n), y=error, color=method, group=method)) +
  geom_point(position=pd) +
  geom_line(position=pd) + 
  xlab(&quot;sample size (per treatment level)&quot;) +
  ylab(&quot;Type I error&quot;) +
  # facet_grid(.~beta_1) +
  NULL
gg</code></pre>
<p><img src="/post/2019-04-12-covariate-adjustment-in-randomized-experiments_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
</div>
<div id="power" class="section level1">
<h1>Power</h1>
<pre class="r"><code># power
# need p_sum from above
gg &lt;- ggplot(data=p_sum[beta_1!=0], aes(x=factor(n), y=error, color=method)) +
  geom_point(position=pd) +
  xlab(&quot;sample size (per treatment level)&quot;) +
  ylab(&quot;Power&quot;) +
  facet_grid(.~beta_1) +
  NULL
gg</code></pre>
<p><img src="/post/2019-04-12-covariate-adjustment-in-randomized-experiments_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
</div>
<div id="sign-error" class="section level1">
<h1>Sign error</h1>
<pre class="r"><code># sign error
p_long2 &lt;- cbind(p_long, b=b_long[, b])
sign_error &lt;- p_long2[beta_1 &gt; 0, .(error=sum(p &lt; 0.1 &amp; b &lt; 0)/niter), by=.(method, n, beta_1)]
gg &lt;- ggplot(data=sign_error, aes(x=factor(n), y=error, color=method)) +
  geom_point(position=pd) +
  xlab(&quot;sample size (per treatment level)&quot;) +
  ylab(&quot;Sign error&quot;) +
  facet_grid(.~beta_1) +
  NULL
gg</code></pre>
<p><img src="/post/2019-04-12-covariate-adjustment-in-randomized-experiments_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
</div>
