---
title: Should the model-averaged prediction be computed on the link or response scale
  in a GLM?
author: Jeff Walker
date: '2018-05-13'
slug: should-the-model-averaged-prediction-be-computed-on-the-link-or-response-scale-in-a-glm
categories: []
tags:
  - ecology
  - model-averaged predictions
  - model averaging
  - generalized linear models
---



<p>(TL;DR: This post-contains a disagreement on the default output of the R package MuMIn, which computes model-averaged predictions and coefficients. But I don’t get to this until point 6 below.)</p>
<p>This post is a follow up <a href="/04/04/model-averaged-coefficients-of-a-glm">to my inital post</a>, which was written as as a way for me to pen my mental thoughts on the recent review of <a href="https://esajournals.onlinelibrary.wiley.com/doi/abs/10.1002/ecm.1309" target="_blank">“Model averaging in ecology: a review of Bayesian, information‐theoretic and tactical approaches for predictive inference”</a>. It was also written without contacting and discussing the issue with the authors. This post benefits from a series of e-mails with the lead author Carsten Dormann and the last author Florian Hartig.</p>
<p>The Dormann et al. paper focuses on model-averaged predictions, but has a short discussion on problems with model-averaged coefficients in the supplement. It is in the supplement, that the authors state that for generalized linear models (GLMs) “coefficient averaging is not equivalent to prediction averaging”. Brian Cade<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> also makes this argument.</p>
<p>In my previous post, I argued that this statement is wrong – predictions from a parameter-averaged model is mathematically identical to averaging predictions. It was hard for me to understand how this was not immediately obvious until my e-mail exchange with Carsten and Florian. In short, I assume that all averaging is done on the link scale and then the predictions are back-transformed to the response scale. Carsten and Florian (and Brian Cade?) argue that this is the “wrong” way to compute averaged predictions. So..</p>
<p>The summary of our differences is</p>
<ol style="list-style-type: decimal">
<li><p>Carsten and Florian argue that predictions should computed on the link scale, back-transformed to the response scale, and then averaged on the response scale. I understand their reason to be that first, this is how everyone outside of ecology does it, and second, predictions have to be averaged on the response scale for non-linear models because there is no link scale, and, since, GLMs are non-linear models, they should be averaged on the response scale.</p></li>
<li><p>I argue that because the model is fit on a linear scale, any subsequent averaging should be on the linear scale. My reason is that because a GLM <em>is a linear model</em>, additive math should be additive (on the link scale) and not multiplicative (on the response scale) to be consistent with the meaning of the fit parameters. For example, a prediction is a weighted sum of the data, with weights that are a function of a linear fit, and everyone agrees that predictions should be computed on the link scale and then back-transformed (if desired). And, a model-averaged prediction is a weighted sum, with both weights and variables that are functions of linear fits, and so the predictions should be averaged on the link scale, and then back-transformed to the response scale (if desired).</p></li>
</ol>
<p>Some final thoughts using their equation S2</p>
<span class="math display">\[\begin{equation}
\frac{1}{m} \sum_{i=1}^m{g^{-1}(Xb_i)} \ne g^{-1}(X \frac{\sum_{i=1}^m{b_i}}{m})
\end{equation}\]</span>
<ol start="3" style="list-style-type: decimal">
<li><p>Dormann et al. advocate averaging using the LHS of eq. S2, I advocate using the RHS.</p></li>
<li><p>If using the RHS of S2 to average predictors, then averaging the predictors or computing the predictor from averaged coefficients are mathematically equivalent.</p></li>
<li><p>GLMs are unlike non-linear models in that non-linear models do not have link functions although some can be linearized. There is no linear model that is fit. Consquently, for non-linear models, averging the predictors of non-linear models on the “response scale” is consistent with the fit model. So in my opinion, this isn’t good justification for averaging GLMs on the response scale.</p></li>
<li><p>Because Carsten and Florian (and presumably the other co-authors of Dormann et al.) argue that predictions should be model averaged on the response scale, they argue that predict.averaging () from the MuMIn package is the wrong way to compute averaged predictors, since these are computed on the link scale and then back-transformed to the response scale. I argue that this is the “right” way to compute these, where “right” is in the sense that it maintains the meaning of the parameters.</p></li>
<li><p>I think this argument from Russell Lenth, the author of the amazingly useful emmeans (formerly lsmeans) package, supports my argument for averaging on the link scale. Here, Lenth comments on why <a href="https://cran.r-project.org/web/packages/emmeans/vignettes/transformations.html">the package computes marginal means on the link and not response scale for GLMs</a>:</p></li>
</ol>
<blockquote>
<p>The model is our best guide</p>
</blockquote>
<blockquote>
<p>This choice of timing is based on the idea that the model is right. In particular, the fact that the response is transformed suggests that the transformed scale is the best scale to be working with. In addition, the model specifies that the effects of source and percent are linear on the transformed scale; inasmuch as marginal averaging to obtain EMMs is a linear operation, that averaging is best done on the transformed scale. For those two good reasons, back-transforming to the response scale is delayed until the very end by default.&quot;</p>
</blockquote>
<ol start="8" style="list-style-type: decimal">
<li><p>The difference in predicted values computed on the link vs. response scale is trivially small for the example below, and probably in most real examples so in a sense, our argument is doesn’t really matter. There are much bigger sources of error in modeling than this.</p></li>
<li><p>Finally, in response to an exchange with Florian, I wanted to make sure that my understanding of MuMIn is correct (it seems to be), so here are five ways to compute a simple count (poisson) example using fake data in addition to the computation from MuMIn.</p></li>
</ol>
<pre class="r"><code>library(ggplot2)
library(MuMIn)
library(BAS)
library(data.table)</code></pre>
<p>A simple model of counts</p>
<pre class="r"><code>  n &lt;- 100
  exp_beta_0 &lt;- 175 # mean Y on response scale
  exp_beta_1 &lt;- 0.99 # effect on response scale
  exp_beta_2 &lt;- 0.99 # effect on response sacle
  
  # create correlated x1 and x2 due to common factor z
  z &lt;- rnorm(n) # common factor to correlate X1 and X2
  r &lt;- 0.6 # correlation between x1 and x2
  alpha &lt;- sqrt(r) # &quot;effect&quot; of Z on X1 and X2
  x1 &lt;- alpha*z + sqrt(1-r)*rnorm(n)
  x2 &lt;- alpha*z + sqrt(1-r)*rnorm(n)

  # expected count in link space
  E_log_count &lt;- log(exp_beta_0) + log(exp_beta_1)*x1 + log(exp_beta_2)*x2 # expected log count
  # observed counts
  count &lt;- rpois(n=n, lambda=exp(E_log_count))

  # create data.table and fit 
  dt &lt;- data.table(count=count, x1=x1, x2=x2)
  fit &lt;- glm(count ~ x1 + x2, family=poisson(link = &quot;log&quot;), data=dt,na.action=na.fail )
  X &lt;- model.matrix(fit)
  
  # all model regression using MuMIn
  fit.mm &lt;- dredge(fit)</code></pre>
<pre><code>## Fixed term is &quot;(Intercept)&quot;</code></pre>
<pre class="r"><code>  model_set &lt;- get.models(fit.mm, subset=TRUE) # all models
  fit.avg &lt;- model.avg(model_set) # coeffcients are on link scale
  fit.avg</code></pre>
<pre><code>## 
## Call:
## model.avg(object = model_set)
## 
## Component models: 
## &#39;1&#39;      &#39;12&#39;     &#39;2&#39;      &#39;(Null)&#39;
## 
## Coefficients: 
##        (Intercept)          x1           x2
## full      5.151309 -0.02318660 -0.005917254
## subset    5.151309 -0.02500045 -0.012549601</code></pre>
<pre class="r"><code>  # (0) MuMIn predict
  yhat0.MuMIn &lt;- predict(fit.avg, backtransform=TRUE)
  
  #is this averaged on link or response scale? And is it the coefficients or the prediction that is averaged?
  
  # (1) average coefficients on link scale. compute prediction on link scale. transform predictions to response scale
  b &lt;- fit.avg$coefficients[&#39;full&#39;,][colnames(X)]
  yhat1 &lt;- exp((X%*%b)[,1]) #
  b_ma_link &lt;- b

  # (2) compute predictions for each model on link scale. Average on link scale. Backtransform to response scale
  yhat2a &lt;- exp(predict(fit.avg, backtransform=FALSE))
  w &lt;- fit.mm$weight
  yhat2b.each_model.link_scale &lt;- sapply(model_set, predict)
  yhat2b.link_scale &lt;- (yhat2b.each_model.link_scale%*%w)[,1]
  yhat2b &lt;- exp(yhat2b.link_scale)
  
  # (3) compute predictions for each model on link scale. Backtransform to response scale. Average on response scale. This is method of Dormann et al.
  yhat3.each_model.response_scale &lt;- exp(yhat2b.each_model.link_scale)
  yhat3 &lt;- (yhat3.each_model.response_scale%*%w)[,1]
  
  # (4) backtransform coefficients to response scale. Average coefficients on response scale. Compute prediction on response scale.
  B &lt;- exp(fit.mm[,colnames(X)])
  B[is.na(B)] &lt;- 0.0
  b_ma &lt;- t(B)%*%w
  yhat4 &lt;- (X%*%b_ma)[,1] #

  # (5) average coefficients on link scale. backtransform to response scale. compute prediction on response scale
  b &lt;- exp(fit.avg$coefficients[&#39;full&#39;,][colnames(X)])
  yhat5 &lt;- (X%*%b)[,1] #</code></pre>
<div id="results" class="section level1">
<h1>Results</h1>
<p>The first few rows of the results matrix of the predictions using five different methods for their computation.</p>
<pre><code>##       MuMIn    yhat1    yhat2    yhat3    yhat4    yhat5
## 1: 173.9498 173.9498 173.9498 173.9504 172.3891 172.4148
## 2: 164.2731 164.2731 164.2731 164.2749 175.0038 176.0379
## 3: 168.3944 168.3944 168.3944 168.4153 173.4299 173.0677
## 4: 178.8003 178.8003 178.8003 178.8016 171.0937 170.5504
## 5: 163.9056 163.9056 163.9056 163.9076 175.1467 176.3084
## 6: 171.9273 171.9273 171.9273 171.9298 173.0122 173.4370</code></pre>
<p><strong>Column Keys</strong></p>
<p>MuMIn = MuMIn’s default prediction</p>
<p>yhat1 = Coefficients averaged on link scale. Predictions computed on link scale from averaged coefficients and then backtransformed to response scale. My preferred method. RHS of eq. S2.</p>
<p>yhat2 = Predictions computed on link scale for each model and then averaged on link scale and then backtransformed to response scale. Alternative to my preferred method.</p>
<p>yhat3 = Predictions computed on link scale for each model and then backtransformed to response scale and then averaged on response scale. This is the method of Dormann et al. 2018 and Cade 2015</p>
<p>yhat4 = Coefficients backtransformed to response scale and then averaged on response scale. Predictions computed on response scale from averaged coefficients.</p>
<p>yhat5 = Coefficients averaged on link scale and then backtransformed to response scale, which are used to compute averaged predictions.</p>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Cade, B.S. (2015). Model averaging and muddled multimodel inferences. Ecology 96, 2370–2382.<a href="#fnref1">↩</a></p></li>
</ol>
</div>
