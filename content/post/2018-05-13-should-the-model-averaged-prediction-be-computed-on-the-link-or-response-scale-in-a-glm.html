---
title: Should the model-averaged prediction be computed on the link or response scale
  in a GLM?
author: Jeff Walker
date: '2018-05-13'
slug: should-the-model-averaged-prediction-be-computed-on-the-link-or-response-scale-in-a-glm
categories: []
tags:
  - ecology
  - model-averaged predictions
  - model averaging
  - generalized linear models
---



<p>(TL;DR: This post-includes a disagreement on the output of the R package MuMIn, which computes model-averaged predictions and coefficients. But I don’t get to this until point 6 below.)</p>
<p>This post is a follow up <a href="/2018/05/model-averaged-coefficients-of-a-glm">to my inital post</a>, which was written as as a way for me to pen my mental thoughts on the recent review of <a href="https://esajournals.onlinelibrary.wiley.com/doi/abs/10.1002/ecm.1309" target="_blank">“Model averaging in ecology: a review of Bayesian, information‐theoretic and tactical approaches for predictive inference”</a>. It was also written without contacting and discussing the issue with the authors. This post benefits from a series of e-mails with the lead author Carsten Dormann and the last author Florian Hartig.</p>
<p>The Dormann et al. paper focuses on model-averaged predictions, but has a short discussion on problems with model-averaged coefficients in the supplement. It is in the supplement, that the authors state that for generalized linear models (GLMs) “coefficient averaging is not equivalent to prediction averaging”. Brian Cade<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> also makes this argument.</p>
<p>In my previous post, I argued that this statement is wrong – predictions from a parameter-averaged model is mathematically identical to averaging predictions. It was hard for me to understand how this was not immediately obvious until my e-mail exchange with Carsten and Florian. In short, I assume that all averaging is done on the link scale and then the predictions are back-transformed to the response scale. Carsten and Florian (and Brian Cade?) argue that this is the “wrong” way to compute averaged predictions.</p>
<p>The summary of our differences is</p>
<ol style="list-style-type: decimal">
<li><p>Carsten and Florian argue that predictions should be computed on the link scale, back-transformed to the response scale, and then averaged on the response scale. I understand their reason to be that first, this is how everyone outside of ecology does it, and second, predictions have to be averaged on the response scale for non-linear models because there is no link scale, and, since, GLMs are non-linear models, they should be averaged on the response scale.</p></li>
<li><p>I argue that because a GLM model is fit on a linear scale, any subsequent averaging should be on the linear scale. My reason is that because a GLM <em>is a linear model</em>, additive math should be additive (on the link scale) and not multiplicative (on the response scale) to be consistent with the meaning of the fit parameters. For example, a prediction is a weighted sum of the data, with weights that are a function of a linear fit, and everyone agrees that predictions should be computed on the link scale and then back-transformed (if desired). And, a model-averaged prediction is a weighted sum, with both weights and variables that are functions of linear fits, and so the predictions should be averaged on the link scale, and then back-transformed to the response scale (if desired).</p></li>
</ol>
<p>Some final thoughts using their equation S2</p>
<span class="math display">\[\begin{equation}
\frac{1}{m} \sum_{i=1}^m{g^{-1}(Xb_i)} \ne g^{-1}(X \frac{\sum_{i=1}^m{b_i}}{m})
\end{equation}\]</span>
<ol start="3" style="list-style-type: decimal">
<li><p>Dormann et al. advocate averaging using the LHS of eq. S2, I advocate using the RHS.</p></li>
<li><p>If using the RHS of S2 to average predictors, <a href="/2018/05/model-averaged-coefficients-of-a-glm">then averaging the predictors or computing the predictor from averaged coefficients are mathematically equivalent</a>.</p></li>
<li><p>GLMs are unlike non-linear models in that non-linear models do not have link functions although some can be linearized. There is no linear model that is fit. Consquently, for non-linear models, averging the predictors of non-linear models on the “response scale” is consistent with the fit model. So in my opinion, this isn’t good justification for averaging GLMs on the response scale.</p></li>
<li><p>Because Carsten and Florian (and presumably the other co-authors of Dormann et al.) argue that predictions should be model averaged on the response scale, they argue that predict.averaging () from the MuMIn package is the wrong way to compute averaged predictors, since these are computed on the link scale and then back-transformed to the response scale. I argue that this is the “right” way to compute these, where “right” is in the sense that it maintains the meaning of the parameters.</p></li>
<li><p>I think this argument from Russell Lenth, the author of the amazingly useful emmeans (formerly lsmeans) package, supports my argument for averaging on the link scale. Here, Lenth comments on why <a href="https://cran.r-project.org/web/packages/emmeans/vignettes/transformations.html">the package computes marginal means on the link and not response scale for GLMs</a>:</p></li>
</ol>
<blockquote>
<p>The model is our best guide</p>
</blockquote>
<blockquote>
<p>This choice of timing is based on the idea that the model is right. In particular, the fact that the response is transformed suggests that the transformed scale is the best scale to be working with. In addition, the model specifies that the effects of source and percent are linear on the transformed scale; inasmuch as marginal averaging to obtain EMMs is a linear operation, that averaging is best done on the transformed scale. For those two good reasons, back-transforming to the response scale is delayed until the very end by default.&quot;</p>
</blockquote>
<ol start="8" style="list-style-type: decimal">
<li><p>The difference in predicted values computed on the link vs. response scale is trivially small for the example below, and perhaps in most real examples, and if this is the case, our argument doesn’t really matter. There are much bigger sources of error in modeling than this.</p></li>
<li><p>Finally, in response to an exchange with Florian, I wanted to make sure that my understanding of MuMIn is correct (it seems to be), so here are five ways to compute a simple count (poisson) example using fake data in addition to the computation from MuMIn.</p></li>
<li><p>Like MuMIn, The BAS package defaults to averaging on the link scale without back-transformation to the response scale – see the code at the bottom. Unlike MuMIn, BAS outputs the predictions on the response scale averaged on the response scale – these are not equal to the back-transformation of the default predictions on the link scale. I couldn’t find this documented.</p></li>
</ol>
<div id="how-does-mumin-model-average-predictions" class="section level2">
<h2>How does MuMIn model average predictions?</h2>
<pre class="r"><code>library(ggplot2)
library(MuMIn)
library(BAS)
library(data.table)</code></pre>
<p>A simple model of counts</p>
<pre class="r"><code>  set.seed(1)
  n &lt;- 100
  exp_beta_0 &lt;- 175 # mean Y on response scale
  exp_beta_1 &lt;- 0.99 # effect on response scale
  exp_beta_2 &lt;- 0.99 # effect on response sacle
  
  # create correlated x1 and x2 due to common factor z
  z &lt;- rnorm(n) # common factor to correlate X1 and X2
  r &lt;- 0.6 # correlation between x1 and x2
  alpha &lt;- sqrt(r) # &quot;effect&quot; of Z on X1 and X2
  x1 &lt;- alpha*z + sqrt(1-r)*rnorm(n)
  x2 &lt;- alpha*z + sqrt(1-r)*rnorm(n)

  # expected count in link space
  E_log_count &lt;- log(exp_beta_0) + log(exp_beta_1)*x1 + log(exp_beta_2)*x2 # expected log count
  # observed counts
  count &lt;- rpois(n=n, lambda=exp(E_log_count))

  # create data.table and fit 
  dt &lt;- data.table(count=count, x1=x1, x2=x2)
  fit &lt;- glm(count ~ x1 + x2, family=poisson(link = &quot;log&quot;), data=dt,na.action=na.fail )
  X &lt;- model.matrix(fit)
  
  # all model regression using MuMIn
  fit.mm &lt;- dredge(fit)</code></pre>
<pre><code>## Fixed term is &quot;(Intercept)&quot;</code></pre>
<pre class="r"><code>  model_set &lt;- get.models(fit.mm, subset=TRUE) # all models
  fit.avg &lt;- model.avg(model_set) # coeffcients are on link scale
  fit.avg</code></pre>
<pre><code>## 
## Call:
## model.avg(object = model_set)
## 
## Component models: 
## &#39;2&#39;      &#39;12&#39;     &#39;1&#39;      &#39;(Null)&#39;
## 
## Coefficients: 
##        (Intercept)          x2           x1
## full      5.168167 -0.02107276 -0.002326521
## subset    5.168167 -0.02288317 -0.007265122</code></pre>
<pre class="r"><code>  # (0) MuMIn predict
  yhat0.MuMIn &lt;- predict(fit.avg, backtransform=TRUE)
  
  #is this averaged on link or response scale? And is it the coefficients or the prediction that is averaged?
  
  # (1) average coefficients on link scale. compute prediction on link scale. transform predictions to response scale
  b &lt;- fit.avg$coefficients[&#39;full&#39;,][colnames(X)]
  yhat1 &lt;- exp((X%*%b)[,1]) #
  b_ma_link &lt;- b

  # (2) compute predictions for each model on link scale. Average on link scale. Backtransform to response scale
  yhat2a &lt;- exp(predict(fit.avg, backtransform=FALSE))
  w &lt;- fit.mm$weight
  yhat2b.each_model.link_scale &lt;- sapply(model_set, predict)
  yhat2b.link_scale &lt;- (yhat2b.each_model.link_scale%*%w)[,1]
  yhat2b &lt;- exp(yhat2b.link_scale)
  
  # (3) compute predictions for each model on link scale. Backtransform to response scale. Average on response scale. This is method of Dormann et al.
  yhat3.each_model.response_scale &lt;- exp(yhat2b.each_model.link_scale)
  yhat3 &lt;- (yhat3.each_model.response_scale%*%w)[,1]
  
  # (4) backtransform coefficients to response scale. Average coefficients on response scale. Compute prediction on response scale.
  B &lt;- exp(fit.mm[,colnames(X)])
  B[is.na(B)] &lt;- 0.0
  b_ma &lt;- t(B)%*%w
  yhat4 &lt;- (X%*%b_ma)[,1] #

  # (5) average coefficients on link scale. backtransform to response scale. compute prediction on response scale
  b &lt;- exp(fit.avg$coefficients[&#39;full&#39;,][colnames(X)])
  yhat5 &lt;- (X%*%b)[,1] #</code></pre>
<div id="results" class="section level3">
<h3>Results</h3>
<p>The first few rows of the results matrix of the predictions using five different methods for their computation.</p>
<pre><code>##       MuMIn    yhat1    yhat2    yhat3    yhat4    yhat5
## 1: 176.7927 176.7927 176.7927 176.7934 175.1100 174.4955
## 2: 171.1034 171.1034 171.1034 171.1072 176.7358 176.9463
## 3: 174.7764 174.7764 174.7764 174.7805 175.5243 174.7209
## 4: 171.3024 171.3024 171.3024 171.3036 176.9411 177.9302
## 5: 180.1184 180.1184 180.1184 180.1233 174.4711 174.2690
## 6: 171.9407 171.9407 171.9407 171.9422 176.5958 176.9982</code></pre>
<p><strong>Column Keys</strong></p>
<p>MuMIn = MuMIn’s default prediction</p>
<p>yhat1 = Coefficients averaged on link scale. Predictions computed on link scale from averaged coefficients and then backtransformed to response scale. My preferred method. RHS of eq. S2.</p>
<p>yhat2 = Predictions computed on link scale for each model and then averaged on link scale and then backtransformed to response scale. Alternative to my preferred method.</p>
<p>yhat3 = Predictions computed on link scale for each model and then backtransformed to response scale and then averaged on response scale. This is the method of Dormann et al. 2018 and Cade 2015</p>
<p>yhat4 = Coefficients backtransformed to response scale and then averaged on response scale. Predictions computed on response scale from averaged coefficients.</p>
<p>yhat5 = Coefficients averaged on link scale and then backtransformed to response scale, which are used to compute averaged predictions.</p>
</div>
</div>
<div id="how-does-the-bas-package-model-average-predictions" class="section level2">
<h2>How does the BAS package model-average predictions?</h2>
<p>This simulation uses the fake data generated above. I’m using package version 1.4.9 and the help page is for 1.5.0, which looks like it has important updates on the output from predict.basglm (I’m using 1.4.9 because I couldn’t get 1.5.0 to compile)</p>
<pre class="r"><code>  # fit using BMA
  packageVersion(&quot;BAS&quot;)</code></pre>
<pre><code>## [1] &#39;1.4.9&#39;</code></pre>
<pre class="r"><code>  # fit &lt;- glm(count ~ x1 + x2, family=poisson(link = &quot;log&quot;), data=dt,na.action=na.fail )
  fit.bma &lt;- bas.glm(count ~ x1 + x2, family=poisson(link = &quot;log&quot;), data=dt)
 
  res.bma.rs &lt;- predict(fit.bma, type=&#39;response&#39;)
  res.bma0.rs &lt;- res.bma.rs$fit[,1]
  res.bma1.rs.ls &lt;- res.bma.rs$Ybma[,1]
  res.bma1.rs.exp.ls &lt;- exp(res.bma1.rs.ls)
  
  res.bma.ls &lt;- predict(fit.bma)
  res.bma0.ls &lt;- res.bma.ls$fit[,1]
  res.bma1.ls.ls &lt;- res.bma.ls$Ybma[,1]
  res.bma1.ls.exp.ls &lt;- exp(res.bma1.ls.ls)
  
  
  bas.res1 &lt;- data.table(
    default.fit=res.bma0.ls,
    default.Ybma=res.bma1.ls.ls,
    default.exp.Ybma=res.bma1.ls.exp.ls,
    response.fit=res.bma0.rs,
    response.Ybma=res.bma1.rs.ls,
    response.exp.Ybma=res.bma1.rs.exp.ls
  )
  
  res.bma &lt;- predict(fit.bma)
  yhat.bma.response &lt;- res.bma$fit[,1]
  yhat.bma.link &lt;- res.bma$Ybma[,1]
  YHAT &lt;- t(res.bma$Ypred)
  w &lt;- res.bma$postprobs
  # averaged on response scale
  yhat1.bma.response &lt;- (exp(YHAT)%*%w)[,1]
  # averaged on link scale and then backtransformed
  yhat2.bma.link &lt;- (YHAT%*%w)[,1]
  yhat2.bma.response &lt;- exp(yhat2.bma.link)

  bas.res2 &lt;- data.table(yhat0=yhat.bma.response,
             yhat1=yhat1.bma.response,
             yhat2=yhat2.bma.response)</code></pre>
<div id="result-1" class="section level3">
<h3>Result 1</h3>
<p>predict.basglm seems to have the same output regardless of the type=‘response’ specification. The prediction on the link scale is in “Ybma” and the prediction on the response scale is in “fit”. Note that <span class="math inline">\(exp(Ybma) \ne fit\)</span>. s</p>
<pre class="r"><code>head(bas.res1)</code></pre>
<pre><code>##    default.fit default.Ybma default.exp.Ybma response.fit response.Ybma
## 1:    176.5610     5.173649         176.5580     176.5610      5.173649
## 2:    173.0640     5.153591         173.0518     173.0640      5.153591
## 3:    175.7336     5.168932         175.7271     175.7336      5.168932
## 4:    172.5097     5.150390         172.4988     172.5097      5.150390
## 5:    177.8421     5.180803         177.8256     177.8421      5.180803
## 6:    173.3129     5.155058         173.3059     173.3129      5.155058
##    response.exp.Ybma
## 1:          176.5580
## 2:          173.0518
## 3:          175.7271
## 4:          172.4988
## 5:          177.8256
## 6:          173.3059</code></pre>
</div>
<div id="result-2" class="section level3">
<h3>Result 2</h3>
<p><span class="math inline">\(fit\)</span> is indeed the predictions averaged on the response scale and not <span class="math inline">\(exp(Ybma)\)</span></p>
<pre class="r"><code>head(bas.res2)</code></pre>
<pre><code>##       yhat0    yhat1    yhat2
## 1: 176.5610 176.5610 176.5580
## 2: 173.0640 173.0640 173.0518
## 3: 175.7336 175.7336 175.7271
## 4: 172.5097 172.5097 172.4988
## 5: 177.8421 177.8421 177.8256
## 6: 173.3129 173.3129 173.3059</code></pre>
<p>Key:</p>
<p>yhat0 - “fit”, which is the prediction on the response scale</p>
<p>yhat1 - my manual computation of the average on the response scale</p>
<p>yhat2 - my manual computation of the average on the link scale and then back-transformed to the response scale.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Cade, B.S. (2015). Model averaging and muddled multimodel inferences. Ecology 96, 2370–2382.<a href="#fnref1">↩</a></p></li>
</ol>
</div>
