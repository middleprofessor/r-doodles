---
title: 'Normalization results in regression to the mean and inflated Type I error conditional on the reference values'
author: Jeff Walker
date: '2019-10-16'
slug: normalization-results-in-regression-to-the-mean
categories:
  - reproducibility
  - stats 101
tags:
  - ancova
  - effect size
  - fake data
  - regression to the mean
  - bias
keywords:
  - tech
output:
  blogdown::html_page:
    toc: true
---


<div id="TOC">
<ul>
<li><a href="#background">Background</a></li>
<li><a href="#reproducibility">Reproducibility</a></li>
<li><a href="#what-are-the-consequences-of-normalization-compare-to-linear-model-with-gapdh-as-covariate">What are the consequences of normalization? Compare to linear model with Gapdh as covariate</a><ul>
<li><a href="#linear-models">linear models</a></li>
</ul></li>
<li><a href="#simulations">Simulations</a><ul>
<li><a href="#simulation-functions">Simulation functions</a></li>
<li><a href="#functions-to-plot-simulation-results">functions to plot simulation results</a></li>
<li><a href="#results-and-consequences">Results and consequences</a></li>
</ul></li>
</ul>
</div>

<p>This not fully fleshed out post has two tl;drs, the first is specific to the paper (see below), the second is very general, for anyone normalizing gel/blot/etc. data.</p>
<p>tl;dr 1 The linear model with Gapdh as covariate fit to the empirical data from the paper is inconclusive while the model with the normalization used by the authors has a very low p-value for both Met and pMet</p>
<p>tl;dr 2 Standard procedure in labs is to normalize values from gels/blots/etc by some standard that is expected to be constant across treatments. A problem with this is <em>regression to the mean</em>, which results in inflated Type I error. This means t-tests and such are too liberal, that is, we reject the null too often, or we too often conclude “an effect exists” when the evidence doesn’t favor this conclusion. The correct way to achieve the same goals as normalization is a linear model with the reference value as a covariate.</p>
<p>I would think this isn’t news but I’m not familiar with the literature. Google Scholaring found mostly normalization in microarray/RNAseq type stuff and much of this is concerned with different issues. There is abundant literature on normalizng on body weight and adjusting for baseline in pre-post designs, but there doesn’t seem to be much acknowledgment of regression to the mean within experimental biology. I did find this,</p>
<p>Janušonis, S., 2009. Comparing two small samples with an unstable, treatment-independent baseline. Journal of neuroscience methods, 179(2), pp.173-178.</p>
<p>which doesn’t seem to recognize the issue of regression to the mean and inflated conditional type I error.</p>
<div id="background" class="section level2">
<h2>Background</h2>
<p>I was having an internal conversation with myself, which led me to thinking about reproducibility in bench biology, which led me to the <a href="https://elifesciences.org/collections/9b1e83d1/reproducibility-project-cancer-biology">cancer reproducibility project</a>. What a terrific site.</p>
<p>I downloaded the article and data for Fig 1C of the <a href="https://elifesciences.org/articles/39944">Replication Study: Melanoma exosomes educate bone marrow progenitor cells toward a pro-metastatic phenotype through MET</a> just to explore. Without looking at the author’s code, I wrote my own script to replicate Fig 1C. My numbers weren’t quite right so I looked at the author’s script and realized that I needed to re-scale within Blot in addition to Antibody and Type. Once I did this, my code reproduces the author’s results. My method for preparing the data is <em>very</em> different from the authors (my code is very data.table-ish), which is pretty typical of any R analysis – ask 10 R scripters how to get something done and you’ll recieve 20 different answers.</p>
<p>Anyway, I’m curious about the normalization since this seems to be very common yet my intuition thinks it can lead to regression to the mean. The normalization here had 2 steps: 1) first, the value for the Antibody levels were normalized by the value of a reference (Gapdh) for each Set. This is the typical normalization throughout bench biology. And 2) second, the Gapdh-normalized values were rescaled by the mean of the Gapdh-normalized values for the shScr Condition within each combination of Antibody+Type+Blot and then <em>all</em> values in the shScr were assigned to 1 (since the mean within the Condition level is 1). The statistical test then is a one-sample t-test of shMet with <span class="math inline">\(\mu=1\)</span>.</p>
<p>Intuition 1: Step one of this normalization would seem to introduce a biased estimate of the effect, conditional on the mean difference in Gapdh between treatment and control values, very similar to the biased estimate of a change score (or change from pre to post) conditional on pre-treatment values <a href="https://www.middleprofessor.com/files/quasipubs/change_scores.html">in a pre-post design</a>.</p>
<p>Intuition 2: Step two would just seem to introduce type I error since we’re removing variance from the 2nd sample.</p>
<p>The proper way to avoid the conditional bias in a pre-post design is to add the pre-treatment value as a covariate. I don’t know if Normalization by a reference sample is conditionally biased but I re-analyzed the data using the Gapdh value as a covariate in a linear model. I also just re-ran a t-test of the normalized response (step 1) without the re-scaling in step 2. Both the linear model and t-test results <em>for these data</em> were very different from the original results. I plotted the data and it’s pretty easy to see why, but it’s hard for me to generalize from this one example. So I did a simulation to check my intuition above.</p>
<p>Indeed, both my intutions turn out to be true. All analysis is below. I parameterized the distribution of Gapdh and the other values so they looked something like the actual values in the paper. I don’t know how much my results would change given different parameterizations of these distributions.</p>
</div>
<div id="reproducibility" class="section level2">
<h2>Reproducibility</h2>
<pre class="r"><code>folder &lt;- &quot;Data from Generation and characterization of shMet B16-F10 cells and exosomes&quot;
filename &lt;- &quot;Study_42_Figure_1_WB_quant_Data.csv&quot;
file_path &lt;- here(data_path, folder, filename)
exp1 &lt;- fread(file_path)
#View(exp1)</code></pre>
<p>Create normalized values</p>
<ol style="list-style-type: decimal">
<li>Value.norm is the conventional normalization using the reference (Gapdh) value.</li>
<li>value.norm.2 is Value.norm rescaled by the mean of shScr</li>
<li>value.norm.3 is setting all rescalings of shScr to = 1</li>
</ol>
<pre class="r"><code># get Gapdh ref for each row to rescale (&quot;normalize&quot;) by Gapdh
gapdh_ref.dt &lt;- exp1[Antibody==&quot;Gapdh&quot;, .(gapdh_ref=mean(Value)), by=Set]
exp1.v1 &lt;- merge(exp1, gapdh_ref.dt, by=&quot;Set&quot;)
exp1.v1[, Value.norm:=Value/gapdh_ref]

# get mean shScr for each Antibody:Type:Blot to rescale by mean shScr 
shScr_ref.dt &lt;- exp1.v1[Condition==&quot;shScr&quot;, .(shScr_ref=mean(Value.norm)), by=.(Antibody, Type, Blot)]
exp1.v1 &lt;- merge(exp1.v1, shScr_ref.dt, by=c(&quot;Antibody&quot;, &quot;Type&quot;, &quot;Blot&quot;))
exp1.v1[, value.norm.2:=Value.norm/shScr_ref]
exp1.v1[, value.norm.3:=ifelse(Condition==&quot;shScr&quot;, 1, value.norm.2)]
#View(exp1.v1)

gg1 &lt;- ggbarplot(data=exp1.v1[Antibody==&quot;Met&quot; &amp; Type==&quot;Cells&quot;], 
                 x=&quot;Condition&quot;, 
                 y=&quot;value.norm.2&quot;,
          add=c(&quot;mean_se&quot;)) +
  ylab(&quot;Met&quot;) +
  NULL
gg2 &lt;- ggbarplot(data=exp1.v1[Antibody==&quot;pMet&quot; &amp; Type==&quot;Cells&quot;,],
                 x=&quot;Condition&quot;, 
                 y=&quot;value.norm.2&quot;,
                 add=c(&quot;mean_se&quot;)) +
  ylab(&quot;pMet&quot;) +
  NULL

gg3 &lt;- ggbarplot(data=exp1.v1[Antibody==&quot;Met&quot; &amp; Type==&quot;Cells&quot;], 
                 x=&quot;Condition&quot;, 
                 y=&quot;value.norm.3&quot;,
          add=c(&quot;mean_se&quot;)) +
  ylab(&quot;Met&quot;) +
  NULL
gg4 &lt;- ggbarplot(data=exp1.v1[Antibody==&quot;pMet&quot; &amp; Type==&quot;Cells&quot;,],
                 x=&quot;Condition&quot;, 
                 y=&quot;value.norm.3&quot;,
                 add=c(&quot;mean_se&quot;)) +
  ylab(&quot;pMet&quot;) +
  NULL

plot_grid(gg1, gg2, gg3, gg4, nrow=2)</code></pre>
<p><img src="/post/2019-10-16-normalization-results-in-regression-to-the-mean_files/figure-html/reproducibility-1.png" width="672" /></p>
<p>The two bottom plots reproduce Fig 1C from the paper. The two top plots are scaled by Gapdh but not shScr</p>
</div>
<div id="what-are-the-consequences-of-normalization-compare-to-linear-model-with-gapdh-as-covariate" class="section level2">
<h2>What are the consequences of normalization? Compare to linear model with Gapdh as covariate</h2>
<p>tl;dr Big. The linear model with Gapdh as covariate is inconclusive while the model with the normalization used by the authors has a very low p-value.</p>
<div id="linear-models" class="section level3">
<h3>linear models</h3>
<div id="met" class="section level4">
<h4>Met</h4>
<p>m1 is the preferred method. m2 is conventional normalization. m4 is what the author’s did.</p>
<pre class="r"><code># linear model with ref as covariate
m1 &lt;- lm(Value ~ gapdh_ref + Condition, data=exp1.v1[Antibody==&quot;Met&quot; &amp; Type==&quot;Cells&quot;])
# linear model with no accounting for ref
m2 &lt;- lm(Value ~ Condition, data=exp1.v1[Antibody==&quot;Met&quot; &amp; Type==&quot;Cells&quot;])
# linear model using Gapdh normalized values
m3 &lt;- lm(Value.norm ~ Condition, data=exp1.v1[Antibody==&quot;Met&quot; &amp; Type==&quot;Cells&quot;])
# linear model using Gapdh normalized rescaled to shScr values
m4 &lt;- lm(value.norm.3 ~ Condition, data=exp1.v1[Antibody==&quot;Met&quot; &amp; Type==&quot;Cells&quot;])
coef(summary(m1))</code></pre>
<pre><code>##                    Estimate   Std. Error    t value  Pr(&gt;|t|)
## (Intercept)    11545.929046 26227.993625  0.4402140 0.6895688
## gapdh_ref         -1.227088     3.499151 -0.3506815 0.7490069
## ConditionshScr 16769.492308  9964.835324  1.6828670 0.1909905</code></pre>
<pre class="r"><code>coef(summary(m2))</code></pre>
<pre><code>##                 Estimate Std. Error   t value   Pr(&gt;|t|)
## (Intercept)     2547.013   4791.796 0.5315362 0.62319492
## ConditionshScr 14538.350   6776.624 2.1453678 0.09849231</code></pre>
<pre class="r"><code>coef(summary(m3))</code></pre>
<pre><code>##                 Estimate Std. Error   t value  Pr(&gt;|t|)
## (Intercept)    0.3647146  0.5688478 0.6411462 0.5563180
## ConditionshScr 1.5410749  0.8044723 1.9156344 0.1279129</code></pre>
<pre class="r"><code>coef(summary(m4))</code></pre>
<pre><code>##                 Estimate Std. Error  t value    Pr(&gt;|t|)
## (Intercept)    0.2258586 0.06511642 3.468535 0.025617769
## ConditionshScr 0.7741414 0.09208852 8.406492 0.001095958</code></pre>
</div>
<div id="pmet" class="section level4">
<h4>pMet</h4>
<p>m1 is the preferred method. m2 is conventional normalization. m4 is what the author’s did.</p>
<pre class="r"><code># linear model with ref as covariate
m1 &lt;- lm(Value ~ gapdh_ref + Condition, data=exp1.v1[Antibody==&quot;pMet&quot; &amp; Type==&quot;Cells&quot;])
# linear model with no accounting for ref
m2 &lt;- lm(Value ~ Condition, data=exp1.v1[Antibody==&quot;pMet&quot; &amp; Type==&quot;Cells&quot;])
# linear model using Gapdh normalized values
m3 &lt;- lm(Value.norm ~ Condition, data=exp1.v1[Antibody==&quot;pMet&quot; &amp; Type==&quot;Cells&quot;])
# linear model using Gapdh normalized rescaled to shScr values
m4 &lt;- lm(value.norm.3 ~ Condition, data=exp1.v1[Antibody==&quot;pMet&quot; &amp; Type==&quot;Cells&quot;])
coef(summary(m1))</code></pre>
<pre><code>##                    Estimate  Std. Error    t value  Pr(&gt;|t|)
## (Intercept)    1038.5456491 8949.475770 0.11604542 0.9121333
## gapdh_ref         0.0656947    1.077481 0.06097064 0.9537447
## ConditionshScr 4474.0624660 3474.762371 1.28758804 0.2542632</code></pre>
<pre class="r"><code>coef(summary(m2))</code></pre>
<pre><code>##                Estimate Std. Error   t value  Pr(&gt;|t|)
## (Intercept)    1563.237   2243.615 0.6967491 0.5120363
## ConditionshScr 4471.471   3172.951 1.4092469 0.2084245</code></pre>
<pre class="r"><code>coef(summary(m3))</code></pre>
<pre><code>##                 Estimate Std. Error   t value  Pr(&gt;|t|)
## (Intercept)    0.2202671  0.2824690 0.7797922 0.4651516
## ConditionshScr 0.5380471  0.3994714 1.3468976 0.2266568</code></pre>
<pre class="r"><code>coef(summary(m4))</code></pre>
<pre><code>##                Estimate Std. Error  t value     Pr(&gt;|t|)
## (Intercept)    0.251231 0.05920414 4.243471 0.0054189900
## ConditionshScr 0.748769 0.08372730 8.942949 0.0001091122</code></pre>
</div>
<div id="some-plots-of-whats-going-on" class="section level4">
<h4>some plots of what’s going on</h4>
<pre class="r"><code>gg6 &lt;- ggplot(data=exp1.v1[Antibody==&quot;Met&quot; &amp; Type==&quot;Cells&quot;], aes(x=gapdh_ref, y=Value, color=Condition)) +
  geom_point() +
  ylab(&quot;Met&quot;) +
  theme_minimal() +
  NULL

gg7 &lt;- ggplot(data=exp1.v1[Antibody==&quot;Met&quot;], aes(x=gapdh_ref, y=Value, color=Condition, shape=Type)) +
  geom_point() +
  ylab(&quot;Met&quot;) +
  theme_minimal() +
  NULL

gg8 &lt;- ggplot(data=exp1.v1[Antibody==&quot;pMet&quot; &amp; Type==&quot;Cells&quot;], aes(x=gapdh_ref, y=Value, color=Condition)) +
  geom_point() +
  ylab(&quot;pMet&quot;) +
  theme_minimal() +
  NULL

gg9 &lt;- ggplot(data=exp1.v1[Antibody==&quot;pMet&quot;], aes(x=gapdh_ref, y=Value, color=Condition, shape=Type)) +
  geom_point() +
  ylab(&quot;pMet&quot;) +
  theme_minimal() +
  NULL
plot_grid(gg6, gg8, nrow=1)</code></pre>
<p><img src="/post/2019-10-16-normalization-results-in-regression-to-the-mean_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<p>It’s pretty hard to figure out systemic bias due to normalization with a sample size of 3 or 4 so…</p>
</div>
</div>
</div>
<div id="simulations" class="section level2">
<h2>Simulations</h2>
<p>Simulate the experiment in Fig 1 C of the paper. Effectively, this simulates an experiment with one control level, one treatment level, and a sample size of 4 (per level). Control and treatment levels are adjusted using a reference level (simulating Gapdh). The adjustments are 1) lm (linear model with Gapdh has covariate), 2) norm1 (the ratio of the control or treatment level divided by Gapdh level), 3) norm2 (norm1 rescaled to the control mean and then all control levels reset to equal one.)</p>
<div id="simulation-functions" class="section level3">
<h3>Simulation functions</h3>
<p>The main function for generating a data set with a control, a treatment, and a reference for normalization.</p>
<pre class="r"><code>simulate_experiment &lt;- function(
  n=10, # number of replicates per treatment level
  rho=0.5, # correlation between the reference value and that of a control level
  s_kappa=1, # effect of treatment on shape (this is multiplicative so 1 = no effect)
  s_theta=1, # effect of treatment on scale (this is multiplicative so 1 = no effect
  kappa_0=80, # shape parameter for reference
  theta_0=100, # scale parameter for reference
  kappa_1=30, # shape parameter for control
  theta_1=100 # scale parameter for control
){
  kappa_1_i &lt;- rep(c(kappa_1, kappa_1*s_kappa), each=n)
  theta_1_i &lt;- rep(c(theta_1, theta_1*s_theta), each=n)
  # control
  y1 &lt;- rgamma(n*2, shape=kappa_0 - rho*sqrt(kappa_0*kappa_1), scale=1)
  y2 &lt;- rgamma(n*2, shape=kappa_1_i - rho*sqrt(kappa_0*kappa_1_i), scale=1)
  y3 &lt;- rgamma(n*2, shape=rho*sqrt(kappa_0*kappa_1), scale=1)
  fd &lt;- data.table(
    treatment=rep(c(&quot;cn&quot;, &quot;tr&quot;), each=n),
    gapdh=theta_0*(y1+y3),
    value=theta_1_i*(y2+y3)
  )
  fd[, norm1:=value/gapdh]
  cn_ref &lt;- mean(fd[treatment==&quot;cn&quot;, norm1])
  fd[, norm2:=norm1/cn_ref]
  return(fd)
}</code></pre>
<p>Script to explore parameterization. To turn on, change eval to TRUE</p>
<pre class="r"><code>n=10^4 # number of replicates per treatment level
rho=0.5 # correlation between the reference value and that of a control level
s_kappa=1.1 # effect of treatment on shape (this is multiplicative so 1 = no effect)
s_theta=1.1 # effect of treatment on scale (this is multiplicative so 1 = no effect
kappa_0=80 # shape parameter for reference
theta_0=100 # scale parameter for reference
kappa_1=30 # shape parameter for control
theta_1=100 # scale parameter for control
(s_kappa*kappa_1*s_theta*theta_1 - kappa_1*theta_1)/(sqrt(kappa_1*theta_1^2))

fd &lt;- simulate_experiment(
  n, # number of replicates per treatment level
  rho, # correlation between the reference value and that of a control level
  s_kappa, # effect of treatment on shape (this is multiplicative so 1 = no effect)
  s_theta, # effect of treatment on scale (this is multiplicative so 1 = no effect
  kappa_0, # shape parameter for reference
  theta_0, # scale parameter for reference
  kappa_1, # shape parameter for control
  theta_1 # scale parameter for control
)

# quick and dirty cohen&#39;s
kappa_1*theta_1
s_kappa*kappa_1*s_theta*theta_1
(means_table &lt;- fd[, .(cell_mean=mean(value), cell_sd=sd(value)), by=treatment])
(means_table[treatment==&quot;tr&quot;, cell_mean] - means_table[treatment==&quot;cn&quot;, cell_mean])/means_table[treatment==&quot;cn&quot;, cell_sd]</code></pre>
<p>Script to generate simulated data <em>n_iter</em> times and output tables of effects and p-values.</p>
<pre class="r"><code>iterate_experiment &lt;- function(
  n=10, # number of replicates per treatment level
  niter=2000, # number of iterations
  rho=0.5, # correlation between the reference value and that of a control level
  s_kappa=1, # effect of treatment on shape (this is multiplicative so 1 = no effect)
  s_theta=1, # effect of treatment on scale (this is multiplicative so 1 = no effect
  kappa_0=80, # shape parameter for reference
  theta_0=100, # scale parameter for reference
  kappa_1=30, # shape parameter for control
  theta_1=100 # scale parameter for control
  ){
  # Given a western blot with three &quot;treatments&quot;: reference (Gapdh) is the set of values for normaliztion
  # control is the set of values for a control. The treatment value is determined by beta_1 -- the effect
  prob_cols &lt;- c(&quot;lm&quot;, &quot;norm1&quot;, &quot;norm2&quot;)
  prob &lt;- data.table(matrix(-9999, nrow=niter, ncol=length(prob_cols)))
  setnames(prob, old=colnames(prob), new=prob_cols)
  effect_cols &lt;- c(&quot;delta_gapdh&quot;, &quot;effect_lm&quot;, &quot;effect_norm1&quot;, &quot;effect_norm2&quot;)
  effects_dt &lt;- data.table(matrix(-9999, nrow=niter, ncol=length(effect_cols)))
  setnames(effects_dt, old=colnames(effects_dt), new=effect_cols)
  # effect_lm &lt;- numeric(niter) # effect size using lm with gapdh as covariate
  # effect_norm1 &lt;- numeric(niter) # effect size using standard normalization against gapdh
  # effect_norm2 &lt;- numeric(niter) # effect size using re-scaling to control (shSrc in this case)
  # delta_gapdh &lt;- numeric(niter) # the difference between control and treatment gapdh
  kappa_1_i &lt;- rep(c(kappa_1, kappa_1*s_kappa), each=n)
  for(iter in 1:niter){
    fd &lt;- simulate_experiment(
      n, # number of replicates per treatment level
      rho, # correlation between the reference value and that of a control level
      s_kappa, # effect of treatment on shape (this is multiplicative so 1 = no effect)
      s_theta, # effect of treatment on scale (this is multiplicative so 1 = no effect
      kappa_0, # shape parameter for reference
      theta_0, # scale parameter for reference
      kappa_1, # shape parameter for control
      theta_1 # scale parameter for control
    )

    m1 &lt;- lm(value ~ gapdh + treatment, data=fd)
    prob[iter, lm := coef(summary(m1))[&quot;treatmenttr&quot;, &quot;Pr(&gt;|t|)&quot;]]
    prob[iter, norm1 := t.test(fd[treatment==&quot;cn&quot;, norm1], fd[treatment==&quot;tr&quot;, norm1], var.equal=TRUE)$p.value]
    prob[iter, norm2 := t.test(x=fd[treatment==&quot;tr&quot;, norm2], mu=1)$p.value]
    
    effects_dt[iter, delta_gapdh := mean(fd[treatment==&quot;tr&quot;, gapdh]) - mean(fd[treatment==&quot;cn&quot;, gapdh])]
    effects_dt[iter, effect_lm := coef(summary(m1))[&quot;treatmenttr&quot;, &quot;Estimate&quot;]]
    effects_dt[iter, effect_norm1 := mean(fd[treatment==&quot;tr&quot;, norm1]) - mean(fd[treatment==&quot;cn&quot;, norm1])]
    effects_dt[iter, effect_norm2 := mean(fd[treatment==&quot;tr&quot;, norm2]) - 1]
  }
  return(
    cbind(prob, effects_dt)
  )
}</code></pre>
</div>
<div id="functions-to-plot-simulation-results" class="section level3">
<h3>functions to plot simulation results</h3>
<pre class="r"><code>plot_effects &lt;- function(res){
  prob_cols &lt;- c(&quot;lm&quot;, &quot;norm1&quot;, &quot;norm2&quot;)
  niter &lt;- nrow(res)
  apply(res[,.SD, .SDcols=prob_cols], 2, function(x) sum(x &lt; 0.05)/niter)
  gg1 &lt;- qplot(x=res$delta_gapdh/10^3, y=res$effect_lm) +
    geom_smooth(method=&quot;lm&quot;) +
    ggtitle(&quot;Linear model&quot;) +
    xlab(expression(paste(Gapdh[t] - Gapdh[c],  &quot;(X 1000)&quot;))) +
    ylab(&quot;Effect&quot;) +
    theme_minimal() +
    NULL
  gg2 &lt;- qplot(x=res$delta_gapdh/10^3, y=res$effect_norm1) +
    geom_smooth(method=&quot;lm&quot;) +
    ggtitle(&quot;Norm1&quot;) +
    xlab(expression(paste(Gapdh[t] - Gapdh[c],  &quot;(X 1000)&quot;))) +
    ylab(&quot;Effect&quot;) +
    theme_minimal() +
    NULL
  gg3 &lt;- qplot(x=res$delta_gapdh/10^3, y=res$effect_norm2) +
    geom_smooth(method=&quot;lm&quot;) +
    ggtitle(&quot;Norm2&quot;) +
    xlab(expression(paste(Gapdh[t] - Gapdh[c],  &quot;(X 1000)&quot;))) +
    ylab(&quot;Effect&quot;) +
    theme_minimal() +
    NULL
  gg &lt;- plot_grid(gg1, gg2, gg3, nrow=1)
  return(gg)
}

plot_prob_t1 &lt;- function(res){
  res[, t1.lm:=ifelse(lm &lt;= 0.05, 1, 0)]
  res[, t1.norm1:=ifelse(norm1 &lt;= 0.05, 1, 0)]
  res[, t1.norm2:=ifelse(norm2 &lt;= 0.05, 1, 0)]
  gg1 &lt;- ggplot(data=res, aes(x=abs(delta_gapdh), y=t1.lm)) +
    geom_smooth(method=&#39;glm&#39;, method.args=list(family=&#39;binomial&#39;)) +
    ylab(&quot;Prob(Type I): linear model&quot;) +
    xlab(expression(paste(&quot;|&quot;,Gapdh[t] - Gapdh[c],&quot;|&quot;))) +
    theme_minimal()
  gg2 &lt;- ggplot(data=res, aes(x=abs(delta_gapdh), y=t1.norm1)) +
    geom_smooth(method=&#39;glm&#39;, method.args=list(family=&#39;binomial&#39;)) +
    ylab(&quot;Prob(Type I): norm1&quot;) +
    xlab(expression(paste(&quot;|&quot;,Gapdh[t] - Gapdh[c],&quot;|&quot;))) +
    theme_minimal()
  gg3 &lt;- ggplot(data=res, aes(x=abs(delta_gapdh), y=t1.norm2)) +
    geom_smooth(method=&#39;glm&#39;, method.args=list(family=&#39;binomial&#39;)) +
    ylab(&quot;Prob(Type I): norm2&quot;) +
    xlab(expression(paste(&quot;|&quot;,Gapdh[t] - Gapdh[c],&quot;|&quot;))) +
    theme_minimal()
  gg &lt;- plot_grid(gg1, gg2, gg3, nrow=1)
  return(gg)
}</code></pre>
</div>
<div id="results-and-consequences" class="section level3">
<h3>Results and consequences</h3>
<div id="cor-with-gapdh0-no-treatment-effect" class="section level4">
<h4>Cor with Gapdh=0, no treatment effect</h4>
<p>This simulates a case where there is no correlation between the reference level and the experimental (control and treatment) levels. Wouldn’t need to normalize if this were the case but I include here to show how patterns are created by normalization.</p>
<pre class="r"><code>set.seed(1)
file_path &lt;- here(output_path, &quot;normalization_res1.rds&quot;)
if(simulate_it==TRUE){
  res &lt;- iterate_experiment(
  n=4, # number of replicates per treatment level
  niter=5000, # number of iterations
  rho=0, # correlation between the reference value and that of a control level
  s_kappa=1, # effect of treatment on shape (this is multiplicative so 1 = no effect)
  s_theta=1, # effect of treatment on scale (this is multiplicative so 1 = no effect
  kappa_0=80, # shape parameter for reference
  theta_0=100, # scale parameter for reference
  kappa_1=30, # shape parameter for control
  theta_1=100 # scale parameter for control
)
  saveRDS(res, file = file_path)
}else{
  res &lt;- readRDS(file = file_path)
}</code></pre>
<p>Unconditional Type I error in the three methods. “Unconditional” means not conditional on the observed difference in Gapdh value between treatment and control.</p>
<pre class="r"><code>prob_cols &lt;- c(&quot;lm&quot;, &quot;norm1&quot;, &quot;norm2&quot;)
niter &lt;- nrow(res)
type_1 &lt;- apply(res[,.SD, .SDcols=prob_cols], 2, function(x) sum(x &lt; 0.05)/niter)
knitr::kable(type_1, col.names=&quot;Type I&quot;)</code></pre>
<table>
<thead>
<tr class="header">
<th></th>
<th align="right">Type I</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>lm</td>
<td align="right">0.0476</td>
</tr>
<tr class="even">
<td>norm1</td>
<td align="right">0.0456</td>
</tr>
<tr class="odd">
<td>norm2</td>
<td align="right">0.1150</td>
</tr>
</tbody>
</table>
<p>Treatment effect size as a function of observed difference in Gapdh value between treatment and control <span class="math inline">\(\Delta Gapdh\)</span>. A slope indicates a <strong>conditional bias</strong> of the effect on <span class="math inline">\(\Delta Gapdh\)</span>, which results because of regression to the mean. The treatment effect of both norm1 and norm2 normalization is strongly conditionally biased.</p>
<pre class="r"><code>plot_effects(res)</code></pre>
<p><img src="/post/2019-10-16-normalization-results-in-regression-to-the-mean_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<pre class="r"><code># coef(summary(lm(effect_lm ~ delta_gapdh, data=res)))</code></pre>
<p>The probability of Type I error as a function of observed difference in Gapdh value between treatment and control <span class="math inline">\(\Delta Gapdh\)</span>. The nominal probability is 0.05. The plots show that the conditional Type I error (conditional on <span class="math inline">\(\Delta Gapdh\)</span>) increases to exceedingly high values as the magnitude of <span class="math inline">\(\Delta Gapdh\)</span> increases for both Norm1 and Norm 2 normalization procedures.</p>
<pre class="r"><code>plot_prob_t1(res)</code></pre>
<p><img src="/post/2019-10-16-normalization-results-in-regression-to-the-mean_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
</div>
<div id="cor-with-gapdh0.5-no-treatment-effect" class="section level4">
<h4>Cor with Gapdh=0.5, no treatment effect</h4>
<p>A correlation between Gapdh value and that of the control or treatment is expected (and the reason why normalization is done).</p>
<pre class="r"><code>set.seed(1)
file_path &lt;- here(output_path, &quot;normalization_res2.rds&quot;)
if(simulate_it==TRUE){
  res &lt;- iterate_experiment(
  n=4, # number of replicates per treatment level
  niter=5000, # number of iterations
  rho=0.5, # correlation between the reference value and that of a control level
  s_kappa=1, # effect of treatment on shape (this is multiplicative so 1 = no effect)
  s_theta=1, # effect of treatment on scale (this is multiplicative so 1 = no effect
  kappa_0=80, # shape parameter for reference
  theta_0=100, # scale parameter for reference
  kappa_1=30, # shape parameter for control
  theta_1=100 # scale parameter for control
)
  saveRDS(res, file = file_path)
}else{
  res &lt;- readRDS(file = file_path)
}</code></pre>
<p>Unconditional Type I error in the three methods. “Unconditional” means not conditional on the observed difference in Gapdh value between treatment and control.</p>
<pre class="r"><code>prob_cols &lt;- c(&quot;lm&quot;, &quot;norm1&quot;, &quot;norm2&quot;)
niter &lt;- nrow(res)
type_1 &lt;- apply(res[,.SD, .SDcols=prob_cols], 2, function(x) sum(x &lt; 0.05)/niter)
knitr::kable(type_1, col.names=&quot;Type I&quot;)</code></pre>
<table>
<thead>
<tr class="header">
<th></th>
<th align="right">Type I</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>lm</td>
<td align="right">0.0468</td>
</tr>
<tr class="even">
<td>norm1</td>
<td align="right">0.0546</td>
</tr>
<tr class="odd">
<td>norm2</td>
<td align="right">0.1100</td>
</tr>
</tbody>
</table>
<p>Treatment effect size as a function of observed difference in Gapdh value between treatment and control <span class="math inline">\(\Delta Gapdh\)</span>. A slope indicates a <strong>conditional bias</strong> of the effect on <span class="math inline">\(\Delta Gapdh\)</span>, which results because of regression to the mean. The treatment effect of both norm1 and norm2 normalization is strongly conditionally biased.</p>
<pre class="r"><code>plot_effects(res)</code></pre>
<p><img src="/post/2019-10-16-normalization-results-in-regression-to-the-mean_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<pre class="r"><code># coef(summary(lm(effect_lm ~ delta_gapdh, data=res)))</code></pre>
<p>The probability of Type I error as a function of observed difference in Gapdh value between treatment and control <span class="math inline">\(\Delta Gapdh\)</span>. The nominal probability is 0.05. The plots show that the conditional Type I error (conditional on <span class="math inline">\(\Delta Gapdh\)</span>) increases to exceedingly high values as the magnitude of <span class="math inline">\(\Delta Gapdh\)</span> increases for both Norm1 and Norm 2 normalization procedures.</p>
<pre class="r"><code>plot_prob_t1(res)</code></pre>
<p><img src="/post/2019-10-16-normalization-results-in-regression-to-the-mean_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>Interesting. The linear model method gets a wee bit conservative with increasing <span class="math inline">\(\Delta Gapdh\)</span> while norm1 is a little liberal. Norm2 is liberal across the range of <span class="math inline">\(\Delta Gapdh\)</span>.</p>
</div>
<div id="cor-with-gapdh0-treatment-effect-1-cohens-d" class="section level4">
<h4>Cor with Gapdh=0, treatment effect ~ 1 (cohen’s d)</h4>
<pre class="r"><code>set.seed(1)
file_path &lt;- here(output_path, &quot;normalization_res3.rds&quot;)
if(simulate_it==TRUE){
  res &lt;- iterate_experiment(
  n=4, # number of replicates per treatment level
  niter=5000, # number of iterations
  rho=0, # correlation between the reference value and that of a control level
  s_kappa=1.1, # effect of treatment on shape (this is multiplicative so 1 = no effect)
  s_theta=1.1, # effect of treatment on scale (this is multiplicative so 1 = no effect
  kappa_0=80, # shape parameter for reference
  theta_0=100, # scale parameter for reference
  kappa_1=30, # shape parameter for control
  theta_1=100 # scale parameter for control
)
  saveRDS(res, file = file_path)
}else{
  res &lt;- readRDS(file = file_path)
}</code></pre>
<p>Since there is a true treatment effect, this is the power (instead of Type I error). Linear model has slightly more power than norm1. norm2 has most power but this is at cost of high Type I error.</p>
<pre class="r"><code>prob_cols &lt;- c(&quot;lm&quot;, &quot;norm1&quot;, &quot;norm2&quot;)
niter &lt;- nrow(res)
type_1 &lt;- apply(res[,.SD, .SDcols=prob_cols], 2, function(x) sum(x &lt; 0.05)/niter)
knitr::kable(type_1, col.names=&quot;Power&quot;)</code></pre>
<table>
<thead>
<tr class="header">
<th></th>
<th align="right">Power</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>lm</td>
<td align="right">0.2106</td>
</tr>
<tr class="even">
<td>norm1</td>
<td align="right">0.1924</td>
</tr>
<tr class="odd">
<td>norm2</td>
<td align="right">0.2236</td>
</tr>
</tbody>
</table>
<p>We would hope the estimate of the effect would not change with <span class="math inline">\(\Delta Gapdh\)</span> (that is, it’s not conditional on this). The conditional effects for both normalizations are interesting. I can’t do the math to figure out what the E(effect) is for either normalization (except in the case when E(effect)=0 as above) but assuming these results are like the case with E(effect)=0 above, then effects are inflated when <span class="math inline">\(\Delta Gapdh &lt; 0\)</span> and supressed when <span class="math inline">\(\Delta Gapdh &gt; 0\)</span></p>
<pre class="r"><code>plot_effects(res)</code></pre>
<p><img src="/post/2019-10-16-normalization-results-in-regression-to-the-mean_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
</div>
<div id="cor-with-gapdh0.5-treatment-effect-1-cohens-d" class="section level4">
<h4>Cor with Gapdh=0.5, treatment effect ~ 1 (cohen’s d)</h4>
<pre class="r"><code>set.seed(1)
file_path &lt;- here(output_path, &quot;normalization_res4.rds&quot;)
if(simulate_it==TRUE){
  res &lt;- iterate_experiment(
  n=4, # number of replicates per treatment level
  niter=5000, # number of iterations
  rho=0.5, # correlation between the reference value and that of a control level
  s_kappa=1.1, # effect of treatment on shape (this is multiplicative so 1 = no effect)
  s_theta=1.1, # effect of treatment on scale (this is multiplicative so 1 = no effect
  kappa_0=80, # shape parameter for reference
  theta_0=100, # scale parameter for reference
  kappa_1=30, # shape parameter for control
  theta_1=100 # scale parameter for control
)
  saveRDS(res, file = file_path)
}else{
  res &lt;- readRDS(file = file_path)
}</code></pre>
<p>Power.</p>
<pre class="r"><code>prob_cols &lt;- c(&quot;lm&quot;, &quot;norm1&quot;, &quot;norm2&quot;)
niter &lt;- nrow(res)
type_1 &lt;- apply(res[,.SD, .SDcols=prob_cols], 2, function(x) sum(x &lt; 0.05)/niter)
knitr::kable(type_1, col.names=&quot;Power&quot;)</code></pre>
<table>
<thead>
<tr class="header">
<th></th>
<th align="right">Power</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>lm</td>
<td align="right">0.1802</td>
</tr>
<tr class="even">
<td>norm1</td>
<td align="right">0.2006</td>
</tr>
<tr class="odd">
<td>norm2</td>
<td align="right">0.2612</td>
</tr>
</tbody>
</table>
<pre class="r"><code>plot_effects(res)</code></pre>
<p><img src="/post/2019-10-16-normalization-results-in-regression-to-the-mean_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p>Don’t believe the higher power with norm2. It’s a mirage due to the liberal Type I error.</p>
</div>
</div>
</div>
